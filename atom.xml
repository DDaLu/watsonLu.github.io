<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>watson&#39;blogs</title>
  
  
  <link href="https://watsonlu6.github.io/atom.xml" rel="self"/>
  
  <link href="https://watsonlu6.github.io/"/>
  <updated>2024-07-28T13:44:52.484Z</updated>
  <id>https://watsonlu6.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ceph_Cache-Tier源码实现</title>
    <link href="https://watsonlu6.github.io/Ceph-Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/</id>
    <published>2022-04-28T12:45:54.000Z</published>
    <updated>2024-07-28T13:44:52.484Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cache-Tier架构"><a href="#Cache-Tier架构" class="headerlink" title="Cache Tier架构"></a>Cache Tier架构</h2><p>Ceph存储集群如果采用廉价的PC和传统的机械硬盘进行搭建，磁盘的访问速度受到了一定的限制，无法达到理想的IOPS性能水平。为了优化系统的IO性能，可以考虑添加快速的存储设备作为缓存，以减少数据的访问延时。其中，Cache Tier分层存储机制是一种常见的解决方案，在Ceph服务端缓存中被广泛使用，可以有效提升后端存储层的I&#x2F;O性能。Cache Tier需要创建一个由高速且昂贵的存储设备（如SSD）组成的存储池作为缓存层，以及一个相对廉价的设备组成的后端存储池作为经济存储层。缓存层使用多副本模式，存储层可以使用多副本或纠删码模式。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0.png" alt="Cache Tier"><br>Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。</p><h2 id="Ceph-Cache-tier处理流程"><a href="#Ceph-Cache-tier处理流程" class="headerlink" title="Ceph Cache tier处理流程"></a>Ceph Cache tier处理流程</h2><p>使用命令add-cache 可以将一个cachepool作为base pool的tier。这时会设置pool的信息，在pool里面记录了cache pool和base pool的关系。客户端在获取pool信息的时候可知，目标base pool存在一个tier，叫做cache pool，那么操作base pool的请求都会发送给cache pool。请求达到cache pool中时，作为tier的pool会有一些特别的处理maybe_cache_handle，具体的流程如下图：<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B02.png" alt="Cache Tier"></p><ul><li>判断操作的object是否在cache pool中命中，如果命中，则直接在cache pool中处理，和在普通pool的请求一样处理。后续会有agent线程将缓存脏数据刷写到base pool中。</li><li>没有命中缓存的情况下，才会去判断缓存模式。如果命中缓存，不管是什么模式都会在cache pool中处理。下面的处理都是未命中缓存的情况。</li><li>判断是否是writeback模式，读操作，如果可以proxy_read，那就直接do_proxy_read读取数据即可，不可以proxy_read 就使用do_cache_redirect，告诉客户端去base pool中读取。写操作，如果当前是evict_full模式，说明现在缓存中已经达到了阈值，需要等待缓存淘汰一些object，在完成写操作，目前放在等待队列中等待，如果不是evict_full模式，则需要从base pool中promote对应的object到cache pool中，promote结束后继续处理本次的写操作。</li><li>判断是否是forward模式。在forward模式下，不再在cachepool中处理请求，会告诉客户端将请求全部发送到base pool中。</li><li>判断是不是readonly模式。写操作会告诉客户端直接想base pool写即可，如果是读操作，则会从base pool中promote该object。</li><li>判断是不是readforward模式。该模式读操作全部都告诉客户端直接去base pool中读取即可，写操作按着writeback模式处理。</li><li>判断是不是readproxy模式。该模式读操作都采用cachepool的proxy read方法，写操作按着writeback模式处理。</li></ul><p>针对其中涉及到的几个封装好的方法的操作： do_cache_redirect， do_proxy_read， do_proxy_write，promote_object<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B03.png" alt="Cache Tier"></p><ul><li><strong>do_cache_redirect</strong> ：客户端请求cache pool，cache pool告诉客户端你应该去base pool中请求，客户端收到应答后，再次发送请求到base pool中请求数据，由base pool告诉客户端请求完成。</li><li><strong>do_proxy_read</strong>：客户端发送读请求到cache pool，但是未命中，则cache pool自己会发送请求到base pool中，获取数据后，由cache pool将数据发送给客户端，完成读请求。但是值得注意的是，虽然cache pool读取到了该object，但不会保存在cache pool中，下次请求仍然需要调用函数promote_objectbasePool读取该对象请求，然后写入cachePool中。</li><li><strong>do_proxy_write</strong>：直接写数据到basePool中，同样，cachePool中并没有该数据对象，还需要后续调用promote_object函数把数据对象从basePool中读到cachePool中。</li><li><strong>promote_object</strong>：当客户端发送请求到cache pool中，但是cache pool未命中，cache pool会选择将该object从base pool中提升到cache pool中，然后在cache pool进行读写操作，操作完成后告知客户端请求完成，在cache pool会缓存该object，下次直接在cache中处理，和proxy_read存在的区别。构造PromoteCallback回调函数，然后调用函数start_copyk拷贝函数。</li></ul><p>无论是 Proxy Read 还是 Promote Object 操作最终都是调用了 objecter 的 read 方法来从base storage层读取对象数据</p><h2 id="Cache-Tier数据结构"><a href="#Cache-Tier数据结构" class="headerlink" title="Cache Tier数据结构"></a>Cache Tier数据结构</h2><p>由于 Tier cache 在 Ceph 中的存在形式是存储池，pg_pool_t保存了存储池的相关属性。(src&#x2F;osd&#x2F;osd_type.h&#x2F;struct pg_pool_t)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">set&lt;<span class="type">uint64_t</span>&gt; tiers;   <span class="comment">//如果当前pool是一个basePool，tiers就记录改basepool的cachePool层，一个base pool可以设置多个cachePool</span></span><br><span class="line"><span class="type">int64_t</span> tier_of;            <span class="comment">//如果当前pool是一个cachePool，那么tier_of记录了该cachePool的basePool</span></span><br><span class="line"><span class="type">int64_t</span> read_tier;       <span class="comment">//设置basePool的读缓存层，根据Ceph不同的Cache Tier模式来设置</span></span><br><span class="line"><span class="type">int64_t</span> write_tier;      <span class="comment">//设置basePool的写缓存层，根据Ceph不同的Cache Tier模式来设置</span></span><br><span class="line"><span class="type">cache_mode_t</span> cache_mode;  <span class="comment">//设置Cache Tier模式</span></span><br><span class="line"><span class="type">uint64_t</span> target_max_bytes;   <span class="comment">//设置了cachePool的最大字节数</span></span><br><span class="line"><span class="type">uint64_t</span> target_max_objects; <span class="comment">//设置了cachePool的最大对象数量</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_dirty_ratio_micro;   <span class="comment">// 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_dirty_high_ratio_micro;   <span class="comment">// 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据</span></span><br><span class="line"><span class="type">uint32_t</span> cache_target_full_ratio_micro;   <span class="comment">// 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰</span></span><br><span class="line"><span class="type">uint32_t</span> cache_min_flush_age;      <span class="comment">// 对象在 cache 中被刷入到 storage 层的最小时间</span></span><br><span class="line"><span class="type">uint32_t</span> cache_min_evict_age;   <span class="comment">// 对象在 cache 中被淘汰的最小时间</span></span><br><span class="line">HitSet::Params hit_set_params; <span class="comment">// HitSet 相关参数</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_period;     <span class="comment">// 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的缓存统计信息</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_count;      <span class="comment">// 记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line"><span class="type">bool</span> use_gmt_hitset;        <span class="comment">// hitset archive 对象的命名规则 </span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_grade_decay_rate;    <span class="comment">//当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数</span></span><br><span class="line"><span class="type">uint32_t</span> hit_set_search_last_n;      <span class="comment">//为温度累积，最多N次hit_sets</span></span><br></pre></td></tr></table></figure><h4 id="读写IO"><a href="#读写IO" class="headerlink" title="读写IO"></a>读写IO</h4><p><strong>Add Cache</strong><br>在 ceph&#x2F;src&#x2F;mon&#x2F;OSDMonitor.cc 中实现了 add-cache 命令，从命令行中获取对应的参数并绑定 Tier 关系</p><p><strong>选择 Cache Pool</strong><br>Cache Tier的应用主要体现在计算OSD的过程中，通过判断basepool的参数，来决定是否要更新targetpool：读操作时，如果有read_tier，则更新为read_tier pool；写操作时，如果有write_tier，则更新为write_tier pool。read_tier和write_tier与pool是否开启Cache Tier有关。</p><p>在 ceph&#x2F;src&#x2F;osdc&#x2F;Objecter.cc&#x2F;Objecter::_calc_target中指定目标存储池为 Cache Pool，设置之后由后续的代码在该 Pool 中执行 Crush 算法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//首先根据base_oloc.pool获取pool信息，获取pg_pool_t对象   </span></span><br><span class="line"><span class="type">const</span> <span class="type">pg_pool_t</span> *pi = osdmap-&gt;<span class="built_in">get_pg_pool</span>(t-&gt;base_oloc.pool);</span><br><span class="line"><span class="comment">// apply tiering 根据读写操作，分别设置需要操作的 tier</span></span><br><span class="line">t-&gt;target_oid = t-&gt;base_oid;         #base_oid        <span class="comment">//读取的对象              #target_oid;          //最终读取的目标对象</span></span><br><span class="line">t-&gt;target_oloc = t-&gt;base_oloc;     #base_oloc       <span class="comment">//对象的pool信息      #//target_oloc      //最终目标对象的pool信息</span></span><br><span class="line"><span class="keyword">if</span> ((t-&gt;flags &amp; CEPH_OSD_FLAG_IGNORE_OVERLAY) == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="comment">//检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值。</span></span><br><span class="line"><span class="keyword">if</span> (is_read &amp;&amp; pi-&gt;<span class="built_in">has_read_tier</span>())</span><br><span class="line">    t-&gt;target_oloc.pool = pi-&gt;read_tier;</span><br><span class="line">    <span class="comment">//如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值。</span></span><br><span class="line"><span class="keyword">if</span> (is_write &amp;&amp; pi-&gt;<span class="built_in">has_write_tier</span>())</span><br><span class="line">        t-&gt;target_oloc.pool = pi-&gt;write_tier;</span><br><span class="line">pi = osdmap-&gt;<span class="built_in">get_pg_pool</span>(t-&gt;target_oloc.pool);</span><br><span class="line"><span class="keyword">if</span> (!pi) &#123;</span><br><span class="line">    t-&gt;osd = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> RECALC_OP_TARGET_POOL_DNE;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>osd 先接收到客户端发送来的请求，然后OSD::dequeue_op()调用 PrimaryLogPG:: do_request()——&gt;PrimaryLogPG::do_op()中处理，这都是正常的一个 pool 处理请求的流程，在 do_op 中来看看不同于其他普通 pool 的处理。如果开启了Cache Tier，将会在do_op中执行以下操作：</p><ol><li>首先判断hit_set中是否包含待操作的对象（hit_set-&gt;contains(obc-&gt;obs.oi.soid)），如果不包含，则把对象添加到hit_set中。添加对象后，如果hit_set满了，或者hit_set超时，则调用hit_set_persist()。</li><li>执行agent_choose_mode()，设置agent相关参数，如flush_mode、num_objects、num_bytes等。</li><li>执行maybe_handle_cache()。这里处理cache执行逻辑。</li><li>如果maybe_handle_cache()中调用maybe_handle_cache_detail()，如果成功处理了op请求，则直接return，否则会继续执行后续操作（说明不需要从datapool读取数据或者转发请求到datapool，可以直接在此osd命中查询的对象），由本OSD执行读取操作。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B01.png" alt="Cache Tier"></li></ol><h4 id="HitSet"><a href="#HitSet" class="headerlink" title="HitSet"></a>HitSet</h4><p>在 write back&#x2F;read forward&#x2F;read proxy 模式下需要 HitSet 来记录缓存命中。</p><p>HitSet 用于跟踪和统计对象的访问行为，记录对象是否存在缓存中。定义了一个缓存查找到抽象接口，目前提供了三种实现方式：ExplicitHashHitSet，ExplicitObjectHitSet，BloomHitSet</p><p>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h 定义了抽象接口，同时该头文件中包含了具体的 HitSet 实现</p><ul><li><strong>ExplicitHashHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitHashHitSet</li><li>基于对象的 32 位 HASH 值的 set 来记录对象的命中，每个对象占用 4 bytes 内存空间</li><li>优点：空间占用相对较少，但需要根据 HASH 进行全局的扫描遍历比较</li></ul></li><li><strong>ExplicitObjectHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class ExplicitObjectHitSet</li><li>使用一个基于 ceph&#x2F;src&#x2F;common&#x2F;hobject 的 set 来记录对象的命中，占用的内存取决于对象的关键信息的大小</li><li>使用内存中缓存数据结构来进行判断带来的优点就是实现相对简单直观，但占用的内存空间相对较大</li></ul></li><li><strong>BloomHitSet</strong><ul><li>ceph&#x2F;src&#x2F;osd&#x2F;HitSet.h&#x2F;class BloomHitSet</li><li>采用了压缩的 Bloom Filter 的方式来记录对象是否在缓存中，进一步减少了内存占用空间</li></ul></li></ul><h3 id="Cache-Tier的初始化"><a href="#Cache-Tier的初始化" class="headerlink" title="Cache Tier的初始化"></a>Cache Tier的初始化</h3><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::hit_set_setup()用来创建并初始化HisSet对象</li><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_setup()完成agent相关的初始化工作</li></ul><h2 id="Cache-Pool-请求处理"><a href="#Cache-Pool-请求处理" class="headerlink" title="Cache Pool 请求处理"></a>Cache Pool 请求处理</h2><p>Cache 的相关请求处理可以通过do_op()进行梳理，主要包含了 agent_choose_mode()和 maybe_handle_cache() 两个主要方法。(src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;do_op(OpRequestRef &amp;))</p><p><strong>agent_choose_mode(bool restart, OpRequestRef op)</strong></p><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;agent_choose_mode</li><li>该函数主要计算一个 PG 的 flush_mode 和 evic_mode 的参数值。</li><li>返回值如果为 True，表明该请求 Op 被重新加入请求队列（由于 EvictMode 为 Full），其他情况返回 false。</li></ul><p><strong>maybe_handle_cache(…)</strong></p><ul><li>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;maybe_handle_cache()调用maybe_handle_cache_detail(）</li><li>处理有关cache的读写请求</li></ul><!-- 图解maybe_handle_cache_detail()缓存策略将以上缓存策略的处理流程转换为流程图如下所示（注：流程细节随着Ceph版本的迭代已经有锁改变，此处重点关注最终的调用）![Cache Tier](/images/缓存基础与Ceph分层存储/Cache-Tier源码实现2.png)针对其中涉及到的几个封装好的方法的操作： do_cache_redirect， do_proxy_read， do_proxy_write，promote_object![Cache Tier](/images/缓存基础与Ceph分层存储/Cache-Tier源码实现3.png)- **do_cache_redirect** ：客户端请求cache pool，cache pool告诉客户端你应该去base pool中请求，客户端收到应答后，再次发送请求到base pool中请求数据，由base pool告诉客户端请求完成。- **do_proxy_read**：客户端发送读请求到cache pool，但是未命中，则cache pool自己会发送请求到base pool中，获取数据后，由cache pool将数据发送给客户端，完成读请求。但是值得注意的是，虽然cache pool读取到了该object，但不会保存在cache pool中，下次请求仍然需要调用函数promote_objectbasePool读取该对象请求，然后写入cachePool中。- **do_proxy_write**：直接写数据到basePool中，同样，cachePool中并没有该数据对象，还需要后续调用promote_object函数把数据对象从basePool中读到cachePool中。- **promote_object**：当客户端发送请求到cache pool中，但是cache pool未命中，cache pool会选择将该object从base pool中提升到cache pool中，然后在cache pool进行读写操作，操作完成后告知客户端请求完成，在cache pool会缓存该object，下次直接在cache中处理，和proxy_read存在的区别。构造PromoteCallback回调函数，然后调用函数start_copyk拷贝函数。无论是 Proxy Read 还是 Promote Object 操作最终都是调用了 objecter 的 read 方法来从base storage层读取对象数据 --><h4 id="Cache-flush-evict"><a href="#Cache-flush-evict" class="headerlink" title="Cache flush &amp; evict"></a>Cache flush &amp; evict</h4><p>cachePool空间不够时，需要选择一些脏数据对象会刷到数据层，即flush操作；将一些clean对象从缓存层剔除，以释放更多的缓存空间，即evict操作。这两种操作都是在后台线程完成的。<strong>flush操作和evict操作算法的好坏决定了Cache Tier的缓存命中率</strong>。evict是针对cachepool中已经过期或过冷的数据，只需要把它从cachepool中删除即可，evict操作通常会影响缓存命中率。flush是把脏数据刷新到storagePool，flush操作通常不会直接影响缓存命中率。flush操作是将缓存中的数据写回到持久存储介质中，从而保证数据的一致性，但并不会直接影响缓存的访问，脏数据是只保存在cachePool中，经过修改后，还未写入storagePool的数据。</p><p><strong>数据结构</strong><br>src&#x2F;osd&#x2F;osd.h&#x2F;OSDServices ：定义了 AgentThread 后台线程，用于完成 flush 和 evict 操作：一是把脏对象从cachePool层适时地会刷到basePool层；二是从cachePool层剔除掉一些不经常访问的clean对象。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Mutex agent_lock;     <span class="comment">// agent 线程锁，保护下面所有数据结构</span></span><br><span class="line">Cond agent_cond;     <span class="comment">// 线程相应的条件变量</span></span><br><span class="line">map&lt;<span class="type">uint64_t</span>, set&lt;PGRef&gt; &gt; agent_queue;   <span class="comment">// agent线程的工作队列，保存了OSD中所有归属于cachePool的淘汰或者回刷所需的 PG 集合，根据PG集合的优先级，保存在不同的map中</span></span><br><span class="line">set&lt;PGRef&gt;::iterator agent_queue_pos;   <span class="comment">//当前在扫描的PG集合的一个位置</span></span><br><span class="line"><span class="type">bool</span> agent_valid_iterator;  <span class="comment">//只有agent_valid_iterator为true时，agent_queue_pos指针才有效，否则从集合的起始处开始扫描</span></span><br><span class="line"><span class="type">int</span> agent_ops;            <span class="comment">// 所有正在进行的回刷和淘汰操作</span></span><br><span class="line"><span class="type">int</span> flush_mode_high_count;      <span class="comment">//一旦FLUSH_MODE_HIGH有了一个pg，就可以高速刷新对象</span></span><br><span class="line">set&lt;<span class="type">hobject_t</span>&gt; agent_oids;    <span class="comment">// 所有正在进行的 agent 操作（回刷或者淘汰）的对象</span></span><br><span class="line"><span class="type">bool</span> agent_active;    <span class="comment">// agent 是否有效</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">AgentThread</span> : <span class="keyword">public</span> Thread&#123;&#125; agent_thread;    <span class="comment">// agent 线程，专门用来处理cache tier数据迁移的线程，线程名叫：osd_srv_agent。其作用就是循环遍历agent_queue中的所有pg，并对他们执行agent_work()操作。osd_srv_agent线程是一个OSD上所有PG公用的，为了保证效率，设置了严格的限流参数：osd_pool_default_cache_max_evict_check_size限制依次遍历对象的总数，达到后立刻切换退出循环在osd_srv_agent中切换PG；osd_agent_max_ops设置了一个循环中最多能够处理几次flush或者evict操作。</span></span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> agent_stop_flag;   <span class="comment">// agent 停止的标志</span></span><br><span class="line">    SafeTimer agent_timer;   <span class="comment">//agent相关定时器：当扫描一个 PG 对象时，该对象既没有剔除操作，也没有回刷操作，就停止 PG 的扫描，把该 PG 加入到定时器中，5S 后继续</span></span><br></pre></td></tr></table></figure><p>src&#x2F;osd&#x2F;TierAgentState.h：TierAgentState用来保存PG相关的agent信息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">hobject_t</span> position;    <span class="comment">//PG内扫描的对象位置</span></span><br><span class="line"><span class="type">int</span> started;    <span class="comment">//PG里所有对象扫描完成后，所发起的所有的agent操作数目。如果没有agent操作，就需要延迟一段时间</span></span><br><span class="line"><span class="type">hobject_t</span> start;    <span class="comment">//本次扫描起始位置</span></span><br><span class="line"><span class="type">bool</span> delaying;    <span class="comment">//是否延迟</span></span><br><span class="line"><span class="type">pow2_hist_t</span> temp_hist;   <span class="comment">//历史统计信息</span></span><br><span class="line"><span class="type">int</span> hist_age;</span><br><span class="line">map&lt;<span class="type">time_t</span>,HitSetRef&gt; hit_set_map;   <span class="comment">//Hitset的历史记录</span></span><br><span class="line">list&lt;<span class="type">hobject_t</span>&gt; recent_clean;   <span class="comment">//最近处于clean的对象</span></span><br><span class="line"><span class="type">unsigned</span> evict_effort;      <span class="comment">//应该驱逐的对象的大致比例（假设它们均匀分布）</span></span><br></pre></td></tr></table></figure><h4 id="flush-evict-执行入口"><a href="#flush-evict-执行入口" class="headerlink" title="flush&#x2F;evict 执行入口"></a>flush&#x2F;evict 执行入口</h4><p>src&#x2F;osd&#x2F;osd.cc&#x2F;OSDService::agent_entry：agent_entry 是 agent_thread 的入口函数，它在后台调用pg-&gt;agent_work()，agent_queue的改变是在PrimaryLogPG::agent_choose_mode函数中改变的</p><p>src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_work：遍历PG中所有对象，去寻找已经过期的、失效的需要flush或者evict的对象并对它们执行相应操作。</p><ol><li><p>扫描本PG的对象，从 agent_state-&gt;position 开始扫描，结果保存在 ls 中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">hobject_t</span>&gt; ls;</span><br><span class="line"><span class="type">int</span> r = pgbackend-&gt;<span class="built_in">objects_list_partial</span>(agent_state-&gt;position, ls_min, ls_max, &amp;ls, &amp;next); </span><br></pre></td></tr></table></figure></li><li><p>对扫描的 ls 对象做相应的检查，执行 evict 操作和 flush 操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (vector&lt;<span class="type">hobject_t</span>&gt;::iterator p = ls.<span class="built_in">begin</span>();p != ls.<span class="built_in">end</span>(); ++p)     </span><br><span class="line"><span class="keyword">if</span> (agent_state-&gt;evict_mode != TierAgentState::EVICT_MODE_IDLE &amp;&amp; <span class="built_in">agent_maybe_evict</span>(obc, <span class="literal">false</span>))</span><br><span class="line">    ++started;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (agent_state-&gt;flush_mode!=TierAgentState::FLUSH_MODE_IDLE&amp;&amp;agent_flush_quota&gt;<span class="number">0</span>&amp;&amp;<span class="built_in">agent_maybe_flush</span>(obc)) &#123;</span><br><span class="line">    ++started;</span><br><span class="line">    --agent_flush_quota;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li></ol><p>真正执行操作的方法</p><ul><li><strong>evict</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_evict</li><li><strong>flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::agent_maybe_flush</li><li><strong>start_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_flush 该函数完成实际的 flush 操作</li><li><strong>start_manifest_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::start_manifest_flush  真正刷回数据之前的数据准备</li><li><strong>do_manifest_flush</strong>：src&#x2F;osd&#x2F;PrimaryLogPG.cc&#x2F;PrimaryLogPG::do_manifest_flush 真正刷回数据的过程</li></ul><p>flush 操作最终是以 Op 请求的方式传递到底层存储层的，也就意味着需要再执行一次 Ceph 存储池写数据的相关逻辑。<br>Ceph的Cache Tier功能目前在对象访问频率和热点统计上的实现都比较简单，可以通过基于自学习的Cache算法提升缓存命中率。</p><p><strong>agent_state在每个函数中都起到决定性地位</strong>：在agent_work中，agent_state-&gt;evict_mode和agent_state-&gt;flush_mode的值决定要不要进行evict和flush判断。在agent_maybe_evict和agent_maybe_flush中agent_state-&gt;evict_mode的值决定要不要直接执行evict或者flush。而agent_state值的计算过程是在agent_choose_mode函数中。agent_choose_mode函数计算一个PG的flush和evict行为的相关参数。该函数主要完成以下任务：</p><ul><li>统计当前PG中dirty object数量和当前PG中所有的object数量；（dirty object指的是脏数据对象)</li><li>统计当前PG中dirty object占用的字节数和当前PG中所有object占用的总的字节数；</li><li>分别从object数量角度和object占用的字节数角度计算dirty占比和full占比；</li><li>计算当前flush mode和evict mode；</li><li>更新agent_state-&gt;flush_mode和agent_state-&gt;evict_mode；</li><li>根据当前flush mode和evict mode决定是要将当前PG加入到待处理的PG队列中；</li></ul><p>从agent_choose_mode最后可以看到，如果缓存池需要flush或者evict，需要将待处理的PG加入到agent_queue队列中，这一动作是最终通过调用_enqueue函数实现，该函数主要完成以下任务：</p><ul><li>src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_enqueue</li><li>判断是否需要调整agent线程要处理哪个pg set；</li><li>将待处理的pg加入到pg set中；</li><li>唤醒agent线程，执行flush或者evict任务；</li></ul><p>从agent_choose_mode最后可以看到，如果缓存池需不需要flush或者evict，但是如果之前agent线程有处理过该PG，需要将待处理的PG从agent_queue队列中移除掉，这一动作最终通过调用_dequeue函数实现，该函数主要完成以下任务：</p><ul><li>src&#x2F;osd&#x2F;OSD.h&#x2F;OSDService::_dequeue</li><li>根据old_priority从agent_queue队列中获取到相应的pg set；</li><li>在pg set中查找要移除的PG；如果找到了，从pg set中删除，并调整下一个要处理的PG；</li><li>如果删除之后的pg set没有任何一个PG，需要从agent_queue队列中移除，并调整下一个要处理的pg set；</li></ul><p><strong>agent_choose_mode流程图</strong><br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B04.jpg" alt="Cache Tier"><br><strong>agent_entry流程图</strong><br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/Cache-Tier%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B05.jpg" alt="Cache Tier"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Cache-Tier架构&quot;&gt;&lt;a href=&quot;#Cache-Tier架构&quot; class=&quot;headerlink&quot; title=&quot;Cache Tier架构&quot;&gt;&lt;/a&gt;Cache Tier架构&lt;/h2&gt;&lt;p&gt;Ceph存储集群如果采用廉价的PC和传统的机械硬盘进行搭建，</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>缓存基础与Ceph分层存储</title>
    <link href="https://watsonlu6.github.io/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/"/>
    <id>https://watsonlu6.github.io/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/</id>
    <published>2022-04-10T11:59:00.000Z</published>
    <updated>2024-07-28T13:18:06.630Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存基础"><a href="#缓存基础" class="headerlink" title="缓存基础"></a>缓存基础</h2><ol><li><p><strong>缓存命中率</strong>：表示从缓存中获取数据的成功率，即缓存命中的次数与总访问次数的比值。缓存命中率越高，表示缓存系统的效率越高，能够更快地响应用户的请求。</p></li><li><p><strong>缓存失效率</strong>：表示从缓存中获取数据失败的次数与总访问次数的比值。缓存失效率越高，表示缓存系统的效率越低，需要从持久存储介质中读取数据的次数也越多，可能会导致系统的响应速度变慢。</p></li><li><p><strong>缓存容量</strong>：指缓存系统能够存储数据的最大容量。缓存容量的大小会影响缓存系统的性能和可靠性，如果缓存容量不足，可能会导致缓存系统频繁地进行evict操作，从而影响系统的响应速度和可用性。</p></li><li><p><strong>缓存算法</strong>：指缓存系统用于决定哪些数据被缓存，哪些数据被删除的算法。常见的缓存算法包括LRU（最近最少使用）、LFU（最不经常使用）、FIFO（先进先出）等。</p></li><li><p><strong>脏数据（Dirty Data）</strong>：指缓存中已经被修改但尚未被写回到持久存储介质（如磁盘）中的数据。这些数据需要及时写回到持久存储介质中以保证数据的一致性。常见的处理策略包括写回（write-back）和写直达（write-through）策略。</p></li><li><p><strong>干净数据（Clean Data）</strong>：指缓存中未被修改或已经被写回到持久存储介质中的数据。干净数据在缓存系统中可以快速读取，减少写入操作，优先选择删除干净数据可以避免写回操作带来的额外开销。</p></li><li><p><strong>evict操作</strong>：从缓存中移除某些数据，以释放缓存空间供其他数据使用。常用的策略包括LRU（Least Recently Used）等，根据最近最少使用的数据进行移除。</p></li><li><p><strong>flush操作</strong>：将缓存中的数据立即写回到持久性存储介质（例如硬盘），以确保缓存中的数据与存储介质中的数据保持一致。</p></li></ol><h4 id="数据一致性和性能考虑"><a href="#数据一致性和性能考虑" class="headerlink" title="数据一致性和性能考虑"></a>数据一致性和性能考虑</h4><ul><li><p><strong>脏数据的处理</strong>：存在脏数据可能导致数据一致性问题和性能问题，因此需要及时处理脏数据。选择适当的写回策略可以平衡数据一致性和系统性能。</p></li><li><p><strong>干净数据的优先删除</strong>：在缓存系统中，干净数据的存在可以提高系统性能，因为它们可以快速读取而不需要进行额外的写入操作。当需要从缓存中删除对象时，通常优先选择删除干净数据。</p></li><li><p><strong>flush操作的选择</strong>：通常在以下情况下使用flush操作：</p><ul><li>数据一致性要求高的场景，如数据库应用</li><li>性能要求不高或系统关闭时需要保证数据的持久性</li></ul></li><li><p><strong>evict操作的选择</strong>：通常在以下情况下使用evict操作：</p><ul><li>缓存空间不足，需要释放空间</li><li>数据访问模式固定或数据访问频率低</li><li>基于缓存替换算法（如LRU、LFU、FIFO等）</li></ul></li></ul><h4 id="缓存替换算法"><a href="#缓存替换算法" class="headerlink" title="缓存替换算法"></a>缓存替换算法</h4><ul><li><strong>LRU（Least Recently Used）</strong>：根据最近的访问时间来决定删除哪些数据。</li><li><strong>LFU（Least Frequently Used）</strong>：基于数据的访问频率选择删除数据。</li><li><strong>FIFO（First In First Out）</strong>：按照数据进入缓存的时间顺序移除数据。</li><li><strong>Random（随机）</strong>：随机选择数据进行删除，简单但效果不如其他算法。</li></ul><h4 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h4><ul><li><p><strong>优化evict操作</strong>：通过使用动态策略（基于数据使用情况）和静态策略（基于数据属性），可以提升缓存性能。了解系统的负载和压力情况也有助于优化evict操作。</p></li><li><p><strong>缓存命中率影响</strong>：evict操作可能导致缓存命中率下降，因为被删除的数据可能被访问到。flush操作通常不会直接影响缓存命中率，但需要高效的实现以避免影响系统性能。</p></li></ul><p>这些基本要素和策略可以帮助优化缓存系统的性能和可靠性，根据具体的应用需求进行适当的调整和选择。</p><h2 id="Ceph分层存储Cache-Tier"><a href="#Ceph分层存储Cache-Tier" class="headerlink" title="Ceph分层存储Cache Tier"></a>Ceph分层存储Cache Tier</h2><p>分层存储是存储领域中的一个重要分支，其思想基石是存储的金字塔模型——描述了快速设备通常容量小而性能高，慢速设备通常容量大而性能低。对于数据访问而言，通常在一段时间内，真实数据的访问是具有时间局部性和空间局部性的。时间局部性是指被访问的数据在短时间内可能再次被访问，空间局部性是指与被访问数据临近的数据有更大的概率被访问。故基于时间局部性理论产生了通常所说的缓存，如：cpu缓存、内存等；而基于空间局部性原理，产生了数据预取，如：指令预取（prefetch）、数据预读（read ahead）等。</p><p>目前Ceph的OSD主要可以基于SSD或者HDD的裸盘进行构建，机械盘通常比固态盘容量大、价格比固态盘低、但读写比固态盘慢，如何用机械盘和固态盘来提供一个高可靠、高性能、高性价比的分布式存储是需要解决的重要问题。如果全部基于SSD进行构建，其性能一定会最优，但是SSD价格昂贵，出于成本考虑，不可能全部采用SSD进行构建，那么SSD与HDD混合硬件架构就显得很有必要。</p><p>Ceph的缓存分层理论基础是数据存在热点，数据访问不均匀。通常，80%的应用只访问20%的数据，这20%的数据被称为热点数据。为了减少响应时间，可以将热点数据保存到性能较高的存储设备（如固态硬盘）中。在Cache Tiering中，有一个分层代理，当保存在缓存层的数据变冷或不再活跃时，该代理会将这些数据刷到存储层，并将其从缓存层中移除。这种操作称为刷新或逐出。在客户端读写数据时，Ceph的对象处理器负责决定对象存储的位置，而Cache Tier则决定何时将缓存层中的对象刷回后端存储层。对于写操作，请求到达缓存层后，完成写操作后直接应答客户端，之后由缓存层的代理线程负责将数据写入存储层。对于读操作，如果命中缓存层，直接在缓存层读取，否则可以重定向到存储层访问。如果数据近期有访问过，说明比较热，可以提升到缓存层中。对于Ceph客户端来说，缓存层和后端存储层是完全透明的。所有Ceph客户端都可以使用缓存层，因此Cache Tier具有提升块设备、Ceph对象存储、Ceph文件系统和原生绑定的I&#x2F;O性能的潜力。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8.jpg" alt="Cache Tier"></p><p>Ceph Cache Tier提供了快速存储池与慢速存储池间的分层缓存特性。通常来说，对于块存储用户而言，数据访问会有明显的时间局部性与空间局部性，故可以通过分层存储思想，改善资源配置及效率。Ceph提供了Cache Tier的解决方案，能够融合两种存储，通过合理配比提供容量与性能介于SSD与HDD之间的虚拟存储资源池。对于对象存储而言，目前主要对外提供基于S3与Swift restful api的访问接口。RGW对象存储可以通过对数据池进行Cache Tier，从而提高其访问效率。</p><p>在Ceph中，分层存储系统通过缓存和存储池的方式实现，热资源池可以将数据存储至那些管理SSD磁盘的OSD上，而冷资源池可以将数据存储至那些管理HDD磁盘的OSD上。若客户命中被访问的数据落在热资源池中，可以直接被访问，此时IO速度最快，接近SSD磁盘的性能。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A81.jpg" alt="Cache Tier命中"></p><p>若客户被访问的数据不落在热资源池中，出现缓存丢失的情况，需要转向去HDD盘上读取数据，而HDD盘处理请求访问速度为毫秒级别，故网络延时与请求处理延时可以近似忽略，认为其访问速度接近HDD磁盘的性能。这时候的处理分为两种：代理读写和数据拉取。当读写请求出现缓存丢失时，代理读写向后端请求冷数据，但缓存池不对数据进行缓存，直接将请求内容返回给客户端。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A82.jpg" alt="缓存池的代理读写"></p><p>读写请求出现缓存丢失时，缓存池向后端请求冷数据，在向后端请求冷数据后，会将数据读入缓存池，继续处理客户端请求并返回请求内容。此外，短时间内被多次访问的数据会被认为是热数据而拉取到热池中，这将消耗HDD磁盘的读带宽与SSD磁盘的写入带宽。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A83.jpg" alt="缓存池的数据拉取"></p><p>另一方面，在热池中的数据，需要定期回写入冷池，此时，回写数据将暂用SSD与HDD磁盘的部分带宽，这个过程叫数据回写。<br><img src="/images/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8/%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E4%B8%8ECeph%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A84.jpg" alt="缓存池的数据回写"></p><p>还未回写入冷资源池的数据，在热资源池中再次被修改，这种情况越多，缓存效率越高，即相当于热资源池带宽充分利用，帮助冷资源池挡掉了大量的写入带宽。可以简单的认为，有1%的数据是需要脏回刷的（即回刷后的1%数据为clean状态，所以后续的命中会是非脏命中），如果所有数据都不脏回刷，且都访问命中的话，那么脏命中率为100%。</p><p>根据上述原理，不难发现，Ceph Cache Tier的性能取决于访问命中率。访问命中率越高时，存储系统越接近SSD磁盘的性能；反之，访问命中率越低时，越接近HDD磁盘的性能。另一方面，在Ceph中，缓存粒度以对象方式进行拉取与回写，故在实际情况下，如果缓存丢失过多，将会有大量的数据会被拉取，从而占用SSD磁盘的带宽，使得其访问带宽比SATA磁盘更差。然而，在实际生产使用过程中，数据总使用量总是逐步增加的，与此同时，热数据的量也将逐步的增加。那么，在整个使用周期中，随着数据量的增加，就必然会经历以下过程：首先刚刚开始使用时，数据量还很少。此时，所有数据全部能够被缓存，数据命中率为100%，效果很好。随着总数据量与热数据量不断的增加，缓存池已经无法容纳所有数据，只能容纳较多的热数据，此时缓存命中率会随之逐步的下降。随着数据的进一步增加，缓存命中率低于某个临界值了，此时保持同样大小的缓存池已经无法给使用带来足够好的收益。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;缓存基础&quot;&gt;&lt;a href=&quot;#缓存基础&quot; class=&quot;headerlink&quot; title=&quot;缓存基础&quot;&gt;&lt;/a&gt;缓存基础&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缓存命中率&lt;/strong&gt;：表示从缓存中获取数据的成功率，即缓存命中的次数与总访问次数的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>存储性能测试工具</title>
    <link href="https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    <id>https://watsonlu6.github.io/%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</id>
    <published>2021-10-11T05:26:35.000Z</published>
    <updated>2024-08-03T06:56:02.287Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FIO简介"><a href="#FIO简介" class="headerlink" title="FIO简介"></a>FIO简介</h2><p>FIO是Linux下开源的一款IOPS测试工具，主要用来对磁盘进行压力测试和性能验证。它可以产生许多线程或进程来执行用户特定类型的I&#x2F;O操作，通过编写作业文件或者直接命令去执行测试动作，相当于是一个 多线程的io生成工具，用于生成多种IO模式来测试硬盘设备的性能（大多情况用于测试裸盘性能）。<br>硬盘I&#x2F;O测试主要有以下类型：</p><ul><li>随机读</li><li>随机写</li><li>顺序读</li><li>顺序写</li><li>混合读写 （可根据需求设置70%读，30%写或100%读等等）</li></ul><h2 id="FIO的安装与使用"><a href="#FIO的安装与使用" class="headerlink" title="FIO的安装与使用"></a>FIO的安装与使用</h2><p>github地址：github.com&#x2F;axboe&#x2F;fio<br>下载安装方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式1</span></span><br><span class="line">yum -i install fio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2</span></span><br><span class="line">yum -y install libaio-devel   <span class="comment">#安装libaio引擎，不然执行fio会报“fio: engine libaio not loadable”，必须要在fio安装前安装，不然还要重新编译安装一遍fio</span></span><br><span class="line">wget https://github.com/axboe/fio/archive/refs/tags/fio-3.10.zip</span><br><span class="line"><span class="built_in">cd</span> /root/fio-fio-3.10</span><br><span class="line">./configure</span><br><span class="line">mke &amp;&amp; make install</span><br></pre></td></tr></table></figure><h2 id="常用参数介绍"><a href="#常用参数介绍" class="headerlink" title="常用参数介绍"></a>常用参数介绍</h2><ul><li>filename&#x3D;&#x2F;dev&#x2F;sdb  要测试盘的名称，支持文件系统或者裸设备，&#x2F;dev&#x2F;sda2或&#x2F;dev&#x2F;sdb</li><li>direct&#x3D;1  测试过程绕过机器自带的buffer，使测试结果更真实（Linux在读写时，数据会先写到缓存，再在后台写到硬盘，读的时候也是优先从缓存中读，这样访问速度会加快，但是一旦掉电，缓存中数据就会清空，所有一种模式为DirectIO，可以跳过缓存，直接读写硬盘）</li><li>ioengine&#x3D;libaio  定义使用什么io引擎去下发io请求<ul><li>sync：同步IO引擎，使用Linux系统调用实现IO操作，可以测试磁盘性能的上限。</li><li>mmap：使用内存映射技术实现IO操作，可以测试文件系统的缓存和文件的预读能力。</li><li>libaio：异步IO引擎，使用Linux系统调用libaio实现IO操作，可以测试磁盘的随机读写性能。</li><li>posixaio：类似于libaio的异步IO引擎，但使用POSIX AIO接口实现IO操作。</li><li>pvsync：使用Linux系统调用实现IO操作，但对写操作进行缓存，并且只在需要时进行刷新，可以提高IO性能。</li><li>rbd：用于测试Ceph集群中rados block device (RBD)的性能，支持异步IO和同步IO操作。</li></ul></li><li>iodepth&#x3D;16  队列的深度为16，在异步模式下，CPU不能一直无限的发命令到硬盘设备。比如SSD执行读写如果发生了卡顿，那有可能系统会一直不停的发命令，几千个，甚至几万个，这样一方面SSD扛不住，另一方面这么多命令会很占内存，系统也要挂掉了。这样，就带来一个参数叫做队列深度。</li><li>bs&#x3D;4k   单次io的块文件大小为4k</li><li>numjobs&#x3D;10   并发工作线程数</li><li>size&#x3D;5G      每个线程读写的数据量是5GB</li><li>runtime&#x3D;60   测试时间为60秒，可以设置2m为两分钟。如果不配置此项，会将设置的size大小全部写入或者读取完为止</li><li>rw&#x3D;randread   测试随机读的I&#x2F;O</li><li>rw&#x3D;randwrite  测试随机写的I&#x2F;O</li><li>rw&#x3D;randrw     测试随机混合写和读的I&#x2F;O</li><li>rw&#x3D;read       测试顺序读的I&#x2F;O</li><li>rw&#x3D;write      测试顺序写的I&#x2F;O</li><li>rw&#x3D;rw         测试顺序混合写和读的I&#x2F;O</li><li>thread        使用pthread_create创建线程，另一种是fork创建进程。进程的开销比线程要大，一般都采用thread测试</li><li>rwmixwrite&#x3D;30   在混合读写的模式下，写占30%（即rwmixread读为70%，单独配置这样的一个参数即可）</li><li>group_reporting 关于显示结果的，汇总每个进程的信息</li><li>name&#x3D;”TDSQL_4KB_read_test”  定义测试任务名称<br>扩展</li><li>lockmem&#x3D;1g       只使用1g内存进行测试</li><li>zero_buffers     用全0初始化缓冲区，默认是用随机数据填充缓冲区</li><li>random_distribution&#x3D;random    #默认情况下，fio 会在询问时使用完全均匀的随机分布，有需要的话可以自定义访问区域，zipf、pareto、normal、zoned</li><li>nrfiles&#x3D;8        每个进程生成文件的数量</li></ul><h2 id="测试场景示例"><a href="#测试场景示例" class="headerlink" title="测试场景示例"></a>测试场景示例</h2><p>100%随机读，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randread -group_reporting -name=<span class="string">&quot;TDSQL_4KB_randread_test&quot;</span></span><br></pre></td></tr></table></figure><p>100%顺序读，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=<span class="built_in">read</span> -group_reporting -name=<span class="string">&quot;TDSQL_4KB_write_test&quot;</span></span><br></pre></td></tr></table></figure><p>70%随机读，30%随机写，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=<span class="string">&quot;TDSQL_4KB_randread70-write_test&quot;</span></span><br></pre></td></tr></table></figure><p>70%顺序读，30%随机写，5G大小，4k块文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=rw -rwmixread=70 -group_reporting -name=<span class="string">&quot;TDSQL_4KB_read70-write_test&quot;</span></span><br></pre></td></tr></table></figure><h2 id="输出报告"><a href="#输出报告" class="headerlink" title="输出报告"></a>输出报告</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]# fio -filename=/dev/sdb -direct=1 -ioengine=libaio -bs=4k -size=5G -numjobs=10 -iodepth=16 -runtime=60 -thread -rw=randrw -rwmixread=70 -group_reporting -name=<span class="string">&quot;local_randrw_test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">local_randrw_test: (g=0): rw=randrw, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16</span><br><span class="line">...</span><br><span class="line">fio-3.10</span><br><span class="line">Starting 10 threads</span><br><span class="line">Jobs: 10 (f=10): [m(10)][100.0%][r=19.4MiB/s,w=8456KiB/s][r=4969,w=2114 IOPS][eta 00m:00s]</span><br><span class="line">local_randrw_test: (groupid=0, <span class="built_in">jobs</span>=10): err= 0: pid=11189: Mon Oct 25 11:01:46 2021</span><br><span class="line">   <span class="built_in">read</span>: IOPS=5230, BW=20.4MiB/s (21.4MB/s)(1226MiB/60031msec)</span><br><span class="line">    slat (usec): min=2, max=342637, avg=1266.82, stdev=7241.29</span><br><span class="line">    clat (usec): min=4, max=459544, avg=20056.81, stdev=24888.90</span><br><span class="line">     lat (usec): min=134, max=459586, avg=21329.16, stdev=25378.16</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  1467],  5.00th=[  1844], 10.00th=[  2147], 20.00th=[  2606],</span><br><span class="line">     | 30.00th=[  3032], 40.00th=[  3556], 50.00th=[  4359], 60.00th=[  6063],</span><br><span class="line">     | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507],</span><br><span class="line">     | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[152044],</span><br><span class="line">     | 99.99th=[219153]</span><br><span class="line">   bw (  KiB/s): min=  795, max= 4494, per=9.91%, avg=2072.23, stdev=744.04, samples=1195</span><br><span class="line">   iops        : min=  198, max= 1123, avg=517.74, stdev=186.00, samples=1195</span><br><span class="line">  write: IOPS=2243, BW=8972KiB/s (9188kB/s)(526MiB/60031msec)</span><br><span class="line">    slat (usec): min=2, max=311932, avg=1272.76, stdev=7272.09</span><br><span class="line">    clat (usec): min=6, max=458031, avg=20206.30, stdev=24897.71</span><br><span class="line">     lat (usec): min=974, max=459755, avg=21484.12, stdev=25400.41</span><br><span class="line">    clat percentiles (usec):</span><br><span class="line">     |  1.00th=[  1500],  5.00th=[  1860], 10.00th=[  2147], 20.00th=[  2606],</span><br><span class="line">     | 30.00th=[  3064], 40.00th=[  3621], 50.00th=[  4424], 60.00th=[  6194],</span><br><span class="line">     | 70.00th=[ 36439], 80.00th=[ 46924], 90.00th=[ 51643], 95.00th=[ 59507],</span><br><span class="line">     | 99.00th=[105382], 99.50th=[117965], 99.90th=[137364], 99.95th=[149947],</span><br><span class="line">     | 99.99th=[200279]</span><br><span class="line">   bw (  KiB/s): min=  357, max= 1944, per=9.90%, avg=888.57, stdev=325.49, samples=1195</span><br><span class="line">   iops        : min=   89, max=  486, avg=221.80, stdev=81.37, samples=1195</span><br><span class="line">  lat (usec)   : 10=0.01%, 50=0.01%, 100=0.01%, 250=0.02%, 500=0.01%</span><br><span class="line">  lat (usec)   : 750=0.01%, 1000=0.01%</span><br><span class="line">  lat (msec)   : 2=7.45%, 4=38.36%, 10=18.10%, 20=1.09%, 50=22.31%</span><br><span class="line">  lat (msec)   : 100=11.42%, 250=1.24%, 500=0.01%</span><br><span class="line">  cpu          : usr=0.26%, sys=19.41%, ctx=12026, majf=0, minf=18</span><br><span class="line">  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=100.0%, 32=0.0%, &gt;=64=0.0%</span><br><span class="line">     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, &gt;=64=0.0%</span><br><span class="line">     issued rwts: total=313975,134655,0,0 short=0,0,0,0 dropped=0,0,0,0</span><br><span class="line">     latency   : target=0, window=0, percentile=100.00%, depth=16</span><br><span class="line"></span><br><span class="line">Run status group 0 (all <span class="built_in">jobs</span>):</span><br><span class="line">   READ: bw=20.4MiB/s (21.4MB/s), 20.4MiB/s-20.4MiB/s (21.4MB/s-21.4MB/s), io=1226MiB (1286MB), run=60031-60031msec</span><br><span class="line">  WRITE: bw=8972KiB/s (9188kB/s), 8972KiB/s-8972KiB/s (9188kB/s-9188kB/s), io=526MiB (552MB), run=60031-60031msec</span><br><span class="line"></span><br><span class="line">Disk stats (<span class="built_in">read</span>/write):</span><br><span class="line">  sdb: ios=314008/134653, merge=0/0, ticks=189470/89778, in_queue=279286, util=99.75%</span><br></pre></td></tr></table></figure><p>输出报告分析<br>下面是每个执行的数据方向的I&#x2F;O统计数据信息的代表值含义</p><ul><li><p>read&#x2F;write： 读&#x2F;写的IO操作（还有一个trim没用过）</p><ul><li>salt： 提交延迟，这是提交I&#x2F;O所花费的时间（min:最小值，max:最大值，avg:平均值，stdev:标准偏差）</li><li>chat： 完成延迟，表示从提交到完成I&#x2F;O部分的时间</li><li>lat： 相应时间，表示从fio创建I&#x2F;O单元到完成I&#x2F;O操作的时间</li><li>bw： 带宽统计</li><li>iops： IOPS统计</li></ul></li><li><p>lat(nsec&#x2F;usec&#x2F;msec)： I&#x2F;O完成延迟的分布。这是从I&#x2F;O离开fio到它完成的时间。与上面单独的读&#x2F;写&#x2F;修剪部分不同，这里和其余部分的数据适用于报告组的所有I&#x2F; o。10&#x3D;0.01%意味着0.01%的I&#x2F;O在250us以下完成。250&#x3D;0.02%意味着0.02%的I&#x2F;O需要10到250us才能完成。</p></li><li><p>cpu： cpu使用率</p></li><li><p>IO depths： I&#x2F;O深度在作业生命周期中的分布</p><ul><li>IO submit： 在一个提交调用中提交了多少个I&#x2F;O。每一个分录表示该数额及其以下，直到上一分录为止——例如，4&#x3D;100%意味着我们每次提交0到4个I&#x2F;O调用</li><li>IO complete： 和上边的submit一样，不过这个是完成了多少个</li><li>IO issued rwt： 发出的read&#x2F;write&#x2F;trim请求的数量，以及其中有多少请求被缩短或删除</li><li>IO latency： 满足指定延迟目标所需的I&#x2F;O深度</li></ul></li><li><p>bw： 总带宽以及最小和最大带宽</p></li><li><p>io： 该组中所有线程执行的累计I&#x2F;O</p></li><li><p>run： 这组线程中最小和最长的运行时。</p></li><li><p>ios： 所有组的I&#x2F; o个数</p></li><li><p>merge： I&#x2F;O调度器执行的总合并数</p></li><li><p>ticks： 使磁盘繁忙的滴答数（仅供参考，原文是Number of ticks we kept the disk busy）</p></li><li><p>in_queue： 在磁盘队列中花费的总时间</p></li><li><p>util： 磁盘利用率。值为100%意味着我们保留了磁盘，如果一直很忙，那么50%的时间磁盘就会闲置一半的时间</p></li></ul><h2 id="FIO通过配置文件运行"><a href="#FIO通过配置文件运行" class="headerlink" title="FIO通过配置文件运行"></a>FIO通过配置文件运行</h2><p>除了命令行直接执行命令外，也可以通过写配置到xxx.fio文件中，每次只用修改配置即可，使用更方便些，执行方式为fio xxx.fio</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">jobs</span>]# <span class="built_in">cat</span> test.fio</span><br><span class="line">[global]</span><br><span class="line">filename=/dev/sdb</span><br><span class="line">ioengine=libaio</span><br><span class="line">direct=1</span><br><span class="line">thread</span><br><span class="line">group_reporting</span><br><span class="line"></span><br><span class="line">[randread-4k-128M]</span><br><span class="line">rw=randread</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line">[randwrite-4k-128M]</span><br><span class="line">rw=randwrite</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line">[write-4k-128M]</span><br><span class="line">rw=write</span><br><span class="line">bs=4k</span><br><span class="line">size=128M</span><br><span class="line">numjobs=5</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行fio命令测试</span></span><br><span class="line">[root@localhost <span class="built_in">jobs</span>]# fio test.fio</span><br><span class="line">randread-4k-128M: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">randwrite-4k-128M: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">write-4k-128M: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.10</span><br><span class="line">Starting 15 threads</span><br><span class="line">Jobs: 6 (f=6): [_(3),r(1),_(1),w(5),E(1),_(4)][92.1%][r=10.8MiB/s,w=29.2MiB/s][r=2777,w=7483 IOPS][eta 00m:05s]</span><br></pre></td></tr></table></figure><h2 id="性能关注的重点"><a href="#性能关注的重点" class="headerlink" title="性能关注的重点"></a>性能关注的重点</h2><ol><li><strong>顺序读写和随机读写</strong>：顺序读写指对大块数据进行读写操作，随机读写则是对随机位置的小块数据进行读写操作。顺序读写通常比随机读写更快，因为它可以利用SSD的顺序读写优势。然而，随机读写需要处理更多的数据以找到所需数据，因此其IOPS和带宽通常低于顺序读写。</li><li><strong>SSD与HDD性能比较</strong>：<ul><li><strong>HDD</strong>：顺硬盘驱动器 (HDD) 的顺序读写和随机读写性能是不同的。顺序读写操作是指读写大块连续的数据，这是硬盘驱动器的强项。因为磁头可以直接读写连续的数据块，因此顺序读写速度快。随机读写操作是指读写随机位置的小块数据，这是硬盘驱动器的弱点。因为磁头需要频繁移动以读写不同的数据块，因此随机读写速度较慢。因此，硬盘驱动器的顺序读写速度通常比随机读写速度快。在评估硬盘驱动器性能时，需要考虑两种读写方式的结果。</li><li><strong>SSD</strong>：SSD 具有很高的随机读写性能，但顺序读写性能仍然不如随机读写性能。因为 SSD 需要管理大量的块，因此对大块连续的数据的读写可能不如对随机位置的小块数据的读写快。但需要注意的是，SSD 的顺序读写性能仍然高于硬盘驱动器 (HDD)。因此，即使是 SSD 的顺序读写性能不如随机读写性能，它仍然具有很高的性能。</li></ul></li></ol><h3 id="测试配置建议"><a href="#测试配置建议" class="headerlink" title="测试配置建议"></a>测试配置建议</h3><ol><li><strong>numjobs和iodepth设置</strong>：<ul><li>numjobs过大可能导致任务等待时间过长，建议设置为1、2、4、8。</li><li>iodepth可以设置大一些，建议为64、128，以增加IO任务队列。</li></ul></li><li><strong>利用率观察</strong>：通过<code>iostat -x -m 5 /dev/sdb</code>查看磁盘的utilize是否达到百分百。如果未达到，可继续增加numjobs直到utilize达到百分百。</li><li><strong>关闭写缓存</strong>：<ul><li>关闭写缓存可以提高数据持久性测试的准确性。</li><li>使用<code>hdparm -W /dev/device</code>查看当前状态，<code>hdparm -W 0 /dev/device</code>关闭写缓存。</li></ul></li></ol><h3 id="其他建议"><a href="#其他建议" class="headerlink" title="其他建议"></a>其他建议</h3><ol><li><strong>获取设备信息</strong>：使用<code>smartctl -a /dev/device</code>获取设备型号、连接版本和速度。</li><li><strong>numjobs大小</strong>:FIO的多线程调度其实还是一个进程，numjobs过大的话会导致任务等待时间过长，任务一直在排队。numjobs不能开太大，建议是1、2、4、8；iodepth任务可以开大点，建议是64、128，因为队列任务相当于IO任务，进行压测时，numjobs从1、2、4、8往上调，同时使用<code>iostat -x -m 5 /dev/sdb</code>查看磁盘的utilize是否达到百分百；如果当前numjobs的utilize还不是百分百，表示不是压测，numjobs再往上加，直到utilize达到百分百为止。</li><li><strong>多个fio进程测一个SSD和一个fio进程多线程测一个SSD的区别</strong><ul><li>多个fio进程测一个SSD和一个fio进程多线程测一个SSD的主要区别在于并发性和资源利用率。多个fio进程可以并发地访问SSD并生成更多的负载，这可以更好地测试SSD的并行读写能力和响应时间，但同时也会占用更多的CPU和内存资源。此外，由于多个fio进程之间的I&#x2F;O请求存在竞争关系，可能会影响测试结果的准确性和一致性。</li><li>相比之下，一个fio进程多线程测一个SSD可以更好地利用系统资源并模拟真实的应用程序I&#x2F;O模式。在这种情况下，每个线程可以并发地访问SSD并生成负载，同时避免了多个fio进程之间的竞争关系。这可以更好地测试SSD的性能和稳定性，并提供更准确的测试结果。</li><li>总的来说，两种方法都有其优缺点和适用场景。需要根据实际情况选择适当的测试方法来评估SSD的性能和可靠性。</li></ul></li><li><strong>磁盘性能摸底时需要关闭写缓存？</strong><ul><li>在使用fio进行性能测试时，是否需要关闭写缓存取决于具体的测试需求和测试方案。如果测试场景需要模拟真实应用程序中的写操作，并希望测试结果反映出SSD的真实性能水平，那么建议关闭写缓存，以便更准确地衡量SSD的写性能和数据持久性。然而，在某些情况下，为了测试SSD的I&#x2F;O性能而不是数据持久性，或者为了测试SSD的读性能，可能需要保持写缓存打开。因此，是否需要关闭写缓存取决于具体的测试需求和测试方案，需要根据实际情况进行决定。</li><li>关闭写缓存会使得磁盘的性能更具可预测性，因为每次写入都会立即被持久化到磁盘上，可以更准确地测试磁盘的写入性能和数据持久性。然而，关闭写缓存会使得写入操作变慢，因为每个写入操作都必须等待磁盘确认数据已经被永久写入。</li><li>不关闭写缓存会使得磁盘的写入性能更高，因为数据可以先被缓存起来，减少了写入操作对磁盘的访问次数，从而提高了写入性能。然而，数据可能会在缓存中存储一段时间，而不是立即写入磁盘，这可能会导致数据丢失或不一致。</li></ul></li></ol><p>通过合理配置fio参数，可以有效测试存储系统的性能。需要根据实际需求选择适当的测试方法和参数设置，确保测试结果的准确性和代表性。在测试过程中，需特别注意顺序读写和随机读写性能的差异，以及SSD和HDD在不同读写模式下的表现。</p><h1 id="Ceph-Rados性能测试工具"><a href="#Ceph-Rados性能测试工具" class="headerlink" title="Ceph Rados性能测试工具"></a>Ceph Rados性能测试工具</h1><p>Ceph 提供了 <code>rados bench</code> 和 <code>rados load-gen</code> 两个命令，用于测试和评估集群的性能。以下是这两个命令的用法和选项。</p><h2 id="rados-bench-命令"><a href="#rados-bench-命令" class="headerlink" title="rados bench 命令"></a>rados bench 命令</h2><p><code>rados bench</code> 命令用于对 Ceph 集群进行基准测试，以评估集群的读写性能。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench &#123;seconds&#125; &#123;operation&#125; [options]</span><br></pre></td></tr></table></figure><h3 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h3><ul><li><code>&#123;seconds&#125;</code>：测试运行的持续时间，单位为秒。</li><li><code>&#123;operation&#125;</code>：指定测试的操作类型，包括 <code>write</code>、<code>seq</code>（顺序读）、<code>rand</code>（随机读）。</li></ul><h3 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li><code>-p &#123;pool&#125;</code> 或 <code>--pool &#123;pool&#125;</code>：指定使用的存储池名称。</li><li><code>-b &#123;block_size&#125;</code> 或 <code>--block-size &#123;block_size&#125;</code>：指定块大小，默认值为 4MB。</li><li><code>-t &#123;threads&#125;</code> 或 <code>--threads &#123;threads&#125;</code>：指定使用的线程数，默认值为 16。</li><li><code>-n &#123;num_objects&#125;</code> 或 <code>--num-objects &#123;num_objects&#125;</code>：指定创建的对象数量。</li><li><code>-c</code> 或 <code>--no-cleanup</code>：在测试结束后保留测试数据。</li><li><code>-D</code> 或 <code>--verify</code>：启用数据验证。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="写入测试"><a href="#写入测试" class="headerlink" title="写入测试"></a>写入测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 write --pool testpool</span><br></pre></td></tr></table></figure><h4 id="顺序读测试"><a href="#顺序读测试" class="headerlink" title="顺序读测试"></a>顺序读测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 <span class="built_in">seq</span> --pool testpool</span><br></pre></td></tr></table></figure><h4 id="随机读测试"><a href="#随机读测试" class="headerlink" title="随机读测试"></a>随机读测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 rand --pool testpool</span><br></pre></td></tr></table></figure><h4 id="使用自定义块大小和线程数"><a href="#使用自定义块大小和线程数" class="headerlink" title="使用自定义块大小和线程数"></a>使用自定义块大小和线程数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados bench 60 write --pool testpool --block-size 8192 --threads 32</span><br></pre></td></tr></table></figure><h2 id="rados-load-gen-命令"><a href="#rados-load-gen-命令" class="headerlink" title="rados load-gen 命令"></a>rados load-gen 命令</h2><p><code>rados load-gen</code> 命令用于生成负载，以测试和评估 Ceph 集群在不同负载下的性能。</p><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen [options]</span><br></pre></td></tr></table></figure><h3 id="常用选项-1"><a href="#常用选项-1" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li><code>-b &#123;bytes&#125;</code> 或 <code>--block-size &#123;bytes&#125;</code>：指定块大小，默认值为 4096 字节。</li><li><code>-t &#123;threads&#125;</code> 或 <code>--threads &#123;threads&#125;</code>：指定使用的线程数，默认值为 16。</li><li><code>-o &#123;objects&#125;</code> 或 <code>--objects &#123;objects&#125;</code>：指定创建的对象数量，默认值为 100。</li><li><code>-p &#123;pool&#125;</code> 或 <code>--pool &#123;pool&#125;</code>：指定使用的存储池名称，默认值为 <code>rbd</code>。</li><li><code>-c &#123;clients&#125;</code> 或 <code>--clients &#123;clients&#125;</code>：指定客户端数量，默认值为 1。</li><li><code>-d &#123;seconds&#125;</code> 或 <code>--duration &#123;seconds&#125;</code>：指定测试运行的持续时间，单位为秒。</li><li><code>--num-objects</code>：指定对象的总数</li><li><code>--min-object-size</code>：指定最小object尺寸</li><li><code>--max-object-size</code>：指定最大object尺寸</li><li><code>--min-op-len</code>：指定操作的最小 io 长度</li><li><code>--max-op-len</code>：指定操作的最大 io 长度</li><li><code>--max-ops</code>：指定最大操作数</li><li><code>--max-backlog</code>：指定最大压测规模</li><li><code>--read-percent</code>：指定读取操作的百分比</li><li><code>--target-throughput</code>：指定目标吞吐量（以字节为单位）</li><li><code>--run-length</code>：指定总时间（以秒为单位）</li></ul><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><h4 id="使用默认参数测试"><a href="#使用默认参数测试" class="headerlink" title="使用默认参数测试"></a>使用默认参数测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen</span><br></pre></td></tr></table></figure><h4 id="指定块大小和对象数量测试"><a href="#指定块大小和对象数量测试" class="headerlink" title="指定块大小和对象数量测试"></a>指定块大小和对象数量测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --block-size 8192 --objects 500</span><br></pre></td></tr></table></figure><h4 id="在指定存储池中测试"><a href="#在指定存储池中测试" class="headerlink" title="在指定存储池中测试"></a>在指定存储池中测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --pool mypool</span><br></pre></td></tr></table></figure><h4 id="使用多个线程和客户端测试"><a href="#使用多个线程和客户端测试" class="headerlink" title="使用多个线程和客户端测试"></a>使用多个线程和客户端测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --threads 32 --clients 4</span><br></pre></td></tr></table></figure><h4 id="指定时间的测试"><a href="#指定时间的测试" class="headerlink" title="指定时间的测试"></a>指定时间的测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados load-gen --duration 60</span><br></pre></td></tr></table></figure><h4 id="指定object大小范围的测试"><a href="#指定object大小范围的测试" class="headerlink" title="指定object大小范围的测试"></a>指定object大小范围的测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p hdd_pool load-gen --num-objects 200 --min-object-size 4K --max-object-size 4M --max-ops 20 --read-percent 0 --min-op-len 4K --max-op-len 1M --target-throughput 20G --run-length 20 --num-threads 64</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;FIO简介&quot;&gt;&lt;a href=&quot;#FIO简介&quot; class=&quot;headerlink&quot; title=&quot;FIO简介&quot;&gt;&lt;/a&gt;FIO简介&lt;/h2&gt;&lt;p&gt;FIO是Linux下开源的一款IOPS测试工具，主要用来对磁盘进行压力测试和性能验证。它可以产生许多线程或进程来执行</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>rbd相关运维命令</title>
    <link href="https://watsonlu6.github.io/rbd%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/"/>
    <id>https://watsonlu6.github.io/rbd%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</id>
    <published>2021-09-22T16:31:00.000Z</published>
    <updated>2024-08-02T17:38:43.819Z</updated>
    
    <content type="html"><![CDATA[<h1 id="rbd-服务管理指南"><a href="#rbd-服务管理指南" class="headerlink" title="rbd 服务管理指南"></a>rbd 服务管理指南</h1><h4 id="创建-rbd-镜像"><a href="#创建-rbd-镜像" class="headerlink" title="创建 rbd 镜像"></a>创建 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rbd create &#123;pool-name&#125;/&#123;image-name&#125; [--size &#123;size&#125;] [--image-format &#123;format&#125;] [--features &#123;feature-list&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>参数说明</p><ul><li>{pool-name}&#x2F;{image-name}：指定存储池名称和镜像名称。</li><li>–size {size}：设置镜像的大小。</li><li>–image-format {format}：指定镜像的格式。有效的格式包括 1（兼容旧版格式）和 2（支持更多特性）。</li><li>–features {feature-list}：启用镜像特性，特性名称之间用逗号分隔。例如，layering,exclusive-lock。</li></ul><h4 id="查看-rbd-镜像列表"><a href="#查看-rbd-镜像列表" class="headerlink" title="查看 rbd 镜像列表"></a>查看 rbd 镜像列表</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">ls</span> &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="获取-rbd-镜像信息"><a href="#获取-rbd-镜像信息" class="headerlink" title="获取 rbd 镜像信息"></a>获取 rbd 镜像信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd info &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="删除-rbd-镜像"><a href="#删除-rbd-镜像" class="headerlink" title="删除 rbd 镜像"></a>删除 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="映射-rbd-镜像到本地设备"><a href="#映射-rbd-镜像到本地设备" class="headerlink" title="映射 rbd 镜像到本地设备"></a>映射 rbd 镜像到本地设备</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd map &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="取消映射-rbd-镜像"><a href="#取消映射-rbd-镜像" class="headerlink" title="取消映射 rbd 镜像"></a>取消映射 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd unmap /dev/rbd/&#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="扩展-rbd-镜像大小"><a href="#扩展-rbd-镜像大小" class="headerlink" title="扩展 rbd 镜像大小"></a>扩展 rbd 镜像大小</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd resize &#123;pool-name&#125;/&#123;image-name&#125; --size &#123;new-size-in-MB&#125;</span><br></pre></td></tr></table></figure><h4 id="从ceph导出-RBD-镜像"><a href="#从ceph导出-RBD-镜像" class="headerlink" title="从ceph导出 RBD 镜像"></a>从ceph导出 RBD 镜像</h4><p>用于将镜像的数据导出到一个本地文件中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">export</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;output-file&#125;</span><br></pre></td></tr></table></figure><h4 id="向ceph导入-RBD-镜像"><a href="#向ceph导入-RBD-镜像" class="headerlink" title="向ceph导入 RBD 镜像"></a>向ceph导入 RBD 镜像</h4><p>用于将本地文件导入到ceph rbd中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd import &#123;input-file&#125; &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用rbd特性"><a href="#启用rbd特性" class="headerlink" title="启用rbd特性"></a>启用rbd特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125;</span><br></pre></td></tr></table></figure><p><strong>rbd镜像特性</strong></p><ul><li>layering：支持图层（Layering）</li><li>exclusive-lock：独占锁（Exclusive Locking）</li><li>object-map：对象映射（Object Map）</li></ul><h4 id="禁用rbd特性"><a href="#禁用rbd特性" class="headerlink" title="禁用rbd特性"></a>禁用rbd特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;feature-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用和禁用所有特性"><a href="#启用和禁用所有特性" class="headerlink" title="启用和禁用所有特性"></a>启用和禁用所有特性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rbd feature <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; --all</span><br><span class="line">rbd feature <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125; --all</span><br></pre></td></tr></table></figure><h4 id="RBD-复制命令"><a href="#RBD-复制命令" class="headerlink" title="RBD 复制命令"></a>RBD 复制命令</h4><p>用于复制 RBD 镜像到同一存储池中的新镜像，或复制到不同存储池中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">cp</span> &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启RBD-深度复制命令"><a href="#启RBD-深度复制命令" class="headerlink" title="启RBD 深度复制命令"></a>启RBD 深度复制命令</h4><p>用于执行深度复制，包括镜像的所有快照和元数据。这个命令是 RADOS 镜像的完整复制工具。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd deep-copy &#123;source-pool-name&#125;/&#123;source-image-name&#125; &#123;destination-pool-name&#125;/&#123;destination-image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-差异命令"><a href="#RBD-差异命令" class="headerlink" title="RBD 差异命令"></a>RBD 差异命令</h4><p>用于查看两个 RBD 镜像之间的差异，包括哪些块已更改、已删除或已新增。它可以帮助识别镜像之间的更改。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd diff &#123;pool-name&#125;/&#123;image-name&#125; [--snap &#123;snapshot-name&#125;] [--diff &#123;other-image&#125;]</span><br></pre></td></tr></table></figure><h4 id="RBD-磁盘使用命令"><a href="#RBD-磁盘使用命令" class="headerlink" title="RBD 磁盘使用命令"></a>RBD 磁盘使用命令</h4><p>用于显示 RBD 镜像的磁盘使用情况，包括镜像占用的总磁盘空间和其他相关信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">du</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-状态命令"><a href="#RBD-状态命令" class="headerlink" title="RBD 状态命令"></a>RBD 状态命令</h4><p>用于显示 RBD 镜像的状态信息，包括镜像的健康状态和其他相关信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd status &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-观察命令"><a href="#RBD-观察命令" class="headerlink" title="RBD 观察命令"></a>RBD 观察命令</h4><p>用于观察镜像的实时更改，这个命令允许用户跟踪镜像的变化，包括数据的写入、删除和其他操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd watch &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="RBD-稀疏化命令"><a href="#RBD-稀疏化命令" class="headerlink" title="RBD 稀疏化命令"></a>RBD 稀疏化命令</h4><p>用于将 RBD 镜像的已分配但未使用的空间标记为稀疏。通过稀疏化，可以释放磁盘上未使用的空间，从而优化存储资源。<br><strong>注意事项</strong></p><ul><li>影响：稀疏化操作会扫描镜像并更新其内部元数据，可能会占用一定的 I&#x2F;O 带宽和计算资源。</li><li>稀疏化条件：只有在镜像的写入操作完成后，才建议执行稀疏化，以避免在镜像空间仍在使用时进行操作。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd sparsify &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="创建-rbd-快照"><a href="#创建-rbd-快照" class="headerlink" title="创建 rbd 快照"></a>创建 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap create &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h4 id="保护-rbd-快照"><a href="#保护-rbd-快照" class="headerlink" title="保护 rbd 快照"></a>保护 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap protect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125;</span><br></pre></td></tr></table></figure><h4 id="取消保护-rbd-快照"><a href="#取消保护-rbd-快照" class="headerlink" title="取消保护 rbd 快照"></a>取消保护 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap unprotect &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snapshot-name&#125;</span><br></pre></td></tr></table></figure><h4 id="列出-rbd-快照"><a href="#列出-rbd-快照" class="headerlink" title="列出 rbd 快照"></a>列出 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap <span class="built_in">ls</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="回滚到-rbd-快照"><a href="#回滚到-rbd-快照" class="headerlink" title="回滚到 rbd 快照"></a>回滚到 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap rollback &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h4 id="删除-rbd-快照"><a href="#删除-rbd-快照" class="headerlink" title="删除 rbd 快照"></a>删除 rbd 快照</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd snap <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;</span><br></pre></td></tr></table></figure><h2 id="rbd-trash"><a href="#rbd-trash" class="headerlink" title="rbd trash"></a>rbd trash</h2><p>rbd trash 功能允许管理员在删除 rbd 镜像时先将其移动到 trash，而不是立即永久删除。这为误删除的镜像提供了恢复的机会。以下是 rbd trash 的详细说明和常用操作指南。<br>rbd trash 功能的主要特点包括：</p><ul><li>安全性：防止意外删除镜像。</li><li>可恢复性：在一定时间内可以恢复已删除的镜像。</li><li>定期清理：可以设置镜像在 trash 中的过期时间，自动清理过期的镜像。</li></ul><h4 id="查看-rbd-trash-中的镜像"><a href="#查看-rbd-trash-中的镜像" class="headerlink" title="查看 rbd trash 中的镜像"></a>查看 rbd trash 中的镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">ls</span> &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="将-rbd-镜像移动到-trash"><a href="#将-rbd-镜像移动到-trash" class="headerlink" title="将 rbd 镜像移动到 trash"></a>将 rbd 镜像移动到 trash</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">mv</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="恢复-trash-中的-rbd-镜像"><a href="#恢复-trash-中的-rbd-镜像" class="headerlink" title="恢复 trash 中的 rbd 镜像"></a>恢复 trash 中的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash restore &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="永久删除-trash-中的-rbd-镜像"><a href="#永久删除-trash-中的-rbd-镜像" class="headerlink" title="永久删除 trash 中的 rbd 镜像"></a>永久删除 trash 中的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看-trash-中镜像的详细信息"><a href="#查看-trash-中镜像的详细信息" class="headerlink" title="查看 trash 中镜像的详细信息"></a>查看 trash 中镜像的详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash info &#123;pool-name&#125;/&#123;image-id or image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="设置-trash-镜像的过期时间"><a href="#设置-trash-镜像的过期时间" class="headerlink" title="设置 trash 镜像的过期时间"></a>设置 trash 镜像的过期时间</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash <span class="built_in">mv</span> &#123;pool-name&#125;/&#123;image-name&#125; --expire &#123;time-spec&#125;</span><br></pre></td></tr></table></figure><p>其中，<code>&#123;time-spec&#125;</code> 可以是以下格式之一：</p><ul><li><code>1d</code>：1天</li><li><code>1h</code>：1小时</li><li><code>1m</code>：1分钟</li></ul><h4 id="查看-trash-镜像的过期时间"><a href="#查看-trash-镜像的过期时间" class="headerlink" title="查看 trash 镜像的过期时间"></a>查看 trash 镜像的过期时间</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash list &#123;pool-name&#125; --long</span><br></pre></td></tr></table></figure><h4 id="清空-trash"><a href="#清空-trash" class="headerlink" title="清空 trash"></a>清空 trash</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd trash purge &#123;pool-name&#125;</span><br></pre></td></tr></table></figure><h4 id="克隆-rbd-镜像"><a href="#克隆-rbd-镜像" class="headerlink" title="克隆 rbd 镜像"></a>克隆 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd <span class="built_in">clone</span> &#123;pool-name&#125;/&#123;parent-image&#125;@&#123;snap-name&#125; &#123;pool-name&#125;/&#123;clone-name&#125;</span><br></pre></td></tr></table></figure><h4 id="合并克隆的-rbd-镜像"><a href="#合并克隆的-rbd-镜像" class="headerlink" title="合并克隆的 rbd 镜像"></a>合并克隆的 rbd 镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd flatten &#123;pool-name&#125;/&#123;clone-name&#125;</span><br></pre></td></tr></table></figure><h4 id="启用镜像同步"><a href="#启用镜像同步" class="headerlink" title="启用镜像同步"></a>启用镜像同步</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image <span class="built_in">enable</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;mode&#125;</span><br></pre></td></tr></table></figure><h4 id="禁用镜像同步"><a href="#禁用镜像同步" class="headerlink" title="禁用镜像同步"></a>禁用镜像同步</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image <span class="built_in">disable</span> &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看镜像同步状态"><a href="#查看镜像同步状态" class="headerlink" title="查看镜像同步状态"></a>查看镜像同步状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd mirror image status &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="查看镜像配置"><a href="#查看镜像配置" class="headerlink" title="查看镜像配置"></a>查看镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image list &#123;pool-name&#125;/&#123;image-name&#125;</span><br></pre></td></tr></table></figure><h4 id="修改镜像配置"><a href="#修改镜像配置" class="headerlink" title="修改镜像配置"></a>修改镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image <span class="built_in">set</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125; &#123;value&#125;</span><br></pre></td></tr></table></figure><h4 id="删除镜像配置"><a href="#删除镜像配置" class="headerlink" title="删除镜像配置"></a>删除镜像配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd config image <span class="built_in">rm</span> &#123;pool-name&#125;/&#123;image-name&#125; &#123;config-key&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;rbd-服务管理指南&quot;&gt;&lt;a href=&quot;#rbd-服务管理指南&quot; class=&quot;headerlink&quot; title=&quot;rbd 服务管理指南&quot;&gt;&lt;/a&gt;rbd 服务管理指南&lt;/h1&gt;&lt;h4 id=&quot;创建-rbd-镜像&quot;&gt;&lt;a href=&quot;#创建-rbd-镜像&quot; c</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph相关运维命令</title>
    <link href="https://watsonlu6.github.io/Ceph%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/"/>
    <id>https://watsonlu6.github.io/Ceph%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4/</id>
    <published>2021-09-07T12:01:00.000Z</published>
    <updated>2024-08-02T17:38:18.260Z</updated>
    
    <content type="html"><![CDATA[<h4 id="查看-Ceph-的守护进程"><a href="#查看-Ceph-的守护进程" class="headerlink" title="查看 Ceph 的守护进程"></a>查看 Ceph 的守护进程</h4><p>使用以下命令查看所有 Ceph 守护进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl list-unit-files | grep ceph</span><br></pre></td></tr></table></figure><h4 id="按类型在-Ceph-节点上启动特定类型的所有守护进程"><a href="#按类型在-Ceph-节点上启动特定类型的所有守护进程" class="headerlink" title="按类型在 Ceph 节点上启动特定类型的所有守护进程"></a>按类型在 Ceph 节点上启动特定类型的所有守护进程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start/restart/stop ceph-osd.target</span><br><span class="line">systemctl start/restart/stop ceph-mon.target</span><br><span class="line">systemctl start/restart/stop ceph-mds.target</span><br><span class="line">systemctl start/restart/stop ceph-radosgw.target</span><br></pre></td></tr></table></figure><h4 id="启动特定守护进程实例"><a href="#启动特定守护进程实例" class="headerlink" title="启动特定守护进程实例"></a>启动特定守护进程实例</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start/status/restart/stop ceph-osd@&#123;<span class="built_in">id</span>&#125;</span><br><span class="line">systemctl start/status/restart/stop ceph-mon@&#123;hostname&#125;</span><br><span class="line">systemctl start/status/restart/stop ceph-mds@&#123;hostname&#125;</span><br><span class="line">systemctl start/restart/stop ceph-radosgw@&#123;hostname&#125;</span><br></pre></td></tr></table></figure><h4 id="查看-Ceph-集群状态"><a href="#查看-Ceph-集群状态" class="headerlink" title="查看 Ceph 集群状态"></a>查看 Ceph 集群状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ceph health detail</span><br></pre></td></tr></table></figure><p>输出信息包括：</p><ul><li>集群的 ID</li><li>集群健康状况</li><li>monitor map 版本和 mon 法定人数状态</li><li>OSD map 版本和 OSD 状态摘要</li><li>PG map 版本</li><li>PG 和 Pool 的数量</li><li>集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量</li><li>客户端的 IOPS 信息</li></ul><h4 id="观察集群中的状态"><a href="#观察集群中的状态" class="headerlink" title="观察集群中的状态"></a>观察集群中的状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph -w</span><br></pre></td></tr></table></figure><p>输出信息包含：</p><ul><li>集群的 ID</li><li>集群健康状况</li><li>monitor map 版本和 mon 法定人数状态</li><li>OSD map 版本和 OSD 状态摘要</li><li>PG map 版本</li><li>PG 和 Pool 的数量</li><li>集群存储的数据量，对象的总量，以及集群的已用容量&#x2F;总容量&#x2F;可用容量</li><li>客户端的 IOPS 信息</li></ul><h4 id="检查集群的容量情况"><a href="#检查集群的容量情况" class="headerlink" title="检查集群的容量情况"></a>检查集群的容量情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph <span class="built_in">df</span></span><br></pre></td></tr></table></figure><h3 id="修改集群配置"><a href="#修改集群配置" class="headerlink" title="修改集群配置"></a>修改集群配置</h3><h4 id="查看默认配置"><a href="#查看默认配置" class="headerlink" title="查看默认配置"></a>查看默认配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph --show-config</span><br></pre></td></tr></table></figure><h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><p>Ceph 支持在运行时更改 ceph-osd、ceph-mon、ceph-mds 守护进程的配置。</p><h4 id="使用-tell-的方式"><a href="#使用-tell-的方式" class="headerlink" title="使用 tell 的方式"></a>使用 tell 的方式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ceph tell &#123;daemon-type&#125;.&#123;<span class="built_in">id</span> or *&#125; injectargs --&#123;name&#125; &#123;value&#125; [--&#123;name&#125; &#123;value&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：</span></span><br><span class="line">ceph tell osd.0 injectargs --debug-osd 20 --debug-ms 1</span><br></pre></td></tr></table></figure><h4 id="使用-daemon-的方式设置"><a href="#使用-daemon-的方式设置" class="headerlink" title="使用 daemon 的方式设置"></a>使用 daemon 的方式设置</h4><p>在设置的角色所在主机上进行设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看配置</span></span><br><span class="line">ceph daemon osd.1 config get mon_osd_full_ratio</span><br><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">ceph daemon osd.1 config <span class="built_in">set</span> mon_osd_full_ratio 0.97</span><br></pre></td></tr></table></figure><h4 id="在线调整日志级别"><a href="#在线调整日志级别" class="headerlink" title="在线调整日志级别"></a>在线调整日志级别</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph tell osd.0 injectargs --debug-osd 0/5</span><br></pre></td></tr></table></figure><h4 id="修改配置文件进行调整"><a href="#修改配置文件进行调整" class="headerlink" title="修改配置文件进行调整"></a>修改配置文件进行调整</h4><p>编辑 <code>/etc/ceph/ceph.conf</code> 中的 [global] 字段添加配置，重启相应服务生效。</p><h4 id="查看-mon-状态"><a href="#查看-mon-状态" class="headerlink" title="查看 mon 状态"></a>查看 mon 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph mon <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="查看-mon-的详细状态"><a href="#查看-mon-的详细状态" class="headerlink" title="查看 mon 的详细状态"></a>查看 mon 的详细状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon mon.ceph-xx-mon00 mon_status</span><br></pre></td></tr></table></figure><h4 id="mon-法定人数状态"><a href="#mon-法定人数状态" class="headerlink" title="mon 法定人数状态"></a>mon 法定人数状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph quorum_status -f json-pretty</span><br></pre></td></tr></table></figure><h4 id="查看-mon-选举状态"><a href="#查看-mon-选举状态" class="headerlink" title="查看 mon 选举状态"></a>查看 mon 选举状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph quorum_status</span><br></pre></td></tr></table></figure><h4 id="查看-mon-的映射信息"><a href="#查看-mon-的映射信息" class="headerlink" title="查看 mon 的映射信息"></a>查看 mon 的映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph mon dump</span><br></pre></td></tr></table></figure><h4 id="查看-mon-的-admin-socket"><a href="#查看-mon-的-admin-socket" class="headerlink" title="查看 mon 的 admin socket"></a>查看 mon 的 admin socket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-conf --name mon.ceph-xx-mon00 --show-config-value admin_socket</span><br><span class="line">/var/run/ceph/ceph-mon.ceph-xx-mon00.asok</span><br></pre></td></tr></table></figure><h2 id="CRUSH-Map"><a href="#CRUSH-Map" class="headerlink" title="CRUSH Map"></a>CRUSH Map</h2><h4 id="创建-bucket"><a href="#创建-bucket" class="headerlink" title="创建 bucket"></a>创建 bucket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush add-bucket host-xx host</span><br></pre></td></tr></table></figure><h4 id="移动-bucket"><a href="#移动-bucket" class="headerlink" title="移动 bucket"></a>移动 bucket</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush move host-xx room=default</span><br></pre></td></tr></table></figure><h4 id="提取-CRUSH-Map"><a href="#提取-CRUSH-Map" class="headerlink" title="提取 CRUSH Map"></a>提取 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd getcrushmap -o crush</span><br></pre></td></tr></table></figure><h4 id="反编译-crush-map"><a href="#反编译-crush-map" class="headerlink" title="反编译 crush map"></a>反编译 crush map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool -d crush -o de_crush </span><br></pre></td></tr></table></figure><h4 id="编译-crush-map"><a href="#编译-crush-map" class="headerlink" title="编译 crush map"></a>编译 crush map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool -c de_crush -o new_crush</span><br></pre></td></tr></table></figure><h4 id="测试新的-CRUSH-Map"><a href="#测试新的-CRUSH-Map" class="headerlink" title="测试新的 CRUSH Map"></a>测试新的 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crushtool --<span class="built_in">test</span> -i new_crush --num-rep 3 --rule 1 --show-mappings </span><br></pre></td></tr></table></figure><h4 id="注入-CRUSH-Map"><a href="#注入-CRUSH-Map" class="headerlink" title="注入 CRUSH Map"></a>注入 CRUSH Map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd setcrushmap -i new_crush</span><br></pre></td></tr></table></figure><h4 id="列出-crush-rule"><a href="#列出-crush-rule" class="headerlink" title="列出 crush_rule"></a>列出 crush_rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush rule <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><h4 id="查看-crush-rule"><a href="#查看-crush-rule" class="headerlink" title="查看 crush_rule"></a>查看 crush_rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd crush rule dump &#123;rule&#125;</span><br></pre></td></tr></table></figure><h2 id="PG-和-PGP"><a href="#PG-和-PGP" class="headerlink" title="PG 和 PGP"></a>PG 和 PGP</h2><h4 id="查看-PG-状态"><a href="#查看-PG-状态" class="headerlink" title="查看 PG 状态"></a>查看 PG 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="查看-PG-组映射信息"><a href="#查看-PG-组映射信息" class="headerlink" title="查看 PG 组映射信息"></a>查看 PG 组映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump</span><br></pre></td></tr></table></figure><h4 id="查看一个-PG-的-map"><a href="#查看一个-PG-的-map" class="headerlink" title="查看一个 PG 的 map"></a>查看一个 PG 的 map</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg map 1.2f6</span><br></pre></td></tr></table></figure><h4 id="查看-PG-详细信息"><a href="#查看-PG-详细信息" class="headerlink" title="查看 PG 详细信息"></a>查看 PG 详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg 1.2f6 query</span><br></pre></td></tr></table></figure><h4 id="显示集群所有-PG-统计"><a href="#显示集群所有-PG-统计" class="headerlink" title="显示集群所有 PG 统计"></a>显示集群所有 PG 统计</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump --format plain</span><br></pre></td></tr></table></figure><h4 id="显示非正常状态的-PG"><a href="#显示非正常状态的-PG" class="headerlink" title="显示非正常状态的 PG"></a>显示非正常状态的 PG</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph pg dump_stuck inactive|unclean|stale</span><br></pre></td></tr></table></figure><h2 id="OSD"><a href="#OSD" class="headerlink" title="OSD"></a>OSD</h2><h4 id="查看-OSD-状态"><a href="#查看-OSD-状态" class="headerlink" title="查看 OSD 状态"></a>查看 OSD 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">stat</span></span><br></pre></td></tr></table></figure><h4 id="检查-OSD-容量是否均衡"><a href="#检查-OSD-容量是否均衡" class="headerlink" title="检查 OSD 容量是否均衡"></a>检查 OSD 容量是否均衡</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">df</span> tree</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-映射信息"><a href="#查看-OSD-映射信息" class="headerlink" title="查看 OSD 映射信息"></a>查看 OSD 映射信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd dump</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-目录树"><a href="#查看-OSD-目录树" class="headerlink" title="查看 OSD 目录树"></a>查看 OSD 目录树</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd tree</span><br></pre></td></tr></table></figure><h4 id="定位-OSD-在集群中的节点位置"><a href="#定位-OSD-在集群中的节点位置" class="headerlink" title="定位 OSD 在集群中的节点位置"></a>定位 OSD 在集群中的节点位置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd find [osd]</span><br></pre></td></tr></table></figure><h4 id="查看对象在哪些-OSD-上"><a href="#查看对象在哪些-OSD-上" class="headerlink" title="查看对象在哪些 OSD 上"></a>查看对象在哪些 OSD 上</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd map test-pool object1</span><br></pre></td></tr></table></figure><h4 id="下线某个-OSD"><a href="#下线某个-OSD" class="headerlink" title="下线某个 OSD"></a>下线某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd down 0</span><br></pre></td></tr></table></figure><h4 id="拉起某个-OSD"><a href="#拉起某个-OSD" class="headerlink" title="拉起某个 OSD"></a>拉起某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd up 0</span><br></pre></td></tr></table></figure><h4 id="将某个-OSD-逐出集群"><a href="#将某个-OSD-逐出集群" class="headerlink" title="将某个 OSD 逐出集群"></a>将某个 OSD 逐出集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd out 0</span><br></pre></td></tr></table></figure><h4 id="将某个-OSD-加入集群"><a href="#将某个-OSD-加入集群" class="headerlink" title="将某个 OSD 加入集群"></a>将某个 OSD 加入集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="keyword">in</span> 0</span><br></pre></td></tr></table></figure><h4 id="删除某个-OSD"><a href="#删除某个-OSD" class="headerlink" title="删除某个 OSD"></a>删除某个 OSD</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd <span class="built_in">rm</span> 0</span><br></pre></td></tr></table></figure><h4 id="查看-OSD-延迟"><a href="#查看-OSD-延迟" class="headerlink" title="查看 OSD 延迟"></a>查看 OSD 延迟</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd perf</span><br></pre></td></tr></table></figure><h4 id="查看当前-OSD-的状态"><a href="#查看当前-OSD-的状态" class="headerlink" title="查看当前 OSD 的状态"></a>查看当前 OSD 的状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph daemon osd.14 perf dump</span><br></pre></td></tr></table></figure><h2 id="Pool"><a href="#Pool" class="headerlink" title="Pool"></a>Pool</h2><h4 id="查看-pool-信息"><a href="#查看-pool-信息" class="headerlink" title="查看 pool 信息"></a>查看 pool 信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd lspools</span><br></pre></td></tr></table></figure><h4 id="查看-pool-详细信息"><a href="#查看-pool-详细信息" class="headerlink" title="查看 pool 详细信息"></a>查看 pool 详细信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">ls</span> detail</span><br></pre></td></tr></table></figure><h4 id="查看-pool-状态"><a href="#查看-pool-状态" class="headerlink" title="查看 pool 状态"></a>查看 pool 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool stats</span><br></pre></td></tr></table></figure><h3 id="创建-pool"><a href="#创建-pool" class="headerlink" title="创建 pool"></a>创建 pool</h3><h4 id="创建副本-pool"><a href="#创建副本-pool" class="headerlink" title="创建副本 pool"></a>创建副本 pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; replicated &#123;crush-ruleset-name&#125; </span><br></pre></td></tr></table></figure><h4 id="创建-EC-pool"><a href="#创建-EC-pool" class="headerlink" title="创建 EC pool"></a>创建 EC pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create &#123;pool-name&#125; &#123;pg-num&#125; &#123;pgp-num&#125; erasure &#123;erasure-code-profile&#125;</span><br></pre></td></tr></table></figure><h4 id="创建-erasure-code-profile"><a href="#创建-erasure-code-profile" class="headerlink" title="创建 erasure-code-profile"></a>创建 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile <span class="built_in">set</span> ec-4-2 k=4 m=2 ruleset-failure-domain=host ruleset-root=hddRoom</span><br></pre></td></tr></table></figure><h4 id="列出-erasure-code-profile"><a href="#列出-erasure-code-profile" class="headerlink" title="列出 erasure-code-profile"></a>列出 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><h4 id="查看-erasure-code-profile"><a href="#查看-erasure-code-profile" class="headerlink" title="查看 erasure-code-profile"></a>查看 erasure-code-profile</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd erasure-code-profile get [name]</span><br></pre></td></tr></table></figure><h4 id="删除-pool"><a href="#删除-pool" class="headerlink" title="删除 pool"></a>删除 pool</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除 pool 前需要执行</span></span><br><span class="line">ceph tell mon.* injectargs --mon-allow-pool-delete=<span class="literal">true</span></span><br><span class="line"><span class="comment"># 删除pool</span></span><br><span class="line">ceph osd pool delete test_pool test_pool --yes-i-really-really-mean-it  <span class="comment">#pool的名字需要重复两次</span></span><br></pre></td></tr></table></figure><h4 id="设置-pool-的-PG-数量"><a href="#设置-pool-的-PG-数量" class="headerlink" title="设置 pool 的 PG 数量"></a>设置 pool 的 PG 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool pg_num 100</span><br></pre></td></tr></table></figure><h4 id="查看-pool-的-PG-数量"><a href="#查看-pool-的-PG-数量" class="headerlink" title="查看 pool 的 PG 数量"></a>查看 pool 的 PG 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool pg_num</span><br></pre></td></tr></table></figure><h4 id="设置-pool-的-PGP-数量"><a href="#设置-pool-的-PGP-数量" class="headerlink" title="设置 pool 的 PGP 数量"></a>设置 pool 的 PGP 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool pgp_num 100</span><br></pre></td></tr></table></figure><h4 id="查看-pool-的-PGP-数量"><a href="#查看-pool-的-PGP-数量" class="headerlink" title="查看 pool 的 PGP 数量"></a>查看 pool 的 PGP 数量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool pgp_num</span><br></pre></td></tr></table></figure><h4 id="设置-pool-池副本数"><a href="#设置-pool-池副本数" class="headerlink" title="设置 pool 池副本数"></a>设置 pool 池副本数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> test_pool size 3</span><br></pre></td></tr></table></figure><h4 id="查看-pool-池副本数"><a href="#查看-pool-池副本数" class="headerlink" title="查看 pool 池副本数"></a>查看 pool 池副本数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get test_pool size</span><br></pre></td></tr></table></figure><h4 id="设置存储池-crush-rule"><a href="#设置存储池-crush-rule" class="headerlink" title="设置存储池 crush rule"></a>设置存储池 crush rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool <span class="built_in">set</span> &lt;poolname&gt; crush_ruleset &lt;ruleset&gt;</span><br></pre></td></tr></table></figure><h4 id="查看存储池-crush-rule"><a href="#查看存储池-crush-rule" class="headerlink" title="查看存储池 crush rule"></a>查看存储池 crush rule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool get &lt;poolname&gt; crush_rule</span><br></pre></td></tr></table></figure><h2 id="RADOS"><a href="#RADOS" class="headerlink" title="RADOS"></a>RADOS</h2><h4 id="查看对象信息"><a href="#查看对象信息" class="headerlink" title="查看对象信息"></a>查看对象信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool <span class="built_in">stat</span> test-object-1</span><br></pre></td></tr></table></figure><h4 id="获取对象内容"><a href="#获取对象内容" class="headerlink" title="获取对象内容"></a>获取对象内容</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool get test-object-1 test.txt</span><br></pre></td></tr></table></figure><h4 id="将指定文件作为对象写入到资源池"><a href="#将指定文件作为对象写入到资源池" class="headerlink" title="将指定文件作为对象写入到资源池"></a>将指定文件作为对象写入到资源池</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool put test-object-2 test.txt</span><br></pre></td></tr></table></figure><h4 id="删除对象"><a href="#删除对象" class="headerlink" title="删除对象"></a>删除对象</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados -p test_pool <span class="built_in">rm</span> test-object-1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;查看-Ceph-的守护进程&quot;&gt;&lt;a href=&quot;#查看-Ceph-的守护进程&quot; class=&quot;headerlink&quot; title=&quot;查看 Ceph 的守护进程&quot;&gt;&lt;/a&gt;查看 Ceph 的守护进程&lt;/h4&gt;&lt;p&gt;使用以下命令查看所有 Ceph 守护进程：&lt;/p&gt;
</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph线程池实现</title>
    <link href="https://watsonlu6.github.io/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-27T14:26:42.000Z</published>
    <updated>2024-07-28T10:16:50.698Z</updated>
    
    <content type="html"><![CDATA[<p>线程池和工作队列是紧密相连的，基本流程就是将任务送入到对应的工作队列中，线程池中的线程从工作队列中取出任务并进行处理。Ceph 为了支持高并发读写，源码设计中大量采用线程池来进行io的推进。Ceph的线程池实现了多种不同的工作队列。一般情况下，一个线程池对应一个类型的工作队列。在要求不高的情况下，也可以一个线程池对应多种类型的工作队列，让线程池处理不同类型的任务。</p><h2 id="mutex的实现"><a href="#mutex的实现" class="headerlink" title="mutex的实现"></a>mutex的实现</h2><p>src&#x2F;common&#x2F;mutex.h<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B01.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B02.png"></p><p>condition variable的实现<br>src&#x2F;common&#x2F;cond.h<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B03.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B04.png"></p><h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><p>Ceph中线程的在src&#x2F;common&#x2F;Thread.h中定义<br>线程编程接口中，一个线程在创建时调用pthread_create函数来传入entry函数，杀死线程调用pthread_kill函数，当线程被杀死之后，必须调用pthread_join函数来进行线程资源的回收，如果不调用此函数，就会出现类似zombie process。如果要想让系统自己回收线程资源，就要将线程与父线程分离即调用pthread_detach。通过接口对比，src&#x2F;common&#x2F;Thread.h中定义的class thread，实际上是Ceph自己封装了一个线程类，这个线程类其实就是对Linux线程接口的一层封装。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B05.png"></p><p>Ceph中所有要用的线程必须继承Thread类，通过查找发现如下一些线程：</p><ol><li>Accepter.h (src\msg)：class Accepter : public Thread  &#x2F;&#x2F;用来socket bind的线程,   accepter线程入口函数里定义了poll的网络通讯结构，用来放入管道</li><li>Admin_socket.h (src\common)：class AdminSocket : public Thread</li><li>Ceph_context.cc (src\common)：class CephContextServiceThread : public Thread</li><li>DispatchQueue.h (src\msg):  class DispatchThread : public Thread   &#x2F;&#x2F;用来进行消息分发的线程，  在simpleMessenger中有dispatch_queue成员变量,</li><li>FileJournal.h (src\os):  class Writer : public Thread     &#x2F;&#x2F;用来进行写数据到journal中的线程</li><li>FileJournal.h (src\os):  class WriteFinisher : public Thread   &#x2F;&#x2F;当用aio异步模式写数据到journal完成后，此线程用来接管其他剩余操作</li><li>FileStore.h (src\os):  struct SyncThread : public Thread    &#x2F;&#x2F;用来同步数据执行同步的线程，主要是将已经完成的journal的序列号写入到文件中</li><li>Finisher.h (src\common):  struct FinisherThread : public Thread   &#x2F;&#x2F;公用的finisher线程，用来查看某些特定的操作是否结束，结束后进行后续处理工作</li><li>MDLog.h (src\mds):  class ReplayThread : public Thread </li><li>OSD.h (src\osd):  struct T_Heartbeat : public Thread   &#x2F;&#x2F;维系osd进程之间互相心跳连接的线程</li><li>OutputDataSocket.h (src\common):class OutputDataSocket : public Thread</li><li>Pipe.h (src\msg): class Reader : public Thread   &#x2F;&#x2F;用来处理所有对socket的读操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理</li><li>Pipe.h (src\msg): class Writer : public Thread   &#x2F;&#x2F;用来处理所有对socket的写操作，由acepter线程将socket accept以后打入到SimpleMessenger::dispatch_queue中交由此线程处理</li><li>Pipe.h (src\msg):    class DelayedDelivery: public Thread    &#x2F;&#x2F;用来处理所有对socket的延时操作</li><li>Signal_handler.cc (src\global)：struct SignalHandler : public Thread </li><li>SimpleMessenger.h (src\msg):  class ReaperThread : public Thread &#x2F;&#x2F;用来进行消息通信的主要线程 reaper是用来在通讯完成时拆除管道，其中成员有accepter线程（用来bind，accept socket文件放入管道），还有dispatch_queue线程</li><li>Throttle.cc (src\test\common):  class Thread_get : public Thread </li><li>Timer.cc (src\common)：class SafeTimerThread : public Thread </li><li>WorkQueue.h (src\common):  struct WorkThread : public Thread</li></ol><p>可以将这些线程分为四类线程</p><ol><li>普通类线程：<br> 使用此类线程类直接申明继承自Thread，重写一个entry函数，在进程启动最初时，调用了create函数创建了线程，同时使用它的人必须自己定义消息队列。上面大部分线程都是此类，比如FileJournal::write_thread就是一个FileJournal::Writer类对象，它自己定义了消息队列FileJournal::writeq</li><li>SafeTimerThread类线程:<br> 此类线程使用者可以直接申明一个SafeTimer成员变量，因为SafeTimer中已经封装了SafeTimerThread类和一个消息队列（成员是Context回调类），并完成了entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过SafeTimer::add_event_after函数将钩子埋入，等待规定时间到达后执行。</li><li>FinisherThread类线程:<br> 此类线程使用者可以直接申明一个Finisher成员变量，因为Finsher中已经封装了FinisherThread类和一个消息队列（成员是Context回调类），并完成entry函数的逻辑流程。使用者使用方法，就是设置回调函数，通过Finisher::queue函数将钩子埋入，等待某类操作完成后执行。</li><li>ThreadPool内部线程：<br> 这类线程由于是具体工作类线程，所以他们一般都是以线程池形式一下创建多个。ThreadPool类内部有多个线程set&lt;WorkThread*&gt;和多个消息队列vector&lt;WorkQueue_*&gt;组成。工作流程就是线程不断的轮询从队列中拿去数据进行操作。</li></ol><p>可以看到Ceph线程的所有接口都只是对相应的Linux接口的封装。继承其的子类主要在于实现entry()函数：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B06.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B07.png"></p><p><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B08.png"></p><h2 id="线程池的实现"><a href="#线程池的实现" class="headerlink" title="线程池的实现"></a>线程池的实现</h2><p>Ceph中线程池的在src&#x2F;common&#x2F;WorkQueue.h中定义<br>线程池和工作队列其实是密不可分的，从Ceph的代码中也可以看出来。让任务推入工作队列，而线程池中的线程负责从工作队列中取出任务进行处理。工作队列和线程池的关系，类似于狡兔和走狗的关系，正是因为有任务，所以才需要雇佣线程来完成任务，没有了狡兔，走狗也就失去了存在的意义。而线程必须要可以从工作队列中认领任务并完成，这就类似于猎狗要有追捕狡兔的功能。正因为两个数据结构拥有如此紧密的关系，因此，Ceph中他们的相关函数都位于WorkQueue.cc和WorkQueue.h中。</p><p><strong>void ThreadPool::start()</strong><br>函数ThreadPool::start()用来启动线程池，其在加锁的情况下，调用函数start_threads()，start_threads()检查当前的线程数，如果小于配置的线程池线程数，就创建新的工作线程。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B09.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B010.png"></p><p><strong>struct WorkThread : public Thread</strong><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B011.png"></p><p><strong>ThreadPool::worker()</strong><br>线程池的关键在于线程的主函数做的事情。首先是工作线程。线程池中会有很多的WorkThread，它的基类就是Thread。线程的主函数为pool-&gt;worker，即ThreadPool::worker函数。其entry函数其实就是调用线程池的worker函数进行具体的工作。</p><p>ThreadPool::worker函数内定义了WorkThread类线程的操作逻辑。基本流程就是轮询所有WorkQueue_，当发现某种类型WorkQueue_中有数据时拿出，然后依次调用该WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。（worker函数的主要实现其实很常规，就是遍历work_queues，从其中找出每一个消息队列实例，并调用WorkQueue_自己定义的函数_void_process和_void_process_finish等函数来顺序执行操作。）<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B012.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B013.png"></p><p>线程池是支持动态调整线程个数的。所谓调整，有两种可能性，一种是线程个数增加，一种线程个数减少。当添加OSD的时候，数据会重分布，恢复的速度可以调节，其中一个重要的参数为osd-max-recovery-threads，该值修改可以实时生效。</p><p><strong>ThreadPool::join_old_threads()</strong><br>线程本身是一个loop，不停地处理WorkQueue中的任务，在一个loop的开头，线程个数是否超出了配置的个数，如果超出了，就需要自杀，所谓自杀即将自身推送到_old_threads中，然后跳出loop，直接返回了。线程池中的其他兄弟在busy-loop开头的join_old_threads函数会判断是否存在自杀的兄弟，如果存在的话，执行join，为兄弟收尸。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B014.png"></p><p><strong>ThreadPool::start_threads()</strong><br>start_threads函数不仅仅可以用在初始化时启动所有工作线程，而且可以用于动态增加，它会根据配置要求的线程数_num_threads和当前线程池中线程的个数，来创建WorkThread，当然了，他会调整线程的io优先级。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B015.png"></p><p><strong>ThreadPool::handle_conf_change()</strong><br>线程池的线程个数如果不够用，也可以动态的增加，通过配置的变化来做到：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B016.png"></p><p><strong>ThreadPool::pause()</strong><br>线程池的工作线程，绝大部分时间内，自然是busy－loop中处理工作队列上的任务，但是有一种场景是，需要让工作暂时停下来，停止工作，不要处理WorkQueue中的任务。线程池提供了一个标志为_pause,只要_pause不等于0，那么线程池中线程就在loop中就不会处理工作队列中的任务，而是空转。为了能够及时的醒来，也不是sleep，而是通过条件等待，等待执行的时间。</p><p>当下达pause指令的时候，很可能线程池中的某几个线程正在处理工作队列中的任务，这种情况下并不是立刻就能停下的，只有处理完手头的任务，在下一轮loop中检查_pause标志位才能真正地停下。那么pause指令就面临选择，要不要等工作线程WorkThread处理完手头的任务。pause函数是等，pauser_new函数并不等，pause_new函数只负责设置标志位，当其返回的时候，某几个线程可能仍然在处理工作队列中的任务。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B017.png"></p><p><strong>struct WorkQueue_</strong><br>在ThreadPool这个类中，set&lt;WorkThread*&gt; _threads保存着线程池中的多个线程，vector&lt;WorkQueue_*&gt; work_queues保存着线程池中的待线程处理的消息队列。整个线程池的原理思想比较简单就是生成一定数目的线程，然后线程从队列中遍历获取队列实例，调用实例自带的处理函数_void_process和_void_process_finish处理。 ThreadPool中的WorkQueue_，这是一种抽象的类，只定义了一个队列应该有的一些特定的函数，这些函数几乎都是虚函数，目的是为了调用到自己三个子类BatchWorkQueue、WorkQueueVal、WorkQueue自己定义的函数。而在三个子类中对应函数_void_process、_void_process_finish中又分别调用了使用者自己继承它们而自己实现的具体操作函数如_process,_process_finish。存放在work_queues里面的WorkQueue_类：<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B018.png"></p><p>这是一个纯虚基类，也就是说不同的线程池要实现自己的队列，继承WorkQueues_并且实现其接口。线程池已经有4个纯虚基类继承这个类：</p><ul><li>BatchWorkQueue<br>  批量处理队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B019.png"></li><li>WorkQueueVal<br>  存值队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B020.png"></li><li>WorkQueue<br>  存指针队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B021.png"></li><li>PointerWQ<br>  存指针队列<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B022.png"></li></ul><p><strong>add_work_queue()&#x2F;remove_work_queue()</strong><br>ThreadPool中的add_work_queue和remove_work_queue就是用来建立和移除与WorkQueue关联的函数<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B023.png"></p><p><strong>TPHandle</strong><br>超时检查，每次线程函数执行时，都会设置一个grace超时时间，当线程执行超过该时间，就认为是unhealthy的状态。当执行时间超过suicide_grace时，OSD就会产生断言而导致自杀。heartbeat_handle_d记录了相关信息，并把该结构添加到HeartbeatMap的系统链表中保存。OSD会有一个定时器，定时检查是否超时。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B024.png"></p><p>线程池使用步骤<br>先创建线程池，然后创建WorkQueue的时候，将线程池作为参数传递给WorkQueue，就能建立关系。</p><ol><li>声明线程池成员ThreadPool *_tp</li><li>声明队列类型ThreadPool::WorkQueue_*_wq</li><li>重写WorkQueue中对应函数_void_process,_void_process_finish</li><li>调用*_tp.add_work_queue(*_wq)将队列传入</li></ol><h2 id="基本线程池扩展"><a href="#基本线程池扩展" class="headerlink" title="基本线程池扩展"></a>基本线程池扩展</h2><p>在Ceph中有不少线程池会实现继承以上基类：<br>ThreadPool op_tp: 处理client请求<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B025.png"></p><p>struct recovery_tp: 处理recovery_tp操作<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B026.png"></p><p>struct command_tp: 处理命令行来的操作<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B027.png"></p><p>ShardedThreadPool: Ceph还实现了另外一种线程池ShardedThreadPool，这种线程池与上面的线程池不同之处在于这种线程池是多线程共享队列的方式。只有一个队列，多个线程同时对这个队列进行处理。<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B028.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B029.png"></p><p>SharededWQ: shardedThreadPool类型线程池内部有个比较重要的消息队列SharededWQ，该队列将多种OP放入其中<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B030.png"></p><p>Ceph 在实际使用中，会用到这种线程池<br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B031.png"><br><img src="/images/thread/Ceph%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B032.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;线程池和工作队列是紧密相连的，基本流程就是将任务送入到对应的工作队列中，线程池中的线程从工作队列中取出任务并进行处理。Ceph 为了支持高并发读写，源码设计中大量采用线程池来进行io的推进。Ceph的线程池实现了多种不同的工作队列。一般情况下，一个线程池对应一个类型的工作队</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_rbd客户端实现</title>
    <link href="https://watsonlu6.github.io/Ceph-rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-15T14:26:55.000Z</published>
    <updated>2024-07-28T09:48:58.097Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-RBD介绍"><a href="#Ceph-RBD介绍" class="headerlink" title="Ceph RBD介绍"></a>Ceph RBD介绍</h2><p>随着云计算的发展，Ceph已经成为目前最为流行的分布式存储系统，俨然存储界的Linux操作系统。Ceph集块存储、文件存储和对象存储于一身，适用场景广泛，用户众多。RBD是 Ceph 分布式存储系统中提供的块存储服务，Ceph的块存储通过一个客户端模块实现，这个客户端可以直接从数据守护进程读写数据（不需要经过一个网关）。根据客户端整合生态系统的差异，使用Ceph的块设备有两种实现方式：librbd (用户态)和krbd (内核态)。RBD：RADOS Block Devices. Ceph block devices are thin-provisioned, resizable and store data striped over multiple OSDs in a Ceph cluster.<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B01.png"></p><p>使用Ceph的块设备有两种路径（内核态与用户态）：(rbd map就是内核使用ceph块设备，调用librbd&#x2F;librados API访问ceph块设备是用户态)</p><ul><li>通过Kernel Module(内核态RBD)：即创建了RBD设备后，把它映射到内核中（使用rbd map命令映射到操作系统上），成为一个虚拟的块设备，这时这个块设备同其他通用块设备一样，设备文件一般为&#x2F;dev&#x2F;rbd0，后续直接使用这个块设备文件就可以了，可以把&#x2F;dev&#x2F;rbd0格式化后挂载到某目录，也可以直接作为裸设备进行使用。krbd是一个内核模块。其在内核中以一个块设备的方式加以实现。这整个Ceph客户端都是以内核模块的方式实现（没有与之相关的用户态进程或者守护进程）。krbd在内核的源码目录源文件:drivers&#x2F;block&#x2F;rbd.c、drivers&#x2F;block&#x2F;rbd_types.h、net&#x2F;ceph&#x2F;、include&#x2F;linux&#x2F;ceph<ul><li><a href="https://www.likecs.com/show-203739919.html">https://www.likecs.com/show-203739919.html</a></li><li><a href="https://github.com/torvalds/linux/blob/cfb92440ee71adcc2105b0890bb01ac3cddb8507/drivers/block/rbd.c">https://github.com/torvalds/linux/blob/cfb92440ee71adcc2105b0890bb01ac3cddb8507/drivers/block/rbd.c</a></li><li><a href="https://github.com/torvalds/linux/tree/85c7000fda0029ec16569b1eec8fd3a8d026be73/include/linux/ceph">https://github.com/torvalds/linux/tree/85c7000fda0029ec16569b1eec8fd3a8d026be73/include/linux/ceph</a></li></ul></li><li>通过librbd(用户态RBD)：即创建了RBD设备后，使用librbd&#x2F;librados库访问和管理块设备。这种方式直接调用librbd提供的接口，实现对RBD设备的访问和管理，不会在客户端产生设备文件。应用方案有：SPDK+librbd&#x2F;librados<ul><li><a href="https://github.com/ceph/ceph/tree/acf835db0376b1b71152949fdfec36e68f4a8474/src/librbd">https://github.com/ceph/ceph/tree/acf835db0376b1b71152949fdfec36e68f4a8474/src/librbd</a></li><li><a href="https://github.com/spdk/spdk/tree/cff525d336fb2c4c087413d4c53474b9e61cbdbe/module/bdev/rbd">https://github.com/spdk/spdk/tree/cff525d336fb2c4c087413d4c53474b9e61cbdbe/module/bdev/rbd</a><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B02.png"></li></ul></li></ul><p>RBD 的块设备由于元数据信息少而且访问不频繁，故 RBD 在 Ceph 集群中不需要单独的守护进程将元数据加载到内存进行元数据访问加速，所有的元数据和数据操作直接与集群中的 Monitor 服务和 OSD 服务进行交互。</p><h2 id="RBD-模块相关IO流图"><a href="#RBD-模块相关IO流图" class="headerlink" title="RBD 模块相关IO流图"></a>RBD 模块相关IO流图</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B03.png"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B04.png"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B05.png"></p><p>客户端写数据osd过程：</p><ol><li>采用的是 librbd 的形式，使用 librbd 创建一个块设备，向这个块设备中写入数据</li><li>在客户端本地同过调用 librados 接口，然后经过 pool，rbd，object，pg 进行层层映射（CRUSH 算法）,在 PG 这一层中，可以知道数据保存在哪几个 OSD 上，这几个 OSD 分为主从的关系</li><li>客户端与 primary OSD 建立 SOCKET 通信，将要写入的数据传给 primary OSD，由 primary OSD 再将数据发送给其他 replica OSD 数据节点。</li></ol><h2 id="IO-时序图"><a href="#IO-时序图" class="headerlink" title="IO 时序图"></a>IO 时序图</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B06.png"><br>librbd提供了针对image的数据读写和管理操作两种访问接口，其中数据读写请求入io_work_queue，然后由线程池中的线程将io请求以object粒度切分并分别调用rados层的aio接口（IoCtxImpl）下发，当所有的object请求完成时，调用librbd io回调（librbd::io::AioCompletion）完成用户层的数据io。而对image的管理操作通常需要涉及单个或多个对象的多次访问以及对内部状态的多次更新，其第一次访问将从用户线程调用至rados层 aio 接口或更新状态后入 op_work_queue 队列进行异步调用，当 rados aio 层回调或 Context 完成时再根据实现逻辑调用新的 rados aio 或构造 Context 回调，如此反复，最后调用应用层的回调完成管理操作请求。<br>      此外为了支持多客户端共享访问 image，librbd 提供了构建于 rados watch&#x2F;notify 之上的通知、远程执行以及 exclusive lock 分布式锁机制。每个 librbd 客户端在打开 image 时（以非只读方式打开）都会 watch image 的 header 对象，从远程发往本地客户端的通知消息或者内部的 watch 错误消息会通过 RadosClient 的 Finisher 线程入 op_work_queue 队列进行异步处理。</p><h2 id="RBD读写流程"><a href="#RBD读写流程" class="headerlink" title="RBD读写流程"></a>RBD读写流程</h2><p>对于任何RBD客户端的读写都要经过以下步骤：</p><ol><li>集群句柄创建、读取配置<br> 集群句柄的创建即是librados:Rados的创建，初始化，读取配置<br> 创建：librados::Rados rados;<br> 初始化：librados::Rados::init(const char * const id)<br>     主要是初始化librados::RadosClient<br>     读取配置：<br>     librados::Rados::conf_read_file(const char * const path) const<br>     librados::Rados::conf_parse_argv(int argc, const char ** argv) const</li><li>集群连接<br> librados::Rados::connect()</li><li>IO上下文环境初始化（pool创建读写等）<br> librados::Rados::ioctx_create(const char *name, IoCtx &amp;io)<br> 主要是IoCtxImpl即librados::IoCtx</li><li>rbd创建<br> librbd::RBD rbd;<br> RBD::create2(IoCtx&amp; io_ctx, const char *name, uint64_t size,uint64_t features, int *order)</li><li>rbd的读写<br> librbd::Image image;<br> RBD::open(IoCtx&amp; io_ctx, Image&amp; image, const char *name)<br> Image::write(uint64_t ofs, size_t len, bufferlist&amp; bl)<br> Image::read(uint64_t ofs, size_t len, bufferlist&amp; bl)</li><li>IO上下文环境关闭<br> librbd::Image::close()<br> librados::IoCtx::close()</li><li>集群句柄关闭<br> librados::Rados::shutdown()</li></ol><h2 id="RBD源码介绍"><a href="#RBD源码介绍" class="headerlink" title="RBD源码介绍"></a>RBD源码介绍</h2><p>librbd以及librados都是属于ceph 的客户端，其提供ceph的接口向上提供块存储服务。<br>librados提供客户端访问Ceph集群的原生态统一接口。其它接口或者命令行工具都基于该动态库实现。在librados中实现了Crush算法和网络通信等公共功能，数据请求操作在librados计算完成后可以直接与对应的OSD交互进行数据传输。<br>librbd 是Ceph提供的在librados上封装的块存储接口的抽象。</p><p>librados主要的类是Rados和IoCtx<br>librados::Rados负责初始化集群、读取配置、连接集群<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B07.jpg"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B08.jpg"></p><p>librados::IoCtx负责创建IO上下文环境<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B09.jpg"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B010.jpg"></p><p>librados::bufferlist负责读写缓存<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B011.jpg"></p><p>librbd最主要的两个类是：RBD和Image<br>librbd::rbd主要负责 Image 的创建、删除、重命名、克隆映像等操作，包括对存储池的元数据的管理，针对部分操作提供异步接口<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B012.jpg"></p><p>librbd::image负责image的读写(read&#x2F;write)，以及快照相关的操作等等。同时提供了相关异步操作的接口。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B013.png"></p><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B014.png"></p><h2 id="rbd-Image的创建"><a href="#rbd-Image的创建" class="headerlink" title="rbd Image的创建"></a>rbd Image的创建</h2><p>rbd卷的创建接口：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B015.jpg"></p><p>函数输入参数：</p><ul><li>io_ctx: 针对pool的上下文环境，对pool的操作都要首先建立一个相应的上下文环境</li><li>*name：rbd卷名字</li><li>size：rbd卷大小</li><li>features: rbd卷的特性</li><li>order: rbd卷的分块大小<br>其具体实现在internal.cc中：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B016.jpg"></li></ul><p>继续往下调用：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B017.jpg"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B018.jpg"></p><p>根据format格式调用不同的创建接口，现在主流采用新的format2，所用调用新的接口：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">create_v2</span><span class="params">(IoCtx&amp; io_ctx, <span class="type">const</span> <span class="type">char</span> *imgname, <span class="type">uint64_t</span> bid, <span class="type">uint64_t</span> size,<span class="type">int</span> order, <span class="type">uint64_t</span> features, <span class="type">uint64_t</span> stripe_unit,<span class="type">uint64_t</span> stripe_count, <span class="type">uint8_t</span> journal_order,<span class="type">uint8_t</span> journal_splay_width, <span class="type">const</span> std::string &amp;journal_pool,<span class="type">const</span> std::string &amp;non_primary_global_image_id,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="type">const</span> std::string &amp;primary_mirror_uuid,<span class="type">bool</span> negotiate_features)</span></span></span><br></pre></td></tr></table></figure><p>这个接口会做如下工作：<br>创建rbd_id.{volume_name}的object：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B019.png"></p><p>然后想这个object写入block_name_prefix中的id号：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B020.png"></p><p>然后向rbd_directory写入卷名和id的一一映射。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B021.jpg"></p><p>创建名为rbd_header.id的object，并向这个object写入size,order,features,RBD_DATA_PREFIX等信息。<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B022.png"></p><p>如果有条带化，则会设置条带化信息：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B023.png"></p><p>创建名为rbd_object_map.{id}的对象：<br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B024.jpg"></p><h2 id="rbd-Image的打开"><a href="#rbd-Image的打开" class="headerlink" title="rbd Image的打开"></a>rbd Image的打开</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B025.jpg"><br><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B026.jpg"></p><p>其实就是生成一个ImageCtx实例，调用其open接口。</p><h2 id="rbd-Image的写"><a href="#rbd-Image的写" class="headerlink" title="rbd Image的写"></a>rbd Image的写</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B027.jpg"></p><h2 id="rbd-Image的读"><a href="#rbd-Image的读" class="headerlink" title="rbd Image的读"></a>rbd Image的读</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B028.jpg"></p><h2 id="rbd-Image的快照"><a href="#rbd-Image的快照" class="headerlink" title="rbd Image的快照"></a>rbd Image的快照</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B029.jpg"></p><h2 id="rbd-Image的克隆"><a href="#rbd-Image的克隆" class="headerlink" title="rbd Image的克隆"></a>rbd Image的克隆</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B030.jpg"></p><h2 id="rbd-Image的删除"><a href="#rbd-Image的删除" class="headerlink" title="rbd Image的删除"></a>rbd Image的删除</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B031.jpg"></p><h2 id="rbd的读写"><a href="#rbd的读写" class="headerlink" title="rbd的读写"></a>rbd的读写</h2><p><img src="/images/rbd/rbd%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E7%8E%B032.png"></p><p>要使用librbd, 需要先安装下面两个包。可以通过yum安装, 也可以通过下载ceph源码编译后, 通过make install进行安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  yum list | grep librbd</span></span><br><span class="line">librbd1.x86_64                  1:0.80.7-3.el7                    base</span><br><span class="line">librbd1-devel.x86_64            1:0.80.7-3.el7                    base</span><br></pre></td></tr></table></figure><p>至于如何使用librbd来编程, 请参考下面的代码, 这是使用librbd的一般流程。<br>编译时记得加上链接参数: g++ librbdtest.cpp -lrados -lrbd。<br>更多函数的使用请参考 librbd.hpp。 另外 这里 有一些不错的示例。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rbd/librbd.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-RBD介绍&quot;&gt;&lt;a href=&quot;#Ceph-RBD介绍&quot; class=&quot;headerlink&quot; title=&quot;Ceph RBD介绍&quot;&gt;&lt;/a&gt;Ceph RBD介绍&lt;/h2&gt;&lt;p&gt;随着云计算的发展，Ceph已经成为目前最为流行的分布式存储系统，俨然存储界的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_crush算法实现</title>
    <link href="https://watsonlu6.github.io/Ceph-crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://watsonlu6.github.io/Ceph-crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-08-02T14:26:17.000Z</published>
    <updated>2024-07-28T09:23:25.673Z</updated>
    
    <content type="html"><![CDATA[<p>分布式存储系统的数据分布算法要解决数据如何分布到集群中的各个节点和磁盘上，其面临： 数据分布和负载均衡、灵活应对集群伸缩、大规模集群计算速率三方面的挑战。 </p><ol><li>数据分布和负载均衡：数据分布均衡，使数据能均匀地分布在各个节点和磁盘上，使数据访问的负载在各个节点和磁盘上。</li><li>灵活应对集群伸缩：系统可以方便地增加或者删除存储设备，当增加或删除存储设备后，能自动实现数据的均衡，并且迁移的数据尽可能减少。</li><li>大规模集群算法计算速率：要求数据分布算法维护的元数据相对较小，并且计算量不能太大。</li></ol><p>在分布式存储系统中，数据分布算法由两种基本实现方法，一种是<code>基于集中式的元数据查询的方式</code>，如HDFS的实现：文件的分布信息是通过访问集中元数据服务器获得；另一种是<code>基于哈希算法计算的方式</code>。例如一致性哈希算法(DHT)。Ceph的数据分布算法CRUSH属于后者。CRUSH(Controlled Replication Under Scalable Hashing)，是一种基于哈希的数据分布算法。与另一种基于集中式的元数据查询的存储方式(文件的分布信息需要先通过访问集中元数据服务器获得)不同。CRUSH算法以数据唯一标识符、当前存储集群的拓扑结构以及数据分布策略作为CRUSH的输入，经过计算获得数据分布位置，直接与OSD进行通信，从而避免集中式查询操作，实现去中心化和高度并发。</p><p>Ceph 作为分布式存储系统，采用多节点多副本的数据存放方式，必然要解决数据如何分布到集群中各个节点和磁盘上。Ceph使用CRUSH数据分布算法。例如一个Ceph集群三副本，就存在着如何映射3个OSD存储这3个副本的数据，Ceph写数据时，即写object时，首先需要计算出object属于哪个PG，然后根据PG id 计算出存放的OSD位置。过程分两步：PG id的计算 ；OSD位置的计算。结合rbd的代码介绍这两个过程：</p><h2 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h2><p>rbd的写接口（src&#x2F;linrbd&#x2F;librbd.cc）<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B01.png"><br>接口传入的参数是起始写位置（ofs）以及写数据大小（len）和要写入的数据（bl），调用io_work_queue-&gt;write()，生成Object写入请求对象，发送到ImageRequestWQ任务队列中，等待工作线程处理。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B02.png"><br>现在看看ImageRequest的数据类型<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B03.png"></p><p>因为Image的ImageWriteRequest继承AbstractImageWriteRequest类，重点关注AbstractImageWriteRequest类<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B04.png"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B05.png"></p><p>发送写请求时调用void AbstractImageWriteRequest<I>::send_request()函数，在这个函数进行切分数据，分成大小同等（可设定，一般为4M）的object(最后一块object可能大小小于块大小)。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B06.png"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B07.png"></p><p>file_to_extents就是将数据段切分各个object，具体怎么分割就不深入看源码了。然后调用send_object_requests()将分片各个object分别构造写请求<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B08.png"></p><h2 id="Op请求处理"><a href="#Op请求处理" class="headerlink" title="Op请求处理"></a>Op请求处理</h2><p>此后会构造objecter的Op请求，发送出去；转到src&#x2F;librados&#x2F;IoCtxImpl.cc，深入了解Op请求的处理。类IoCtxImpl是pool相关的上下文信息，一个pool对应一个IoCtxImpl对象，可以在该pool里创建、删除对象，完成对象数据读写等各种操作，包括同步和异步的实现。类IoCtxImpl把请求封装成ObjectOperation类。然后再添加pool的地址信息，封装成Obejcter::Op对象。Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。类IoCtxImpl的write&#x2F;read等同步操作函数通过调用operate()来调用op_submit()，类IoCtxImpl的aio_write&#x2F;aio_read&#x2F;aio_operate等异步函数直接调用了op_submit(），说明op_submit(）是object读写操作的入口。调用函数objeter-&gt;op_submit发送给相应的OSD，如果是同步操作，就等待操作完成。如果是异步操作，就不用等待，直接返回，当操作完成后，调用相应的回调函数通知。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B09.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B010.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B011.png"></p><p>Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B012.png"></p><h2 id="发送数据op-submit"><a href="#发送数据op-submit" class="headerlink" title="发送数据op_submit"></a>发送数据op_submit</h2><p>在op_submit()调用_op_submit_with_budget()处理Throttle相关流量的限制<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B013.png"><br>在_op_submit_with_budget()中，如果osd_timeout大于0，就是设置定时器，当操作超时，就调用定时器回调函数op_ cancel取消操作，然后通过调用_op_submit(op, sul, ptid)。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B014.png"></p><p>_op_submit函数完成了关键的地址寻址和发送工作，比如_calc_target()、_get_session()、_send_op()等，调用函数_calc_target()计算对象的目标OSD；调用函数_get_session()获取目标OSD的链接，如果返回值为-EAGAIN，就升级为写锁，重新获取。检查当前的状态标志，如果当前是CEPH_OSDMAP_PAUSEWR或者OSD空间满，就暂时不发送，否则调用函数_prepare_osd_op准备请求的信息，调用函数_send_op发送出去。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B015.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B016.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B017.png"></p><h2 id="对象寻址-calc-target"><a href="#对象寻址-calc-target" class="headerlink" title="对象寻址_calc_target"></a>对象寻址_calc_target</h2><p>重点详细分析下_calc_target函数：首先调用函数osdmap-&gt;get_pg_pool()根据t-&gt;base_oloc.pool获取pool信息，获取pg_pool_t对象；检查pi-&gt;last_force_op_resend是否强制重发，如果强制重发，force_resend设置为true；检查cache tier，如果是读操作，并且有读缓存，就设置t-&gt;target_oloc.pool为该pool的read_tier值；如果是写操作，并且有写缓存，就设置t-&gt;target_oloc.pool为该pool的write_tier值；调用函数osdmap-&gt;object_locator_to_pg()获取目标对象所在的PG；调用函数osdmap-&gt;pg_to_up_acting_osds()通过CRUSH算法，获取该PG对应的OSD列表，即pg_to_up_acting_osds()通过CRUSH算法计算OSD；判断读写操作：读操作，如果设置了CEPH_OSD_FLAG_BALANCE_READS标志，调用rand() 取余随机选择一个副本读取；读操作，如果设置了CEPH_OSD_FLAG_LOCALIZE_READS标志，尽可能从本地副本读取；写操作，target的OSD就设置为主OSD。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B018.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B019.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B020.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B021.png"></p><p>首先获取pool信息，判断是否有效：<br>        <code>const pg_pool_t *pi = osdmap-&gt;get_pg_pool(t-&gt;base_oloc.pool);</code><br>然后根据获取pgid，注意pgid是一个结构体pg_t<br>pg_t 的结构如下：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B022.png"></p><p>m_pool 是pool id， m_seed是函数根据object id算出来的哈希值，m_preferred赋值-1。<br>接下来就是调用osdmap-&gt;pg_to_up_acting_osds()，获取该PG对应的OSD列表，即选择OSD：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B023.png"></p><p>pg_to_up_acting_osds()函数在src\osd\OSDMap.cc中，函数功能是选出up osds以及 acting osds, 两个都是数组类型，大小为副本数<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B024.png"></p><p>继续跟踪这个函数：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B025.png"></p><p>进入_pg_to_raw_osds：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B026.png"></p><p>上面函数crush-&gt;do_rule()就是真正调用crush算法计算出相应的osd列表。<br>这里重点解释下参数pps：对象到PG的映射：任何程序通过客户端访问集群时，首先由客户端生成一个字符串形式的对象名，然后基于对象名和命名空间计算得出一个32位哈希值。针对此哈希值，对该存储池的PG总数量pg_num取模(掩码计算)，得到该对象所在的PG的id号。<br><code>ps_t pps = pool.raw_pg_to_pps(pg);  // placement ps</code><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B027.jpg"></p><p>可以看出pps这是一个哈希值，这个哈希值根据pool id，函数中pg.ps()就是我们object哈希算出的m_seed：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B028.jpg"></p><h2 id="调用CRUSH算法"><a href="#调用CRUSH算法" class="headerlink" title="调用CRUSH算法"></a>调用CRUSH算法</h2><p>下面就是进入do_rule 进行CRUSH算法的处理了：src&#x2F;crush&#x2F;CrushWrapper.h<br>调用crush_do_rule()函数<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B029.png"></p><p>继续调用crush_do_rule()算法，执行CEUSH算法<br><strong>CRUSH算法：</strong>针对指定输入x(要计算PG的pg_id)，CRUSH将输出一个包含n个不同目标存储对象(例如磁盘)的集合(OSD列表)。CRUSH的计算过程使用x、cluster map、placement rule作为哈希函数输入。因此如果cluster map不发生变化(一般placement rule不会轻易变化)，那么结果就是确定的。算法输入需要3个输入参数：</p><ol><li>输入x 即PG id的哈希值</li><li>crush_map即集群的拓扑结构，集群的层级化描述，形如”数据中心-&gt;机架-&gt;主机-&gt;磁盘”这样的层级拓扑。用树来表示，每个叶子节点都是真实的最小物理存储设备，称为devices；所有中间节点统称为bucket，每个bucket可以是一些devices的集合，也可以是低一级的buckets集合；根节点称为root，是整个集群的入口。</li><li>ruleno 即选择策略，就rule规则，这里用编号表示；它决定一个PG的对象副本如何选择(从定义的cluster map的拓扑结构中)的规则，以此完成数据映射。palcement rule可以包含多个操作，这些操作共有3种类型：take(root)、select(replicas, type)、emit(void)<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B030.png"></li></ol><p>crush 算法输入需要3个输入参数：</p><ol><li>输入x 即PG id的哈希值</li><li>crush_map即集群的拓扑结构</li><li>ruleno 即选择策略，就rule规则，这里用编号表示</li></ol><p>可以通过集群输出crush_map:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B031.jpg"></p><p>vim crush_map如下：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B032.png"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B033.jpg"></p><p><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B034.jpg"></p><p>显示的结构和代码中的结构还是有着映射的关系：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B035.jpg"></p><p>其中crush_bucket:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B036.jpg"><br>对应：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B037.0.jpg"><br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B037.jpg"></p><p>crush_rule:<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B038.jpg"><br>对应于：<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B039.png"></p><p>逐一对比分析其数据结构。<br>这里分析下其选择OSD的过程：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> *a = scratch;</span><br><span class="line"><span class="type">int</span> *b = scratch + result_max;</span><br><span class="line"><span class="type">int</span> *c = scratch + result_max*<span class="number">2</span>;</span><br><span class="line">w = a;</span><br><span class="line">o= b;</span><br></pre></td></tr></table></figure><p>a, b, c 分别指向 scratch向量的0, 1, 2的位置.<br>w &#x3D; a; o &#x3D; b; </p><ul><li>w被用作一个先入先出队列来在CRUSH map中进行横向优先搜索(BFS traversal). </li><li>o存储crush_choose_firstn选择的结果. </li><li>c存储最终的OSD选择结果.</li></ul><p>crush_do_rule函数里面最重要的是函数里面的for循环，这个循环就是筛选osd的过程，</p><p>for循环中：</p><ol><li>首先从rule规则中当前执行的步骤，首次就执行第一条步骤：<br> <code>struct crush_rule_step *curstep = &amp;rule-&gt;steps[step];</code></li><li>然后根据当前执行步骤的操作类型，选择不同的分支操作，首先一般是take操作，而且是take fault。即crush map树根节点。这个过程就是根据step 逐步选择bucket 知道知道叶子节点，即OSD。</li><li>这个过程中，crush_choose_firstn 函数, 递归的选择特定bucket或者设备,并且可以处理冲突,失败的情况.</li><li>如果当前是choose过程,通过调用crush_bucket_choose来直接选择. </li><li>如果当前是chooseleaf选择叶子节点的过程,该函数将递归直到得到叶子节点.<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B040.png"></li></ol><p>在for循环中的crush_choose_firstn()计算后如果结果不是OSD类型, o 交给w。以便于 w成为下次crush_choose_firstn的输入参数。在crush_choose_firstn()中，for(){}：副本选择循环判断条件rep是否等于副本数numrep，rep叠加。do{}while (retry_descent)：选择OSD冲突或故障域失效时循环，随机因子r改变。do{}while (retry_bucket)：进行bucket层级选择，当前item type不是OSD时循环，当前进行选择的bucket，即in改变。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B041.png"></p><p>在crush_choose_firstn()函数中有crush_bucket_choose函数，这个函数根据bucket类型选择不同的权重计算方法刷选出bucket。如果采用straw2，就会采用bucket_straw2_choose接口进行筛选。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B042.jpg"></p><p>bucket_straw2_choose()功能是通过调用伪随机算法计算伪随机数，以伪随机数最高的作为选择出的节点<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B043.png"></p><p>generate_exponential_distribution()产生随机数的思想是：采用逆变换采样的思想，先调用crush_hash32_3()计算哈希值，然后取随机数的低16位。计算指数随机变量。作为参考，请参阅指数分布示例：<a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling#Examples%E3%80%82">https://en.wikipedia.org/wiki/Inverse_transform_sampling#Examples。</a> 由于某种原因，略小于 0x10000 会产生更准确的分布……可能是舍入效果。 自然对数查找表映射 [0,0xffff]（对应实数 [1&#x2F;0x10000, 1] 到 [0, 0xffffffffffff]（对应实数 [-11.090355,0]）。除以 16.16 定点权重。 请注意，ln 值为负数，因此较大的权重意味着较大的（较小的负数）draw值。<br><img src="/images/crush/crush%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B044.png"></p><p>CRUSH算法的一些缺陷： </p><ol><li>CRUSH算法提供了uniform、list和tree等bucket类型作为straw bucket类型的替代方案，但这些算法在添加或删除服务器时需要进行不必要的重排，这使它们不适合用于大规模存储系统。 </li><li>CRUSH算法的查找函数需要进行O(log n)的二分查找，以找到与给定对象ID最接近的虚拟ID。这个计算对于系统中的每个对象都需要进行，因此在系统中有大量对象时，计算成本会很高。 </li><li>CRUSH算法在重建过程中可能会出现瓶颈，因为它需要在placement groups中进行数据放置，这可能会导致数据重建速度变慢。</li><li>CRUSH算法的计算复杂度较高，需要进行大量的计算，这可能会影响系统的性能。 综上所述，CRUSH算法虽然是一种灵活的对象放置算法，但它也存在一些缺陷，需要进一步改进和优化。</li></ol><p>由于CRUSH算法的计算复杂度较高，需要进行大量的计算，因此使用多线程来加速计算是一种可行的方法。具体来说，可以将CRUSH算法的计算任务分配给多个线程，每个线程负责计算一部分任务，然后将结果合并起来。这样可以充分利用多核处理器的计算能力，提高计算效率。但是，需要注意的是，多线程计算也会带来一些额外的开销，如线程间的同步和通信开销，因此需要进行合理的线程调度和优化，以达到最佳的性能提升效果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;分布式存储系统的数据分布算法要解决数据如何分布到集群中的各个节点和磁盘上，其面临： 数据分布和负载均衡、灵活应对集群伸缩、大规模集群计算速率三方面的挑战。 &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据分布和负载均衡：数据分布均衡，使数据能均匀地分布在各个节点和磁盘上，使数据访问的负载在</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_Bufferlist的设计与使用</title>
    <link href="https://watsonlu6.github.io/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>https://watsonlu6.github.io/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8/</id>
    <published>2021-07-14T05:19:06.000Z</published>
    <updated>2024-07-27T14:37:12.169Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-Bufferlist的设计与使用"><a href="#Ceph-Bufferlist的设计与使用" class="headerlink" title="Ceph Bufferlist的设计与使用"></a>Ceph Bufferlist的设计与使用</h2><p>做为主要和磁盘、网络打交道的分布式存储系统，序列化是最基础的功能之一。当一个结构通过网络发送或写入磁盘时，它被编码为一串字节。可序列化结构具encode 和 decode方法，将结构体<strong>序列化</strong>后存入bufferlist和从bufferlist读出字节串<strong>反序列化</strong>出结构体。bufferlist是ceph的底层组件，用于存储二进制数据，其存储的数据可以直接写入磁盘，在代码中有很广泛的使用。</p><p><strong>为什么要用bufferlist？</strong></p><p>为了免拷贝。发送数据时，传统的socket接口通常需要读取一段连续的内存。但是我们要发的数据内存不连续，所以以前的做法是申请一块大的内存，然后将不连续的内存内的数据拷贝到大内存块中，然后将大内存块地址给发送接口。但是找一块连续的大内存并不容易，系统可能会为此做各种腾挪操作，而将数据拷贝的大内存中，又是一个拷贝操作。RDMA的发送支持聚散表，不需要读取连续的内存。有bufferlist之后，我们可以通过bufferlist，将不连续的物理内存管理起来，形成一段“连续”的虚拟内存，然后将bufferlist的内存指针传递给聚散表，再把聚散表交给RDMA 发送接口即可。整个过程免去了内存拷贝操作。大大降低了CPU的消耗。</p><p>在ceph中经常需要将一个bufferlist编码(encode)到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和copy，效率较高。</p><p>补充：</p><ol><li>传统内存访问需要通过CPU进行数据copy来移动数据，通过CPU将内存中的Buffer1移动到Buffer2中。</li><li>DMA(直接内存访问)是一种能力，允许在计算机主板上的设备直接把数据发送到内存中去，数据搬运不需要CPU的参与。</li><li>DMA模式：可以同DMA Engine之间通过硬件将数据从Buffer1移动到Buffer2，而不需要操作系统CPU的参与，大大降低了CPU Copy的开销。</li><li>RDMA是一种概念，在两个或者多个计算机进行通讯的时候使用DMA， 从一个主机的内存直接访问另一个主机的内存。RDMA是一种新的直接内存访问技术，RDMA让计算机可以直接存取其他计算机的内存，而不需要经过处理器的处理。RDMA将数据从一个系统快速移动到远程系统的内存中，而不对操作系统造成任何影响。</li></ol><h2 id="bufferlist的设计"><a href="#bufferlist的设计" class="headerlink" title="bufferlist的设计"></a>bufferlist的设计</h2><p>Bufferlist负责管理Ceph中所有的内存。整个Ceph中所有涉及到内存的操作，无论是msg分配内存接收消息，还是OSD构造各类数据结构的持久化表示（encode&#x2F;decode），再到实际磁盘操作，都将bufferlist作为基础。bufferlist对应的类为buffer::list(using bufferlist &#x3D; buffer::list;)，而buffer::list又基于buffer::ptr和buffer::raw实现，探讨buffer::list的实现，不能跳过它们。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> ceph &#123;</span><br><span class="line">    <span class="keyword">namespace</span> buffer &#123;</span><br><span class="line">    <span class="keyword">inline</span> <span class="keyword">namespace</span> v14_2_0 &#123;</span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">ptr</span>;</span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">list</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">hash</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">using</span> bufferptr = buffer::ptr;</span><br><span class="line">    <span class="keyword">using</span> bufferlist = buffer::list;</span><br><span class="line">    <span class="keyword">using</span> bufferhash = buffer::hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ceph::buffer是ceph非常底层的实现，负责管理ceph的内存。ceph::buffer的设计较为复杂，但本身没有任何内容，主要包含buffer::list、 buffer::ptr、 buffer::raw、 buffer::hash。这三个类都定义在src&#x2F;include&#x2F;buffer.h和src&#x2F;common&#x2F;buffer.cc中。</p><ol><li>buffer::raw：负责维护物理内存的引用计数nref和释放操作。</li><li>buffer::ptr：指向buffer::raw的指针。</li><li>buffer::list：表示一个ptr的列表（std::list<bufferptr>），相当于将N个ptr构成一个更大的虚拟的连续内存。</li><li>buffer::hash：一个或多个bufferlist的有效哈希。</li></ol><p>buffer这三个类的相互关系可以用下面这个图来表示：<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_1.png"><br>图中蓝色的表示bufferlist，橙色表示bufferptr，绿色表示bufferraw。</p><pre><code>在这个图中，实际占用的系统内存一共就三段，分别是raw0，raw1和raw2代表的三段内存。raw0被ptr0，ptr1，ptr2使用raw1被ptr3，ptr4，ptr6使用raw2被ptr5，ptr7使用而list0是由ptr0-5组成的，list1是由ptr6和ptr7组成的。</code></pre><p>从这张图上我们就可以看出bufferlist的设计思路： </p><ul><li>对于bufferlist来说，仅关心一个个ptr。bufferlist将ptr连在一起，当做是一段连续的内存使用。因此，可以通过bufferlist::iterator一个字节一个字节的迭代整个bufferlist中的所有内容，而不需要关心到底有几个ptr，更不用关心这些ptr到底和系统内存是怎么对应的；也可以通过bufferlist::write_file方法直接将bufferlist中的内容出到一个文件中；或者通过bufferlist::write_fd方法将bufferlist中的内容写入到某个fd中。</li><li>bufferraw负责管理系统内存的，bufferraw只关心一件事：维护其所管理的系统内存的引用计数，并且在引用计数减为0时——即没有ptr再使用这块内存时，释放这块内存。</li><li>bufferptr负责连接bufferlist和bufferraw。bufferptr关心的是如何使用内存。每一个bufferptr一定有一个bufferraw为其提供系统内存，然后ptr决定使用这块内存的哪一部分。bufferlist只用通过ptr才能对应到系统内存中，而bufferptr而可以独立存在，只是大部分ptr还是为bufferlist服务的，独立的ptr使用的场景并不是很多。<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_2.png"><br>通过引入ptr这样一个中间层次，bufferlist使用内存的方式可以非常灵活。</li></ul><ol><li>快速encode&#x2F;decode。在Ceph中经常需要将一个bufferlist编码（encode）到另一个bufferlist中，例如在msg发送消息的时候，通常msg拿到的osd等逻辑层传递给它的bufferlist，然后msg还需要给这个bufferlist加上消息头和消息尾，而消息头和消息尾也是用bufferlist表示的。这时候，msg通常会构造一个空的bufferlist，然后将消息头、消息尾、内容都encode到这个空的bufferlist。而bufferlist之间的encode实际只需要做ptr的copy，而不涉及到系统内存的申请和Copy，效率较高。</li><li>一次分配，多次使用。调用malloc之类的函数申请内存是非常重量级的操作。利用ptr这个中间层可以缓解这个问题，可以一次性申请一块较大的内存，也就是一个较大的bufferraw，然后每次需要内存的时候，构造一个bufferptr，指向这个bufferraw的不同部分。这样就不再需要向系统申请内存了。最后将这些ptr都加入到一个bufferlist中，就可以形成一个虚拟的连续内存。</li><li>减少内存分配次数和碎片。利用bufferptr这个中间层进行内存的多次使用，多个bufferptr可以引用同一段bufferraw的不同区域，这个bufferraw可以预先一次性申请较大一段连续内存，从而避免了多次申请内存以及内存碎片的产生。</li></ol><h4 id="buffer-raw"><a href="#buffer-raw" class="headerlink" title="buffer::raw"></a>buffer::raw</h4><p>raw的数据成员部分代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">char</span> *data;    <span class="comment">//数据指针</span></span><br><span class="line">    <span class="type">unsigned</span> len;     <span class="comment">//数据长度</span></span><br><span class="line">    std::atomic&lt;<span class="type">unsigned</span>&gt; nref&#123;<span class="number">0</span>&#125;;      <span class="comment">//引用计数</span></span><br><span class="line">    <span class="type">int</span> mempool; </span><br><span class="line">    <span class="keyword">mutable</span> ceph::spinlock crc_spinlock;     <span class="comment">//读写锁</span></span><br><span class="line">    map&lt;pair&lt;<span class="type">size_t</span>, <span class="type">size_t</span>&gt;, pair&lt;<span class="type">uint32_t</span>, <span class="type">uint32_t</span>&gt;&gt; crc_map;    <span class="comment">//crc校验信息</span></span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>最基本的成员：data是指向具体数据的指针，len是数据的长度，nref是引用计数。而mempool是其对应的内存池的index，这个和data空间的分配有关，暂时不去管它。</p><p>data指向的数据有很多来源，直接通过malloc从内存分配只是最基础的一种，可能还来自mmap内存映射的空间，甚至可以通过pipe管道＋splice实现零拷贝获取空间。有些时候，分配的空间时，会提出对齐的要求，比如按页对齐等等。对于每一种数据来源，需要不同逻辑的数据分配和释放函数，所以raw对应了很多子类，分别表示不同的数据。</p><p>下列类都继承了buffer::raw，实现了对data对应内存空间的申请</p><ol><li>类raw_malloc实现了用malloc函数分配内存空间的功能</li><li>类class buffer::raw_mmap_pages实现了通过mmap来把内存匿名映射到进程的地址空间</li><li>类class buffer::raw_posix_aligned调用了函数posix_memalign来申请内存地址对齐的内存空间。</li><li>类class buffer::raw_hack_aligned是在系统不支持内存对齐申请的情况下自己实现了内存地址的对齐</li><li>类class buffer::raw_pipe实现了pipe做为Buffer的内存空间</li><li>类class buffer::raw_char使用了C++的new操作符来申请空间</li></ol><p>这是因为这些来源不同，要求不同，buffer::raw也就有了一些变体，举个例子，对应于malloc的raw子类为buffer::raw_malloc，构造和析构函数中实现了使用malloc进行数据分配和释放的逻辑：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw_malloc : <span class="keyword">public</span> buffer::raw</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">raw_malloc</span><span class="params">(<span class="type">unsigned</span> l)</span> : raw(l)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">    <span class="keyword">if</span> (len)</span><br><span class="line">    &#123;</span><br><span class="line">        data = (<span class="type">char</span> *)<span class="built_in">malloc</span>(len);</span><br><span class="line">        <span class="keyword">if</span> (!data)</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">bad_alloc</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        data = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">    <span class="built_in">inc_history_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">raw_malloc</span>(<span class="type">unsigned</span> l, <span class="type">char</span> *b) : <span class="built_in">raw</span>(b, l)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">raw_malloc</span>() <span class="keyword">override</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">free</span>(data);</span><br><span class="line">    <span class="built_in">dec_total_alloc</span>(len);</span><br><span class="line">    bdout &lt;&lt; <span class="string">&quot;raw_malloc &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; free &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">raw *<span class="title">clone_empty</span><span class="params">()</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">raw_malloc</span>(len);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>对应于malloc的raw子类为buffer::raw_mmap_pages，顾名思义，也能够猜到，这个数据的来源是通过mmap分配的匿名内存映射。因此析构的时候，毫不意外，掉用munmap解除映射，归还空间给系统：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">buffer</span>::raw_mmap_pages : <span class="keyword">public</span> buffer::raw &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">raw_mmap_pages</span><span class="params">(<span class="type">unsigned</span> l)</span> : raw(l) &#123;</span></span><br><span class="line">        data = (<span class="type">char</span>*)::<span class="built_in">mmap</span>(<span class="literal">NULL</span>, len, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, <span class="number">-1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (!data)</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">bad_alloc</span>();</span><br><span class="line">        <span class="built_in">inc_total_alloc</span>(len);</span><br><span class="line">        <span class="built_in">inc_history_alloc</span>(len);</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;raw_mmap &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; alloc &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; l &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">raw_mmap_pages</span>() &#123;</span><br><span class="line">        ::<span class="built_in">munmap</span>(data, len);</span><br><span class="line">        <span class="built_in">dec_total_alloc</span>(len);</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;raw_mmap &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; free &quot;</span> &lt;&lt; (<span class="type">void</span> *)data &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; buffer::<span class="built_in">get_total_alloc</span>() &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">raw* <span class="title">clone_empty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">raw_mmap_pages</span>(len);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="buffer-ptr"><a href="#buffer-ptr" class="headerlink" title="buffer::ptr"></a>buffer::ptr</h3><p>buffer::ptr是在buffer::raw系列的基础上，这个类也别名bufferptr， 这个类是raw这个类的包装升级版本，它的_raw就是指向buffer::raw类型的变量。成员部分如下（include&#x2F;buffer.h）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> ptr</span><br><span class="line">&#123;</span><br><span class="line">    raw *_raw;</span><br><span class="line">    <span class="type">unsigned</span> _off, _len;</span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类buffer::ptr就是对于buffer::raw的一部分数据段，ptr是raw里的一个任意的数据段，_off是在_raw里的偏移量，_len是在ptr的长度。<br><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_3.png"><br>raw是真正存储数据的地方，而ptr只是指向某个raw中的一段的指针。其数据成员 _raw为指向raw的指针，_off表示数据起始偏移，_len表示数据长度。这边还有提一下ptr的append函数，直观上ptr不应该提供append函数，事实上ptr的append确实很局限，只有当ptr对应的raw区域后方有空闲空间的时候，才能append成功，至于空间不够的情况，应该是交给list等高层类来处理。代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> buffer::ptr::<span class="built_in">append</span>(<span class="type">const</span> <span class="type">char</span> *p, <span class="type">unsigned</span> l)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(l &lt;= <span class="built_in">unused_tail_length</span>());</span><br><span class="line">    <span class="type">char</span> *c = _raw-&gt;data + _off + _len;</span><br><span class="line">    <span class="built_in">maybe_inline_memcpy</span>(c, p, l, <span class="number">32</span>);</span><br><span class="line">    _len += l;</span><br><span class="line">    <span class="keyword">return</span> _len + _off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>buffer::ptr其他常见操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">buffer::ptr&amp; buffer::ptr::<span class="keyword">operator</span>= (<span class="type">const</span> ptr&amp; p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (p._raw) &#123;</span><br><span class="line">        p._raw-&gt;nref.<span class="built_in">inc</span>();</span><br><span class="line">        bdout &lt;&lt; <span class="string">&quot;ptr &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">&quot; get &quot;</span> &lt;&lt; _raw &lt;&lt; bendl;</span><br><span class="line">    &#125;</span><br><span class="line">    buffer::raw *raw = p._raw; </span><br><span class="line">    <span class="built_in">release</span>();</span><br><span class="line">    <span class="keyword">if</span> (raw) &#123;</span><br><span class="line">        _raw = raw;</span><br><span class="line">        _off = p._off;</span><br><span class="line">        _len = p._len;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        _off = _len = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">buffer::raw *buffer::ptr::<span class="built_in">clone</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">clone</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> buffer::ptr::<span class="built_in">swap</span>(ptr&amp; other)</span><br><span class="line">&#123;</span><br><span class="line">    raw *r = _raw;</span><br><span class="line">    <span class="type">unsigned</span> o = _off;</span><br><span class="line">    <span class="type">unsigned</span> l = _len;</span><br><span class="line">    _raw = other._raw;</span><br><span class="line">    _off = other._off;</span><br><span class="line">    _len = other._len;</span><br><span class="line">    other._raw = r;</span><br><span class="line">    other._off = o;</span><br><span class="line">    other._len = l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">char</span>&amp; buffer::ptr::<span class="keyword">operator</span>[](<span class="type">unsigned</span> n) <span class="type">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(n &lt; _len);</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">get_data</span>()[_off + n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span>&amp; buffer::ptr::<span class="keyword">operator</span>[](<span class="type">unsigned</span> n)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">assert</span>(_raw);</span><br><span class="line">    <span class="built_in">assert</span>(n &lt; _len);</span><br><span class="line">    <span class="keyword">return</span> _raw-&gt;<span class="built_in">get_data</span>()[_off + n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> buffer::ptr::<span class="built_in">cmp</span>(<span class="type">const</span> ptr&amp; o) <span class="type">const</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> l = _len &lt; o._len ? _len : o._len;</span><br><span class="line">    <span class="keyword">if</span> (l) &#123;</span><br><span class="line">        <span class="type">int</span> r = <span class="built_in">memcmp</span>(<span class="built_in">c_str</span>(), o.<span class="built_in">c_str</span>(), l);</span><br><span class="line">        <span class="keyword">if</span> (r)</span><br><span class="line">            <span class="keyword">return</span> r;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (_len &lt; o._len)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (_len &gt; o._len)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;                 </span><br></pre></td></tr></table></figure><h3 id="buffer-list"><a href="#buffer-list" class="headerlink" title="buffer::list"></a>buffer::list</h3><p>类buffer::list是一个使用广泛的类，它是多个buffer::ptr的列表，也就是多个内存数据段的列表。多个bufferptr形成一个list，这就是bufferlist。简单来说，list就是一个ptr组成的链表：（include&#x2F;buffer.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> list</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// my private bits</span></span><br><span class="line">std::list&lt;ptr&gt; _buffers;    <span class="comment">//所有的ptr</span></span><br><span class="line"><span class="type">unsigned</span> _len;       <span class="comment">//所有的ptr的数据总长度</span></span><br><span class="line"><span class="type">unsigned</span> _memcopy_count; <span class="comment">//当调用函数rebuild用来内存对齐时，需要内存拷贝的数据量</span></span><br><span class="line">ptr append_buffer;       <span class="comment">// 当有小的数据就添加到这个buffer里</span></span><br><span class="line">    <span class="keyword">mutable</span> iterator last_p;       <span class="comment">//访问list的迭代器</span></span><br><span class="line">......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph_Bufferlist%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BD%BF%E7%94%A8_4.png"><br>buffers是一个ptr的链表，_len是整个_buffers中所有的ptr的数据的总长度，_memcopy_count用于统计memcopy的字节数，append_buffer是用于优化append操作的缓冲区，可以看出bufferlist将数据以不连续链表的方式存储。</p><h3 id="bufferlist的迭代器"><a href="#bufferlist的迭代器" class="headerlink" title="bufferlist的迭代器"></a>bufferlist的迭代器</h3><p>迭代器中提供的seek(unsigned o)和advance(int o)等函数中的o都是指bufferlist的偏移，而不是单个ptr内的偏移。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> is_const&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CEPH_BUFFER_API</span> iterator_impl</span><br><span class="line">    : <span class="keyword">public</span> std::iterator&lt;std::forward_iterator_tag, <span class="type">char</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="type">bl_t</span> *bl;</span><br><span class="line">    <span class="type">list_t</span> *ls;   <span class="comment">// meh.. just here to avoid an extra pointer dereference..</span></span><br><span class="line">    <span class="type">unsigned</span> off; <span class="comment">// in bl</span></span><br><span class="line">    <span class="type">list_iter_t</span> p;</span><br><span class="line">    <span class="type">unsigned</span> p_off; <span class="comment">// in *p</span></span><br><span class="line">    ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其数据成员的含义如下：</p><ul><li>bl：指针，指向bufferlist</li><li>ls：指针，指向bufferlist的成员 _buffers</li><li>p: 类型是std::list::iterator，用来迭代遍历bufferlist中的bufferptr</li><li>p_off：当前位置在对应的bufferptr中的偏移量</li><li>off：当前位置在整个bufferlist中的偏移量</li></ul><h3 id="bufferlist常用函数"><a href="#bufferlist常用函数" class="headerlink" title="bufferlist常用函数"></a>bufferlist常用函数</h3><p>librados只给出bufferlist API</p><ol><li>clear()<br> 清空bufferlist中的内容</li><li>push_front(raw* &#x2F; ptr &amp;)<br>push_back(raw* &#x2F; ptr &amp;)<br> 在_buffers的前面或后面增加新的ptr</li><li>rebuild()<br>rebuild(ptr &amp;nb)<br> 将bufferlist中buffers链表中所有的ptr中的数据存到一个ptr中，并将_buffers原有数据clear，然后将新的单个ptr push到_buffers中。<br> 带参数时使用参数传入的ptr作为目标ptr，不带参数时自己创建一个ptr。</li><li>claim(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br> 将bl的数据拿过来，替换原有的数据。调用后bl数据被清空。</li><li>claim_append(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br>claim_prepend(list &amp;bl, unsigned int flags &#x3D; CLAIM_DEFAULT);<br> 将bl的数据拿过来，splice到_buffers的尾部&#x2F;头部。</li><li>append(…)<br> 将数据追加到_buffers尾部，已有ptr空间不够时，会自动分配新的ptr。</li><li>splice(unsigned off, unsigned len, list *claim_by &#x3D; 0)            bl.splice(10,10,&amp;bl2);<br> 将_buffers中总偏移off处长度为len的数据，move到claim_by对应的bufferlist的尾部。注意是move不是copy。</li><li>write(int off, int len, std::ostream &amp;out)<br> 将_buffers中总偏移量off处长度为len的数据，写入到ostream。注意是copy，不是move。</li><li>push_front(ptr&amp; pb)<br> 添加一个ptr到list头部</li><li>push_front(raw *r)<br>添加一个raw到list头部中，先构造一个ptr，后添加list中</li><li>is_aligned(align)<br>判断内存是否以参数align对齐，每一个ptr都必须以align对齐</li><li>read_fd()&#x2F;write_fd()<br>把数据写入文件描述符或者从文件描述符读取数据</li><li>read_file()&#x2F;write_file()<br>把数据写入文件或从文件读取数据的功能</li><li>write_stream()</li></ol><p>内存对齐：有些情况下，需要内存地址对齐，例如当以directIO方式写入数据至磁盘时，需要内存地址按照内存页面大小（page）对齐，也即buffer::list的内存地址都需按照page对齐。函数rebuild用来完成对齐的功能。其实现的方法也比较简单，检查没有对齐的ptr，申请一块新对齐的内存，把数据拷贝过去，释放内存空间就可以了。</p><p>相关链接：<br>    <a href="http://bean-li.github.io/bufferlist-in-ceph/">http://bean-li.github.io/bufferlist-in-ceph/</a><br>    <a href="https://www.jianshu.com/p/01e1f4e398df">https://www.jianshu.com/p/01e1f4e398df</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-Bufferlist的设计与使用&quot;&gt;&lt;a href=&quot;#Ceph-Bufferlist的设计与使用&quot; class=&quot;headerlink&quot; title=&quot;Ceph Bufferlist的设计与使用&quot;&gt;&lt;/a&gt;Ceph Bufferlist的设计与使用&lt;/</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph序列化</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2021-07-10T04:43:01.000Z</published>
    <updated>2024-07-27T14:36:56.441Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-数据序列化"><a href="#Ceph-数据序列化" class="headerlink" title="Ceph 数据序列化"></a>Ceph 数据序列化</h2><p>Ceph 作为主要处理磁盘和网络的分布式存储系统，数据序列化是其最基本的功能之一。当一个结构通过网络发送或写入磁盘时，它会被编码为一串字节。可序列化的结构体具有 encode 和 decode 方法，用于将结构体序列化后存入 bufferlist，或从 bufferlist 读取字节串并反序列化为结构体。</p><p>在 Ceph 中，经常需要将一个 bufferlist 编码（encode）到另一个 bufferlist 中。例如，在 msg 发送消息时，msg 通常会接收到由 OSD 等逻辑层传递给它的 bufferlist，然后 msg 需要给这个 bufferlist 添加消息头和消息尾，而消息头和消息尾也是用 bufferlist 表示的。在这种情况下，msg 通常会构造一个空的 bufferlist，然后将消息头、消息尾和内容都编码到这个空的 bufferlist 中。</p><p>在 bufferlist 之间进行编码实际上只需要进行指针的复制，而不涉及系统内存的申请和复制，因此效率较高。encode 和 decode 方法的主要作用是方便 Ceph 不同模块之间的参数传输。</p><p>在Ceph代码中有很多例子，这里有一个例子。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AcmeClass</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> member1;</span><br><span class="line">    std::string member2;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">encode</span><span class="params">(bufferlist &amp;bl)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">ENCODE_START</span>(<span class="number">1</span>, <span class="number">1</span>, bl);</span><br><span class="line">        ::<span class="built_in">encode</span>(member1, bl);</span><br><span class="line">        ::<span class="built_in">encode</span>(member2, bl);</span><br><span class="line">        <span class="built_in">ENCODE_FINISH</span>(bl);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">decode</span><span class="params">(bufferlist::iterator &amp;bl)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">DECODE_START</span>(<span class="number">1</span>, bl);</span><br><span class="line">        ::<span class="built_in">decode</span>(member1, bl);</span><br><span class="line">        ::<span class="built_in">decode</span>(member2, bl);</span><br><span class="line">        <span class="built_in">DECODE_FINISH</span>(bl);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>ENCODE_START</code>宏写入标头 说明version和 compat_version（初值均为 1）。每当对encode进行更改时，version就会增加。仅当更改会影响decode时compat_version才会增加  - 比如新结构体只在尾部添加字段，不会影响旧结构体的解析，因此在结构末尾添加字段的更改不需要增加 compat_version。<br><code>DECODE_START</code>宏采用一个参数，指定encode代码可以处理的最新消息版本。这与消息中编码的 compat_version 进行比较，如果消息太新，则会抛出异常。因为对 compat_verison 的更改很少，所以在添加字段时通常不需要担心。</p><h2 id="Ceph序列化的方式"><a href="#Ceph序列化的方式" class="headerlink" title="Ceph序列化的方式"></a>Ceph序列化的方式</h2><p>序列化（在 Ceph 中称为 encode）的目的是将数据结构表示为二进制流，以便通过网络传输或保存在磁盘等存储介质上。其逆过程称为反序列化（在 Ceph 中称为 decode）。例如，对于字符串“abc”，其序列化结果为7个字节（bytes）：03 00 00 00 61 62 63，其中前四个字节（03 00 00 00）表示字符串的长度为3个字符，后三个字节（61 62 63）分别是字符“abc”的 ASCII 码的十六进制表示。Ceph 采用 little-endian 的序列化方式，即低地址存放最低有效字节，因此32位整数0x12345678的序列化结果为78 56 34 12。</p><p>由于序列化在整个 Ceph 系统中是非常基础且常用的功能，Ceph 将其序列化方式设计为统一的结构，即任何支持序列化的数据结构都必须提供一对定义在全局命名空间中的序列化&#x2F;反序列化（encode&#x2F;decode）函数。例如，如果我们定义了一个结构体 inode，就必须在全局命名空间中定义以下两个方法：</p><ol><li><code>encode(struct inode, bufferlist bl);</code></li><li><code>decode(struct inode, bufferlist::iterator bl);</code></li></ol><p>在此基础上，序列化的使用变得非常简单。对于任意可序列化的类型 T 的实例 instance_T，可以通过如下语句将 instance_T 序列化并保存到 bufferlist 类的实例 instance_bufferlist 中。</p><p>bufferlist类（定义于include&#x2F;buffer.h）是ceph核心的缓存类，用于保存序列化结果、数据缓存、网络通信等，能够将bufferlist理解为一个可变长度的char数组。</p><p>如下代码演示了将一个时间戳以及一个inode序列化到一个bufferlist中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">utime_t</span> timestamp;</span><br><span class="line"><span class="type">inode_t</span> inode;</span><br><span class="line">bufferlist bl;</span><br><span class="line">::<span class="built_in">encode</span>(timetamp, bl)</span><br><span class="line">::<span class="built_in">encode</span>(inode, bl);</span><br></pre></td></tr></table></figure><p>序列化后的数据能够经过反序列化方法读取，例如如下代码片断从一个bufferlist中反序列化一个时间戳和一个inode（前提是该bl中已经被序列化了一个utime_t和一个inode，不然会报错）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bufferlist::iterator bl;</span><br><span class="line">::<span class="built_in">decode</span>(timetamp, bl)</span><br><span class="line">::<span class="built_in">decode</span>(inode, bl);</span><br></pre></td></tr></table></figure><h2 id="各种数据类型的序列化"><a href="#各种数据类型的序列化" class="headerlink" title="各种数据类型的序列化"></a>各种数据类型的序列化</h2><p>Ceph为其全部用到数据类型提供了序列化方法或反序列化方法，这些数据类型包括了绝大部分<code>基础数据类型（int、bool等）</code>、<code>结构体类型的序列化（ceph_mds_request_head等）</code>、<code>集合类型（vector、list、set、map等）</code>、以及<code>自定义的复杂数据类型（例如表示inode的inode_t等）</code>，如下分别介绍不一样数据类型的序列化实现方式。</p><h4 id="1、基本数据类型的序列化"><a href="#1、基本数据类型的序列化" class="headerlink" title="1、基本数据类型的序列化"></a>1、基本数据类型的序列化</h4><p>基本数据类型的序列化结果基本就是该类型在内存中的表示形式。基本数据类型的序列化方法使用手工编写，定义在include&#x2F;encoding.h中，包括如下类型：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__u8, __s8, <span class="type">char</span>, <span class="type">bool</span></span><br><span class="line">ceph_le64, ceph_le32, ceph_le16,</span><br><span class="line"><span class="type">float</span>, <span class="type">double</span>,</span><br><span class="line"><span class="type">uint64_t</span>, <span class="type">int64_t</span>, <span class="type">uint32_t</span>, <span class="type">int32_t</span>, <span class="type">uint16_t</span>, <span class="type">int16_t</span>,</span><br><span class="line">string, <span class="type">char</span>*</span><br></pre></td></tr></table></figure><p>在手工编写encode方法过程当中，为了不重复代码，借助了WRITE_RAW_ENCODER和WRITE_INTTYPE_ENCODER两个宏。</p><h4 id="2、结构体类型的序列化"><a href="#2、结构体类型的序列化" class="headerlink" title="2、结构体类型的序列化"></a>2、结构体类型的序列化</h4><p>结构体类型的序列化方法与基本数据类型的序列化方法一致，即便用结构体的内存布局做为序列化的形式。在结构体定义完成后，经过调用WRITE_RAW_ENCODER宏函数生成结构体的全局encode方法，例如结构体ceph_mds_request_head相关结构实现以下。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ceph_mds_request_head</span> &#123;</span><br><span class="line">    __le64 oldest_client_tid;</span><br><span class="line">    __le32 mdsmap_epoch;</span><br><span class="line">    __le32 flags;</span><br><span class="line">    __u8 num_retry, num_fwd;</span><br><span class="line">    __le16 num_releases;</span><br><span class="line">    __le32 op;</span><br><span class="line">    __le32 caller_uid, caller_gid;</span><br><span class="line">    __le64 ino;</span><br><span class="line">&#125; __attribute__ ((packed));</span><br><span class="line"><span class="built_in">WRITE_RAW_ENCODER</span>(ceph_mds_request_head)</span><br></pre></td></tr></table></figure><p>其中：<br>    ceph_mds_request_head结构体定义在include&#x2F;ceph_fs.h . WRITE_RAW_ENCODER(ceph_mds_request_head)语句位于include&#x2F;types.h WRITE_RAW_ENCODER宏函数定义在include&#x2F;encoding.h WRITE_RAW_ENCODER宏函数其实是经过调用encode_raw实现的，而encode_raw调用bufferlist的append的方法，经过内存拷贝，将数据结构放入到bufferlist中。相关代码为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">encode_raw</span><span class="params">(<span class="type">const</span> T&amp; t, bufferlist&amp; bl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    bl.<span class="built_in">append</span>((<span class="type">char</span>*)&amp;t, <span class="built_in">sizeof</span>(t));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">decode_raw</span><span class="params">(T&amp; t, bufferlist::iterator &amp;p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    p.<span class="built_in">copy</span>(<span class="built_in">sizeof</span>(t), (<span class="type">char</span>*)&amp;t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、集合数据类型的序列化"><a href="#3、集合数据类型的序列化" class="headerlink" title="3、集合数据类型的序列化"></a>3、集合数据类型的序列化</h4><p>集合数据类型序列化的基本思路包括两步：</p><ul><li>序列化集合大小，</li><li>序列化集合内的全部元素</li></ul><p>例如vector<T>&amp; v的序列化方法：其中元素的序列化经过调用该元素的encode方法实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">encode</span><span class="params">(<span class="type">const</span> std::vector&lt;T&gt;&amp; v, bufferlist&amp; bl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __u32 n = v.<span class="built_in">size</span>();</span><br><span class="line">    <span class="built_in">encode</span>(n, bl);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">typename</span> std::vector&lt;T&gt;::const_iterator p = v.<span class="built_in">begin</span>(); p != v.<span class="built_in">end</span>(); ++p)</span><br><span class="line">    <span class="built_in">encode</span>(*p, bl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经常使用集合数据类型的序列化已经由Ceph实现，位于include&#x2F;encoding.h中，包括如下集合类型：pair, triple, list, set, vector, map, multimap, hash_map, hash_set, deque。集合类型的序列化方法皆为基于泛型（模板类）的实现方式，适用于全部泛型派生类。</p><h4 id="4、复杂数据类型的序列化"><a href="#4、复杂数据类型的序列化" class="headerlink" title="4、复杂数据类型的序列化"></a>4、复杂数据类型的序列化</h4><p>除以上两种业务无关的数据类型外，其它数据类型的序列化实现包括两部分： 在类型内部现实encode方法，将类型内部的encode方法重定义为全局方法。如下以utime_t类为例：utime_t内部实现了encode和decode两个方法，WRITE_CLASS_ENCODER宏函数将这两个方法转化为全局方法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">utime_t</span> &#123;</span><br><span class="line">    <span class="keyword">struct</span> &#123;</span><br><span class="line">    __u32 tv_sec, tv_nsec;</span><br><span class="line">    &#125; tv;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">encode</span><span class="params">(bufferlist &amp;bl)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    ::<span class="built_in">encode</span>(tv.tv_sec, bl);</span><br><span class="line">    ::<span class="built_in">encode</span>(tv.tv_nsec, bl);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">decode</span><span class="params">(bufferlist::iterator &amp;p)</span> </span>&#123;</span><br><span class="line">    ::<span class="built_in">decode</span>(tv.tv_sec, p);</span><br><span class="line">    ::<span class="built_in">decode</span>(tv.tv_nsec, p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">WRITE_CLASS_ENCODER</span>(<span class="type">utime_t</span>)</span><br></pre></td></tr></table></figure><p>复杂数据结构内部的encode方法的实现方式一般是调用其内部主要数据结构的encode方法，例如utime_t类的encode方法其实是序列化内部的tv.tv_sec和tv.tv_nsec两个成员。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-数据序列化&quot;&gt;&lt;a href=&quot;#Ceph-数据序列化&quot; class=&quot;headerlink&quot; title=&quot;Ceph 数据序列化&quot;&gt;&lt;/a&gt;Ceph 数据序列化&lt;/h2&gt;&lt;p&gt;Ceph 作为主要处理磁盘和网络的分布式存储系统，数据序列化是其最基本的功能</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph相关数据结构</title>
    <link href="https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://watsonlu6.github.io/Ceph%E7%9B%B8%E5%85%B3%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-07-02T15:33:02.000Z</published>
    <updated>2024-07-27T14:36:43.411Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph-相关数据结构"><a href="#Ceph-相关数据结构" class="headerlink" title="Ceph 相关数据结构"></a>Ceph 相关数据结构</h2><p>要想深入到Ceph的源码底层，就必须对代码通用库里的一些关键，常见的数据结构进行学习，这样才能更好的理解源代码。从最高的逻辑层次为<code>Pool</code>的概念，然后是<code>PG</code>的概念。其次是<code>OSDＭap</code>记录了集群的所有的配置信息。数据结构<code>OSDOp</code>是一个操作上下文的封装。结构<code>object_info_t</code>保存了一个元数据信息和访问信息。对象<code>ObjectState</code>是在<code>object_info_t</code>基础上添加了一些内存的状态信息。<code>SnapSetContext</code>和<code>ObjectContext</code>分别保存了快照和对象上下文相关的信息。<code>Session</code>保存了一个端到端的链接相关的上下文。</p><h3 id="Pool"><a href="#Pool" class="headerlink" title="Pool"></a>Pool</h3><p><code>Pool</code>是整个集群层面定义的一个逻辑的存储池。对一个Pool可以设置相应的数据冗余类型，目前有副本和纠删码两种实现。数据结构pg_pool_t用于保存Pool的相关信息。<br>Pool的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">pg_pool_t</span> &#123;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_CEPHFS;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_RBD;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">char</span> *APPLICATION_NAME_RGW;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">enum</span> &#123;</span><br><span class="line">    TYPE_REPLICATED = <span class="number">1</span>,     <span class="comment">// replication  副本   </span></span><br><span class="line">    <span class="comment">//TYPE_RAID4 = 2,   // raid4 (never implemented)   从来没实现的raid4</span></span><br><span class="line">    TYPE_ERASURE = <span class="number">3</span>,      <span class="comment">// erasure-coded   纠删码</span></span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">enum</span> &#123;</span><br><span class="line">    FLAG_HASHPSPOOL = <span class="number">1</span>&lt;&lt;<span class="number">0</span>, <span class="comment">// hash pg seed and pool together (instead of adding)</span></span><br><span class="line">    FLAG_FULL       = <span class="number">1</span>&lt;&lt;<span class="number">1</span>, <span class="comment">// pool is full</span></span><br><span class="line">    FLAG_EC_OVERWRITES = <span class="number">1</span>&lt;&lt;<span class="number">2</span>, <span class="comment">// enables overwrites, once enabled, cannot be disabled</span></span><br><span class="line">    FLAG_INCOMPLETE_CLONES = <span class="number">1</span>&lt;&lt;<span class="number">3</span>, <span class="comment">// may have incomplete clones (bc we are/were an overlay)</span></span><br><span class="line">    FLAG_NODELETE = <span class="number">1</span>&lt;&lt;<span class="number">4</span>, <span class="comment">// pool can&#x27;t be deleted</span></span><br><span class="line">    FLAG_NOPGCHANGE = <span class="number">1</span>&lt;&lt;<span class="number">5</span>, <span class="comment">// pool&#x27;s pg and pgp num can&#x27;t be changed</span></span><br><span class="line">    FLAG_NOSIZECHANGE = <span class="number">1</span>&lt;&lt;<span class="number">6</span>, <span class="comment">// pool&#x27;s size and min size can&#x27;t be changed</span></span><br><span class="line">    FLAG_WRITE_FADVISE_DONTNEED = <span class="number">1</span>&lt;&lt;<span class="number">7</span>, <span class="comment">// write mode with LIBRADOS_OP_FLAG_FADVISE_DONTNEED</span></span><br><span class="line">    FLAG_NOSCRUB = <span class="number">1</span>&lt;&lt;<span class="number">8</span>, <span class="comment">// block periodic scrub</span></span><br><span class="line">    FLAG_NODEEP_SCRUB = <span class="number">1</span>&lt;&lt;<span class="number">9</span>, <span class="comment">// block periodic deep-scrub</span></span><br><span class="line">    FLAG_FULL_QUOTA = <span class="number">1</span>&lt;&lt;<span class="number">10</span>, <span class="comment">// pool is currently running out of quota, will set FLAG_FULL too</span></span><br><span class="line">    FLAG_NEARFULL = <span class="number">1</span>&lt;&lt;<span class="number">11</span>, <span class="comment">// pool is nearfull</span></span><br><span class="line">    FLAG_BACKFILLFULL = <span class="number">1</span>&lt;&lt;<span class="number">12</span>, <span class="comment">// pool is backfillfull</span></span><br><span class="line">    FLAG_SELFMANAGED_SNAPS = <span class="number">1</span>&lt;&lt;<span class="number">13</span>, <span class="comment">// pool uses selfmanaged snaps</span></span><br><span class="line">    FLAG_POOL_SNAPS = <span class="number">1</span>&lt;&lt;<span class="number">14</span>,        <span class="comment">// pool has pool snaps</span></span><br><span class="line">    FLAG_CREATING = <span class="number">1</span>&lt;&lt;<span class="number">15</span>,          <span class="comment">// initial pool PGs are being created</span></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="type">utime_t</span> create_time;      <span class="comment">//Pool创建时间</span></span><br><span class="line">  <span class="type">uint64_t</span> flags;           <span class="comment">///&lt; FLAG_*   Pool的相关标志</span></span><br><span class="line">  __u8 type;                <span class="comment">///&lt; TYPE_*   类型</span></span><br><span class="line">  __u8 size, min_size;     <span class="comment">///&lt;Pool的size和min_size，即副本数和至少保证的副本数</span></span><br><span class="line">  __u8 crush_rule;          <span class="comment">///&lt; crush placement rule    rule的编号</span></span><br><span class="line">  __u8 object_hash;         <span class="comment">///&lt; hash mapping object name to ps   对象映射的hash函数</span></span><br><span class="line">  __u8 pg_autoscale_mode;   <span class="comment">///&lt; PG_AUTOSCALE_MODE_        PG数自动增减模式</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  __u32 pg_num = <span class="number">0</span>, pgp_num = <span class="number">0</span>;  <span class="comment">///&lt; pg、pgp的数量</span></span><br><span class="line">  __u32 pg_num_pending = <span class="number">0</span>;       <span class="comment">///&lt; pg_num we are about to merge down to</span></span><br><span class="line">  __u32 pg_num_target = <span class="number">0</span>;        <span class="comment">///&lt; pg_num we should converge toward</span></span><br><span class="line">  __u32 pgp_num_target = <span class="number">0</span>;       <span class="comment">///&lt; pgp_num we should converge toward</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  map&lt;string,string&gt; properties;  <span class="comment">///&lt; OBSOLETE</span></span><br><span class="line">  string erasure_code_profile; <span class="comment">///&lt; name of the erasure code profile in OSDMap</span></span><br><span class="line">  <span class="type">epoch_t</span> last_change;      <span class="comment">///&lt; most recent epoch changed, exclusing snapshot changes</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend (pre-nautilus clients only)</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend_prenautilus = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">/// last epoch that forced clients to resend (pre-luminous clients only)</span></span><br><span class="line">  <span class="type">epoch_t</span> last_force_op_resend_preluminous = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// metadata for the most recent PG merge</span></span><br><span class="line">  <span class="type">pg_merge_meta_t</span> last_pg_merge_meta;</span><br><span class="line">  </span><br><span class="line">  <span class="type">snapid_t</span> snap_seq;        <span class="comment">///&lt; seq for per-pool snapshot</span></span><br><span class="line">  <span class="type">epoch_t</span> snap_epoch;       <span class="comment">///&lt; osdmap epoch of last snap</span></span><br><span class="line">  <span class="type">uint64_t</span> auid;            <span class="comment">///&lt; who owns the pg</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> quota_max_bytes; <span class="comment">///&lt; maximum number of bytes for this pool</span></span><br><span class="line">  <span class="type">uint64_t</span> quota_max_objects; <span class="comment">///&lt; maximum number of objects for this pool</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Pool snaps (global to this pool).  These define a SnapContext for</span></span><br><span class="line"><span class="comment">   * the pool, unless the client manually specifies an alternate</span></span><br><span class="line"><span class="comment">   * context.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  map&lt;<span class="type">snapid_t</span>, <span class="type">pool_snap_info_t</span>&gt; snaps;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Alternatively, if we are defining non-pool snaps (e.g. via the</span></span><br><span class="line"><span class="comment">   * Ceph MDS), we must track @removed_snaps (since @snaps is not</span></span><br><span class="line"><span class="comment">   * used).  Snaps and removed_snaps are to be used exclusive of each</span></span><br><span class="line"><span class="comment">   * other!</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  interval_set&lt;<span class="type">snapid_t</span>&gt; removed_snaps;</span><br><span class="line"></span><br><span class="line">  <span class="type">unsigned</span> pg_num_mask, pgp_num_mask;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Tier cache : Base Storage = N : 1</span></span><br><span class="line">  <span class="comment">// ceph osd tier add &#123;data_pool&#125; &#123;cache pool&#125;</span></span><br><span class="line">  set&lt;<span class="type">uint64_t</span>&gt; tiers;      <span class="comment">///&lt; pools that are tiers of us</span></span><br><span class="line">  <span class="type">int64_t</span> tier_of;         <span class="comment">///&lt; pool for which we are a tier</span></span><br><span class="line">  <span class="comment">// Note that write wins for read+write ops</span></span><br><span class="line">  <span class="comment">// WriteBack mode, read_tier is same as write_tier. Both are cache pool.</span></span><br><span class="line">  <span class="comment">// Diret mode. cache pool is read_tier, not write_tier. </span></span><br><span class="line">  <span class="comment">// ceph osd tier set-overlay &#123;data_pool&#125; &#123;cache_pool&#125;</span></span><br><span class="line">  <span class="type">int64_t</span> read_tier;       <span class="comment">///&lt; pool/tier for objecter to direct reads to</span></span><br><span class="line">  <span class="type">int64_t</span> write_tier;      <span class="comment">///&lt; pool/tier for objecter to direct writes to</span></span><br><span class="line">  <span class="comment">// Set cache mode</span></span><br><span class="line">  <span class="comment">// ceph osd tier cache-mode &#123;cache-pool&#125; &#123;cache-mode&#125;</span></span><br><span class="line">  <span class="type">cache_mode_t</span> cache_mode;  <span class="comment">///&lt; cache pool mode</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> target_max_bytes;   <span class="comment">///&lt; tiering: target max pool size</span></span><br><span class="line">  <span class="type">uint64_t</span> target_max_objects; <span class="comment">///&lt; tiering: target max pool size</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 目标脏数据率：当脏数据比例达到这个值，后台 agent 开始 flush 数据</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_dirty_ratio_micro; <span class="comment">///&lt; cache: fraction of target to leave dirty</span></span><br><span class="line">  <span class="comment">// 高目标脏数据率：当脏数据比例达到这个值，后台 agent 开始高速 flush 数据</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_dirty_high_ratio_micro; <span class="comment">///&lt; cache: fraction of  target to flush with high speed</span></span><br><span class="line">  <span class="comment">// 数据满的比率：当数据达到这个比例时，认为数据已满，需要进行缓存淘汰</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_target_full_ratio_micro;  <span class="comment">///&lt; cache: fraction of target to fill before we evict in earnest</span></span><br><span class="line">  <span class="comment">// 对象在 cache 中被刷入到 storage 层的最小时间</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_min_flush_age;  <span class="comment">///&lt; minimum age (seconds) before we can flush</span></span><br><span class="line">  <span class="comment">// 对象在 cache 中被淘汰的最小时间</span></span><br><span class="line">  <span class="type">uint32_t</span> cache_min_evict_age;  <span class="comment">///&lt; minimum age (seconds) before we can evict</span></span><br><span class="line">  <span class="comment">// HitSet 相关参数</span></span><br><span class="line">  HitSet::Params hit_set_params; <span class="comment">///&lt; The HitSet params to use on this pool</span></span><br><span class="line">  <span class="comment">// 每间隔 hit_set_period 一段时间，系统重新产生一个新的 hit_set 对象来记录对象的h缓存统计信息</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_period;      <span class="comment">///&lt; periodicity of HitSet segments (seconds)</span></span><br><span class="line">  <span class="comment">// 记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_count;       <span class="comment">///&lt; number of periods to retain</span></span><br><span class="line">  <span class="comment">// hitset archive 对象的命名规则 </span></span><br><span class="line">  <span class="type">bool</span> use_gmt_hitset;        <span class="comment">///&lt; use gmt to name the hitset archive object</span></span><br><span class="line">  <span class="type">uint32_t</span> min_read_recency_for_promote;   <span class="comment">///&lt; minimum number of HitSet to check before promote on read</span></span><br><span class="line">  <span class="type">uint32_t</span> min_write_recency_for_promote;  <span class="comment">///&lt; minimum number of HitSet to check before promote on write</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_grade_decay_rate;   <span class="comment">///&lt; current hit_set has highest priority on objects</span></span><br><span class="line">                                       <span class="comment">///&lt; temperature count,the follow hit_set&#x27;s priority decay </span></span><br><span class="line">                                       <span class="comment">///&lt; by this params than pre hit_set</span></span><br><span class="line">                                       <span class="comment">//当前hit_set在对象温度计数上具有最高优先级，后续hit_set的优先级比预hit_set衰减此参数</span></span><br><span class="line">  <span class="type">uint32_t</span> hit_set_search_last_n;   <span class="comment">///&lt; accumulate atmost N hit_sets for temperature  为温度累积最多N次hit_sets</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint32_t</span> stripe_width;        <span class="comment">///&lt; erasure coded stripe size in bytes</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> expected_num_objects; <span class="comment">///&lt; expected number of objects on this pool, a value of 0 indicates</span></span><br><span class="line">                                 <span class="comment">///&lt; user does not specify any expected value</span></span><br><span class="line">  <span class="type">bool</span> fast_read;            <span class="comment">///&lt; whether turn on fast read on the pool or not</span></span><br><span class="line">  <span class="type">pool_opts_t</span> opts; <span class="comment">///&lt; options</span></span><br><span class="line">  <span class="comment">/// application -&gt; key/value metadata</span></span><br><span class="line">  map&lt;string, std::map&lt;string, string&gt;&gt; application_metadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  vector&lt;<span class="type">uint32_t</span>&gt; grade_table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">get_grade</span><span class="params">(<span class="type">unsigned</span> i)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (grade_table.<span class="built_in">size</span>() &lt;= i)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> grade_table[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">calc_grade_table</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> v = <span class="number">1000000</span>;</span><br><span class="line">    grade_table.<span class="built_in">resize</span>(hit_set_count);        <span class="comment">// hit_set_count记录系统保存最近的多少个 hit_set 记录</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">unsigned</span> i = <span class="number">0</span>; i &lt; hit_set_count; i++) &#123;</span><br><span class="line">      v = v * (<span class="number">1</span> - (hit_set_grade_decay_rate / <span class="number">100.0</span>));</span><br><span class="line">      grade_table[i] = v;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>数据结构pg_pool_t的成员变量和方法较多，不一一介绍了。</p><h2 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h2><p><code>PG</code>可以认为是一组对象的集合，该集合里的对象有共同特征：副本都分布在相同的OSD列表中。结构体pg_t只是一个PG的静态描述信息（只有三个成员变量），类PG及其子类ReplicatedPG都是和PG相关的处理。<br>pg_t的数据结构如下：（src&#x2F;osd&#x2F;osd_types.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">pg_t</span> &#123;</span><br><span class="line">  <span class="type">uint64_t</span> m_pool;    <span class="comment">//pg所在的pool</span></span><br><span class="line">  <span class="type">uint32_t</span> m_seed;    <span class="comment">//pg的序号</span></span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">uint8_t</span> calc_name_buf_size = <span class="number">36</span>;  <span class="comment">// max length for max values len(&quot;18446744073709551615.ffffffff&quot;) + future suffix len(&quot;_head&quot;) + &#x27;\0&#x27;</span></span><br><span class="line">  <span class="function"><span class="type">hobject_t</span> <span class="title">get_hobj_start</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">hobject_t</span> <span class="title">get_hobj_end</span><span class="params">(<span class="type">unsigned</span> pg_num)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">generate_test_instances</span><span class="params">(list&lt;<span class="type">pg_t</span>*&gt;&amp; o)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="OSDMap"><a href="#OSDMap" class="headerlink" title="OSDMap"></a>OSDMap</h2><p><code>OSDMap类</code>定义了Ceph整个集群的全局信息。它由Monitor实现管理，并以全量或者增量的方式向整个集群扩散。每一个epoch对应的OSDMap都需要持久化保存在meta下对应对象的omap属性中。内部类Incremental以增量的形式保存了OSDMap新增的信息。OSDMap包含了四类信息：首先是集群的信息，其次是pool的信息，然后是临时PG相关信息，最后就是所有OSD的状态信息。<br>OSDMap类的数据结构如下：（src&#x2F;osd&#x2F;OSDMap.h）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OSDMap</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">typedef</span> interval_set&lt;</span><br><span class="line">    <span class="type">snapid_t</span>,</span><br><span class="line">    mempool::osdmap::flat_map&lt;<span class="type">snapid_t</span>,<span class="type">snapid_t</span>&gt;&gt; <span class="type">snap_interval_set_t</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Incremental</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MEMPOOL_CLASS_HELPERS</span>();</span><br><span class="line"><span class="comment">//系统相关的信息</span></span><br><span class="line">    <span class="comment">/// feature bits we were encoded with.  the subsequent OSDMap</span></span><br><span class="line">    <span class="comment">/// encoding should match.</span></span><br><span class="line">    <span class="type">uint64_t</span> encode_features;</span><br><span class="line">    uuid_d fsid;    <span class="comment">//当前集群的fsid值</span></span><br><span class="line">    <span class="type">epoch_t</span> epoch; <span class="comment">//当前集群的epoch值 new epoch; we are a diff from epoch-1 to epoch</span></span><br><span class="line">    <span class="type">utime_t</span> modified;   <span class="comment">//创建修改的时间戳</span></span><br><span class="line">    <span class="type">int64_t</span> new_pool_max; <span class="comment">//incremented by the OSDMonitor on each pool create</span></span><br><span class="line">    <span class="type">int32_t</span> new_flags;</span><br><span class="line">    <span class="type">int8_t</span> new_require_osd_release = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// full (rare)</span></span><br><span class="line">    bufferlist fullmap;  <span class="comment">// in lieu of below.</span></span><br><span class="line">    bufferlist crush;</span><br><span class="line">......</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">//集群相关的信息</span></span><br><span class="line">  uuid_d fsid;     <span class="comment">//当前集群的fsid值</span></span><br><span class="line">  <span class="type">epoch_t</span> epoch;        <span class="comment">//当前集群的epoch值 what epoch of the osd cluster descriptor is this</span></span><br><span class="line">  <span class="type">utime_t</span> created, modified; <span class="comment">//创建、修改的时间戳 epoch start time   </span></span><br><span class="line">  <span class="type">int32_t</span> pool_max;     <span class="comment">//最大的pool数量 the largest pool num, ever</span></span><br><span class="line">  <span class="type">uint32_t</span> flags;       <span class="comment">//一些标志信息</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">//OSD相关的信息</span></span><br><span class="line">  <span class="type">int</span> num_osd;         <span class="comment">//OSD的总数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int</span> num_up_osd;      <span class="comment">//处于up状态的OSD的数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int</span> num_in_osd;      <span class="comment">//处于in状态的OSD的数量 not saved; see calc_num_osds</span></span><br><span class="line">  <span class="type">int32_t</span> max_osd;     <span class="comment">//OSD的最大数目</span></span><br><span class="line">  vector&lt;<span class="type">uint32_t</span>&gt; osd_state;      <span class="comment">//OSD的状态</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int32_t</span>,<span class="type">uint32_t</span>&gt; crush_node_flags; <span class="comment">// crush node -&gt; CEPH_OSD_* flags</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int32_t</span>,<span class="type">uint32_t</span>&gt; device_class_flags; <span class="comment">// device class -&gt; CEPH_OSD_* flags</span></span><br><span class="line"></span><br><span class="line">  <span class="type">utime_t</span> last_up_change, last_in_change;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// These features affect OSDMap[::Incremental] encoding, or the</span></span><br><span class="line">  <span class="comment">// encoding of some type embedded therein (CrushWrapper, something</span></span><br><span class="line">  <span class="comment">// from osd_types, etc.).</span></span><br><span class="line">  <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">uint64_t</span> SIGNIFICANT_FEATURES =</span><br><span class="line">    CEPH_FEATUREMASK_PGID64 |</span><br><span class="line">    CEPH_FEATUREMASK_PGPOOL3 |</span><br><span class="line">    CEPH_FEATUREMASK_OSDENC |</span><br><span class="line">    CEPH_FEATUREMASK_OSDMAP_ENC |</span><br><span class="line">    CEPH_FEATUREMASK_OSD_POOLRESEND |</span><br><span class="line">    CEPH_FEATUREMASK_NEW_OSDOP_ENCODING |</span><br><span class="line">    CEPH_FEATUREMASK_MSG_ADDR2 |</span><br><span class="line">    CEPH_FEATUREMASK_CRUSH_TUNABLES5 |</span><br><span class="line">    CEPH_FEATUREMASK_CRUSH_CHOOSE_ARGS |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_LUMINOUS |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_MIMIC |</span><br><span class="line">    CEPH_FEATUREMASK_SERVER_NAUTILUS;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">addrs_s</span> &#123;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; client_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; cluster_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; hb_back_addrs;</span><br><span class="line">    mempool::osdmap::vector&lt;std::shared_ptr&lt;<span class="type">entity_addrvec_t</span>&gt; &gt; hb_front_addrs;</span><br><span class="line">  &#125;;</span><br><span class="line">  </span><br><span class="line">  std::shared_ptr&lt;addrs_s&gt; osd_addrs;    <span class="comment">//OSD的地址</span></span><br><span class="line">  <span class="type">entity_addrvec_t</span> _blank_addrvec;</span><br><span class="line">  mempool::osdmap::vector&lt;__u32&gt;   osd_weight;   <span class="comment">//OSD的权重 16.16 fixed point, 0x10000 = &quot;in&quot;, 0 = &quot;out&quot;</span></span><br><span class="line">  mempool::osdmap::vector&lt;<span class="type">osd_info_t</span>&gt; osd_info;    <span class="comment">//OSD 的基本信息</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::vector&lt;uuid_d&gt; &gt; osd_uuid;  <span class="comment">//OSD对应的uuid</span></span><br><span class="line">  mempool::osdmap::vector&lt;<span class="type">osd_xinfo_t</span>&gt; osd_xinfo;   <span class="comment">//OSD一些扩展信息</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//PG相关的信息</span></span><br><span class="line">  std::shared_ptr&lt;PGTempMap&gt; pg_temp;  <span class="comment">// temp pg mapping (e.g. while we rebuild)</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::map&lt;<span class="type">pg_t</span>,<span class="type">int32_t</span> &gt; &gt; primary_temp;  <span class="comment">// temp primary mapping (e.g. while we rebuild)</span></span><br><span class="line">  std::shared_ptr&lt; mempool::osdmap::vector&lt;__u32&gt; &gt; osd_primary_affinity; <span class="comment">///&lt; 16.16 fixed point, 0x10000 = baseline</span></span><br><span class="line">  <span class="comment">// remap (post-CRUSH, pre-up)</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">pg_t</span>,mempool::osdmap::vector&lt;<span class="type">int32_t</span>&gt;&gt; pg_upmap; <span class="comment">///&lt; remap pg</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">pg_t</span>,mempool::osdmap::vector&lt;pair&lt;<span class="type">int32_t</span>,<span class="type">int32_t</span>&gt;&gt;&gt; pg_upmap_items; <span class="comment">///&lt; remap osds in up set</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//pool的相关信息</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int64_t</span>,<span class="type">pg_pool_t</span>&gt; pools;   <span class="comment">//pool的id到pg_pool_t的映射</span></span><br><span class="line">  mempool::osdmap::map&lt;<span class="type">int64_t</span>,string&gt; pool_name;  <span class="comment">//pool的id到pool的名字的映射</span></span><br><span class="line">  mempool::osdmap::map&lt;string,map&lt;string,string&gt; &gt; erasure_code_profiles;    <span class="comment">//pool的EC相关信息</span></span><br><span class="line">  mempool::osdmap::map&lt;string,<span class="type">int64_t</span>&gt; name_pool;  <span class="comment">//pool的名字到pool的id的映射</span></span><br></pre></td></tr></table></figure><h2 id="Op"><a href="#Op" class="headerlink" title="Op"></a>Op</h2><p><code>结构体Op</code>封装了完成一个操作的相关上下文信息，包括target地址信息(op_target_t)、链接信息(session)等</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Op封装了完成一个操作的相关的上下文信息，包括target地址信息、链接信息等。</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Op</span> : <span class="keyword">public</span> RefCountedObject &#123;</span><br><span class="line">    OSDSession *session;   <span class="comment">//OSD相关的Session信息 </span></span><br><span class="line">    <span class="type">int</span> incarnation;    <span class="comment">//引用次数</span></span><br><span class="line">    <span class="type">op_target_t</span> target;   <span class="comment">//地址信息</span></span><br><span class="line">    ConnectionRef con;  <span class="comment">// for rx buffer only</span></span><br><span class="line">    <span class="type">uint64_t</span> features;  <span class="comment">// explicitly specified op features</span></span><br><span class="line">    vector&lt;OSDOp&gt; ops;   <span class="comment">// 对应多个操作的封装</span></span><br><span class="line">    <span class="type">snapid_t</span> snapid;     <span class="comment">//快照的ID</span></span><br><span class="line">    SnapContext snapc;   <span class="comment">//pool层级的快照信息</span></span><br><span class="line">    ceph::real_time mtime;</span><br><span class="line">    bufferlist *outbl;    <span class="comment">//输出的bufferlist</span></span><br><span class="line">    vector&lt;bufferlist*&gt; out_bl;     <span class="comment">//每个操作对应的bufferlist</span></span><br><span class="line">    vector&lt;Context*&gt; out_handler;    <span class="comment">//每个操作对应的回调函数</span></span><br><span class="line">    vector&lt;<span class="type">int</span>*&gt; out_rval;     <span class="comment">//每个操作对应的输出结果</span></span><br><span class="line">    <span class="type">int</span> priority;</span><br><span class="line">    Context *onfinish;</span><br><span class="line">    <span class="type">uint64_t</span> ontimeout;</span><br><span class="line">    <span class="type">ceph_tid_t</span> tid;</span><br><span class="line">    <span class="type">int</span> attempts;</span><br><span class="line">    <span class="type">version_t</span> *objver;</span><br><span class="line">    <span class="type">epoch_t</span> *reply_epoch;</span><br><span class="line">    ceph::coarse_mono_time stamp;</span><br><span class="line">    <span class="type">epoch_t</span> map_dne_bound;</span><br><span class="line">    <span class="type">int</span> budget;</span><br><span class="line">    <span class="comment">/// true if we should resend this message on failure</span></span><br><span class="line">    <span class="type">bool</span> should_resend;</span><br><span class="line">    <span class="comment">/// true if the throttle budget is get/put on a series of OPs,</span></span><br><span class="line">    <span class="comment">/// instead of per OP basis, when this flag is set, the budget is</span></span><br><span class="line">    <span class="comment">/// acquired before sending the very first OP of the series and</span></span><br><span class="line">    <span class="comment">/// released upon receiving the last OP reply.</span></span><br><span class="line">    <span class="type">bool</span> ctx_budgeted;</span><br><span class="line">    <span class="type">int</span> *data_offset;</span><br><span class="line"></span><br><span class="line">    <span class="type">osd_reqid_t</span> reqid; <span class="comment">// explicitly setting reqid</span></span><br><span class="line">    ZTracer::Trace trace;</span><br></pre></td></tr></table></figure><h2 id="op-target-t"><a href="#op-target-t" class="headerlink" title="op_target_t"></a>op_target_t</h2><p>数据结构op_target_t封装了对象所在的PG，以及PG对应的OSD列表等地址信息。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//封装了对象所在的PG，以及PG对应的OSD列表等地址信息</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">op_target_t</span> &#123;</span><br><span class="line">    <span class="type">int</span> flags = <span class="number">0</span>;    <span class="comment">//标志</span></span><br><span class="line">    <span class="type">epoch_t</span> epoch = <span class="number">0</span>;  <span class="comment">///&lt; latest epoch we calculated the mapping</span></span><br><span class="line">    <span class="type">object_t</span> base_oid;   <span class="comment">//读取的对象</span></span><br><span class="line">    <span class="type">object_locator_t</span> base_oloc;   <span class="comment">//对象的pool信息</span></span><br><span class="line">    <span class="type">object_t</span> target_oid;     <span class="comment">//最终读取的目标对象</span></span><br><span class="line">    <span class="type">object_locator_t</span> target_oloc;   <span class="comment">//最终目标对象的pool信息</span></span><br><span class="line">    <span class="comment">///&lt; true if we are directed at base_pgid, not base_oid</span></span><br><span class="line">    <span class="type">bool</span> precalc_pgid = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">///&lt; true if we have ever mapped to a valid pool</span></span><br><span class="line">    <span class="type">bool</span> pool_ever_existed = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">///&lt; explcit pg target, if any</span></span><br><span class="line">    <span class="type">pg_t</span> base_pgid;</span><br><span class="line">    <span class="type">pg_t</span> pgid; <span class="comment">///&lt; last (raw) pg we mapped to</span></span><br><span class="line">    <span class="type">spg_t</span> actual_pgid; <span class="comment">///&lt; last (actual) spg_t we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num = <span class="number">0</span>; <span class="comment">///&lt; last pg_num we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num_mask = <span class="number">0</span>; <span class="comment">///&lt; last pg_num_mask we mapped to</span></span><br><span class="line">    <span class="type">unsigned</span> pg_num_pending = <span class="number">0</span>; <span class="comment">///&lt; last pg_num we mapped to</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; up; <span class="comment">///&lt; set of up osds for last pg we mapped to</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; acting; <span class="comment">///&lt; set of acting osds for last pg we mapped to</span></span><br><span class="line">    <span class="type">int</span> up_primary = <span class="number">-1</span>; <span class="comment">///&lt; last up_primary we mapped to</span></span><br><span class="line">    <span class="type">int</span> acting_primary = <span class="number">-1</span>;  <span class="comment">///&lt; last acting_primary we mapped to</span></span><br><span class="line">    <span class="type">int</span> size = <span class="number">-1</span>; <span class="comment">///&lt; the size of the pool when were were last mapped</span></span><br><span class="line">    <span class="type">int</span> min_size = <span class="number">-1</span>; <span class="comment">///&lt; the min size of the pool when were were last mapped</span></span><br><span class="line">    <span class="type">bool</span> sort_bitwise = <span class="literal">false</span>; <span class="comment">///&lt; whether the hobject_t sort order is bitwise</span></span><br><span class="line">    <span class="type">bool</span> recovery_deletes = <span class="literal">false</span>; <span class="comment">///&lt; whether the deletes are performed during recovery instead of peering</span></span><br><span class="line">    <span class="type">bool</span> used_replica = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">bool</span> paused = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">int</span> osd = <span class="number">-1</span>;      <span class="comment">///&lt; the final target osd, or -1</span></span><br><span class="line">    <span class="type">epoch_t</span> last_force_resend = <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h2 id="CRUSH-Map"><a href="#CRUSH-Map" class="headerlink" title="CRUSH Map"></a>CRUSH Map</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_step</span> &#123;</span><br><span class="line">__u32 op;    <span class="comment">//操作类型</span></span><br><span class="line">__s32 arg1;   <span class="comment">//操作数1</span></span><br><span class="line">__s32 arg2;    <span class="comment">//操作数2</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">crush_opcodes</span> &#123;</span><br><span class="line">CRUSH_RULE_NOOP = <span class="number">0</span>,</span><br><span class="line">CRUSH_RULE_TAKE = <span class="number">1</span>,          <span class="comment">/* arg1 = value to start with */</span></span><br><span class="line">CRUSH_RULE_CHOOSE_FIRSTN = <span class="number">2</span>, <span class="comment">/* arg1 = num items to pick */</span> <span class="comment">/* arg2 = type */</span>      </span><br><span class="line">CRUSH_RULE_CHOOSE_INDEP = <span class="number">3</span>,  <span class="comment">/* same */</span></span><br><span class="line">CRUSH_RULE_EMIT = <span class="number">4</span>,          <span class="comment">/* no args */</span></span><br><span class="line">CRUSH_RULE_CHOOSELEAF_FIRSTN = <span class="number">6</span>,</span><br><span class="line">CRUSH_RULE_CHOOSELEAF_INDEP = <span class="number">7</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSE_TRIES = <span class="number">8</span>, <span class="comment">/* override choose_total_tries */</span></span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_TRIES = <span class="number">9</span>, <span class="comment">/* override chooseleaf_descend_once */</span></span><br><span class="line">CRUSH_RULE_SET_CHOOSE_LOCAL_TRIES = <span class="number">10</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSE_LOCAL_FALLBACK_TRIES = <span class="number">11</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_VARY_R = <span class="number">12</span>,</span><br><span class="line">CRUSH_RULE_SET_CHOOSELEAF_STABLE = <span class="number">13</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 用于指定相对于传递给 do_rule 的 max 参数的选择 num (arg1)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_CHOOSE_N            0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_CHOOSE_N_MINUS(x)   (-(x))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 规则掩码用于描述规则的用途。</span></span><br><span class="line"><span class="comment"> * 给定规则集和输出集的大小，我们在规则列表中搜索匹配的 rule_mask。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_mask</span> &#123;</span><br><span class="line">__u8 ruleset;   <span class="comment">//ruleId</span></span><br><span class="line">__u8 type;   <span class="comment">//多副本还是纠删码</span></span><br><span class="line">__u8 min_size;   <span class="comment">//副本数大于等于时适用</span></span><br><span class="line">__u8 max_size;   <span class="comment">//副本数小于等于时适用</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule</span> &#123;</span><br><span class="line">__u32 len;   <span class="comment">//steps数组的长度</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_mask</span> mask;   <span class="comment">//releset相关的配置参数</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule_step</span> steps[<span class="number">0</span>];   <span class="comment">//step集合</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> crush_rule_size(len) (sizeof(struct crush_rule) + \</span></span><br><span class="line"><span class="meta">      (len)*sizeof(struct crush_rule_step))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * A bucket is a named container of other items (either devices or</span></span><br><span class="line"><span class="comment"> * other buckets).</span></span><br><span class="line"><span class="comment"> * 桶是其他item（设备或其他存储桶）的命名容器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 使用三种算法中的一种来选择的，这些算法代表了性能和重组效率之间的权衡。 </span></span><br><span class="line"><span class="comment"> * 如果您不确定要使用哪种存储桶类型，我们建议您使用 ::CRUSH_BUCKET_STRAW2。</span></span><br><span class="line"><span class="comment"> * 该表总结了在添加或删除item时每个选项的速度如何与映射稳定性相比较。</span></span><br><span class="line"><span class="comment"> * Bucket Alg     Speed       Additions    Removals</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------</span></span><br><span class="line"><span class="comment"> * uniform         O(1)       poor         poor</span></span><br><span class="line"><span class="comment"> * list            O(n)       optimal      poor</span></span><br><span class="line"><span class="comment"> * straw2          O(n)       optimal      optimal</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">crush_algorithm</span> &#123;</span><br><span class="line">CRUSH_BUCKET_UNIFORM = <span class="number">1</span>,</span><br><span class="line">CRUSH_BUCKET_LIST = <span class="number">2</span>,</span><br><span class="line">CRUSH_BUCKET_TREE = <span class="number">3</span>,</span><br><span class="line">CRUSH_BUCKET_STRAW = <span class="number">4</span>,</span><br><span class="line">CRUSH_BUCKET_STRAW2 = <span class="number">5</span>,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">const</span> <span class="type">char</span> *<span class="title">crush_bucket_alg_name</span><span class="params">(<span class="type">int</span> alg)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CRUSH_LEGACY_ALLOWED_BUCKET_ALGS (\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_UNIFORM) |\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_LIST) |\</span></span><br><span class="line"><span class="meta">(1 &lt;&lt; CRUSH_BUCKET_STRAW))</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> &#123;</span><br><span class="line">__s32 id;       <span class="comment">//bucket的编号。小于0 /*!&lt; bucket identifier, &lt; 0 and unique within a crush_map */</span></span><br><span class="line">__u16 type;      <span class="comment">//bucket的类型/*!&lt; &gt; 0 bucket type, defined by the caller */</span></span><br><span class="line">__u8 alg;        <span class="comment">//使用的crush算法/*!&lt; the item selection ::crush_algorithm */</span></span><br><span class="line">__u8 hash;       <span class="comment">//使用的hash算法/* which hash function to use, CRUSH_HASH_* */</span></span><br><span class="line">__u32 weight;   <span class="comment">//权重 /*!&lt; 16.16 fixed point cumulated children weight */</span></span><br><span class="line">__u32 size;      <span class="comment">//items的数量/*!&lt; size of the __items__ array */</span></span><br><span class="line">    __s32 *items;    <span class="comment">//子bucket/*!&lt; array of children: &lt; 0 are buckets, &gt;= 0 items */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_weight_set</span> &#123;</span><br><span class="line">  __u32 *weights; <span class="comment">/*!&lt; 16.16 fixed point weights in the same order as items */</span></span><br><span class="line">  __u32 size;     <span class="comment">/*!&lt; size of the __weights__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_choose_arg</span> &#123;</span><br><span class="line">  __s32 *ids;                           <span class="comment">/*!&lt; values to use instead of items */</span></span><br><span class="line">  __u32 ids_size;                       <span class="comment">/*!&lt; size of the __ids__ array */</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">crush_weight_set</span> *weight_set;  <span class="comment">/*!&lt; weight replacements for a given position */</span></span><br><span class="line">  __u32 weight_set_positions;           <span class="comment">/*!&lt; size of the __weight_set__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_choose_arg_map</span> &#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">crush_choose_arg</span> *args; <span class="comment">/*!&lt; replacement for each bucket in the crushmap */</span></span><br><span class="line">  __u32 size;                    <span class="comment">/*!&lt; size of the __args__ array */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_uniform</span> &#123;</span><br><span class="line">       <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__u32 item_weight;  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_list</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__u32 *item_weights;  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">__u32 *sum_weights;   <span class="comment">/*!&lt; 16.16 fixed point sum of the weights */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_tree</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h;  <span class="comment">/* note: h.size is _tree_ size, not number of</span></span><br><span class="line"><span class="comment">   actual items */</span></span><br><span class="line">__u8 num_nodes;</span><br><span class="line">__u32 *node_weights;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_straw</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h;</span><br><span class="line">__u32 *item_weights;   <span class="comment">/* 16-bit fixed point */</span></span><br><span class="line">__u32 *straws;         <span class="comment">/* 16-bit fixed point */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket_straw2</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">crush_bucket</span> h; <span class="comment">/*!&lt; generic bucket information */</span></span><br><span class="line">__.  <span class="comment">/*!&lt; 16.16 fixed point weight for each item */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_map</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_bucket</span> **buckets;  **类型，所有的bucket都存在这里</span><br><span class="line">        <span class="comment">/*! 一个大小为__max_rules__ 的crush_rule 指针数组。</span></span><br><span class="line"><span class="comment">         * 如果规则被删除，数组的一个元素可能为NULL（没有API 可以这样做，但将来可能会有一个）。 </span></span><br><span class="line"><span class="comment">         * 规则必须使用crunch_add_rule() 添加。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">crush_rule</span> **rules;   <span class="comment">//**类型，多层嵌套的rules</span></span><br><span class="line">    __s32 max_buckets; <span class="comment">/*!&lt; the size of __buckets__ */</span>  <span class="comment">// bucket的总数</span></span><br><span class="line">__u32 max_rules; <span class="comment">/*!&lt; the size of __rules__ */</span>      <span class="comment">// rule的总数</span></span><br><span class="line">__s32 max_devices;   <span class="comment">// osd的总数</span></span><br><span class="line">__u32 choose_local_tries;   <span class="comment">//选择的总次数</span></span><br><span class="line">__u32 choose_local_fallback_tries;  </span><br><span class="line">__u32 choose_total_tries;</span><br><span class="line">__u32 chooseleaf_descend_once;</span><br><span class="line">__u8 chooseleaf_vary_r;</span><br><span class="line">__u8 chooseleaf_stable;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">该值是在构建器解码或构建后计算的。 它在此处公开（而不是具有“构建 CRUSH 工作空间”功能），以便调用者可以保留静态缓冲区、在堆栈上分配空间，或者在需要时避免调用堆分配器。 </span></span><br><span class="line"><span class="comment">        工作空间的大小取决于映射，而传递给映射器的临时向量的大小取决于所需结果集的大小。尽管如此，没有什么能阻止调用者在一个膨胀 foop 中分配两个点并传递两个点。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">size_t</span> working_size;</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph-相关数据结构&quot;&gt;&lt;a href=&quot;#Ceph-相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;Ceph 相关数据结构&quot;&gt;&lt;/a&gt;Ceph 相关数据结构&lt;/h2&gt;&lt;p&gt;要想深入到Ceph的源码底层，就必须对代码通用库里的一些关键，常见的</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph源码编译调试</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95/</id>
    <published>2021-06-20T07:24:13.000Z</published>
    <updated>2024-07-27T14:38:39.225Z</updated>
    
    <content type="html"><![CDATA[<p>对于一个ceph开发人员来说编译源码以及打rpm是其必备技能。无论是fix bug还是向社区提交pull request都离不开编译源码。</p><h2 id="编译环境"><a href="#编译环境" class="headerlink" title="编译环境"></a>编译环境</h2><p><strong>环境介绍</strong></p><ul><li>ceph version: N版 14.2.16</li><li>硬件环境：Centos7虚拟机</li></ul><p><strong>网络环境与源加速</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">额外软件源、生成新的缓存</span></span><br><span class="line">yum -y install centos-release-scl</span><br><span class="line">yum -y install epel-release        </span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line">yum list</span><br><span class="line">yum update</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更换pip源，创建 .pip 目录</span></span><br><span class="line">mkdir ~/.pip                      </span><br><span class="line">cd ~/.pip                                      </span><br><span class="line">vi pip.conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入以下配置</span></span><br><span class="line">[global]</span><br><span class="line">index-url = https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置yum源</span></span><br><span class="line">vim /etc/yum.repos.d/ceph.repo</span><br><span class="line"></span><br><span class="line">[norch]</span><br><span class="line">name=norch</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[x86_64]</span><br><span class="line">name=x86 64</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[SRPMS]</span><br><span class="line">name=SRPMS</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/SRPMS/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[aarch64]</span><br><span class="line">name=aarch64</span><br><span class="line">baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/aarch64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure><p><strong>安装编译环境及依赖包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">yum -y install rdma-core-devel systemd-devel keyutils-libs-devel openldap-devel leveldb-devel snappy-devel lz4-devel curl-devel nss-devel</span><br><span class="line">yum -y install libzstd zstd gcc cmake make git wget</span><br><span class="line">yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils       # 安装gcc 7.2</span><br><span class="line">scl enable devtoolset-7 bash      #临时生效</span><br><span class="line">source /opt/rh/devtoolset-7/enable</span><br><span class="line">echo &quot;source /opt/rh/devtoolset-7/enable&quot; &gt;&gt;/etc/profile  #长期生效</span><br><span class="line">gcc -v                         #查看环境gcc版本</span><br><span class="line">wget https://github.com/Kitware/CMake/releases/download/v3.18.2/cmake-3.18.2.tar.gz      #安装cmake3</span><br><span class="line">tar -zxvf cmake-3.18.2.tar.gz</span><br><span class="line">cd cmake-3.18.2 </span><br><span class="line">yum -y install ncurses-devel openssl-devel</span><br><span class="line">./bootstrap</span><br><span class="line">gmake &amp;&amp; gmake install</span><br><span class="line">ln -s /usr/local/share/cmake /usr/bin/</span><br><span class="line">cmake -version</span><br></pre></td></tr></table></figure><p><strong>安装 ccache 加速编译</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载安装包并解压</span></span><br><span class="line">mkdir /home/ccache        </span><br><span class="line">cd /home/ccache</span><br><span class="line">wget https://github.com/ccache/ccache/releases/download/v4.0/ccache-4.0.tar.gz</span><br><span class="line">tar -zxvf ccache-4.0.tar.gz</span><br><span class="line">cd ccache-4.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编译安装</span></span><br><span class="line">mkdir build     </span><br><span class="line">cd build</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=Release -DZSTD_FROM_INTERNET=ON ..</span><br><span class="line">make -j12</span><br><span class="line">make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置</span></span><br><span class="line">mkdir -p /root/.config/ccache/          </span><br><span class="line">vi /root/.config/ccache/ccache.conf</span><br><span class="line">max_size = 16G</span><br><span class="line">sloppiness = time_macros</span><br><span class="line">run_second_cpp = true</span><br></pre></td></tr></table></figure><h2 id="编译ceph代码"><a href="#编译ceph代码" class="headerlink" title="编译ceph代码"></a>编译ceph代码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 下载Ceph源码一</span></span></span><br><span class="line">mkdir /home/ceph</span><br><span class="line">cd /home/ceph</span><br><span class="line">git clone git://github.com/ceph/ceph.git       #(git clone https://github.com/ceph/ceph.git)</span><br><span class="line">cd ceph</span><br><span class="line">git checkout nautilus                            #切换分支，这里以 N 版本为例</span><br><span class="line">git submodule update --init --recursive          #进入ceph目录，下载ceph代码依赖</span><br><span class="line">   </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 下载Ceph源码二</span></span></span><br><span class="line">wget https://mirrors.aliyun.com/ceph/debian-nautilus/pool/main/c/ceph/ceph_14.2.22.orig.tar.gz</span><br><span class="line">tar -zxvf ceph_14.2.22.orig.tar.gz</span><br><span class="line">cd ceph_14.2.2</span><br><span class="line"></span><br><span class="line">./install-deps.sh                                #执行依赖安装脚本，ceph 自带的解决依赖的脚本</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 修改cmake参数，因为后面需要使用gdb debug客户端程序，客户端程序会依赖librados库，所以我们必须以debug的模式去编译ceph，否则编译器会优化掉很多参数，导致很多信息缺失，需要修改一下ceph cmake的参数。如图所示</span></span></span><br><span class="line">vim do_cmake.sh    </span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">&#123;CMAKE&#125; -DCMAKE_C_FLAGS=<span class="string">&quot;-O0 -g3 -gdwarf-4&quot;</span> -DCMAKE_CXX_FLAGS=<span class="string">&quot;-O0 -g3 -gdwarf-4&quot;</span> -DBOOST_J=$(<span class="built_in">nproc</span>) <span class="variable">$ARGS</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span> ..</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到这里修改了cmake的参数，增加了两个配置项，稍微解释一下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CMAKE_C_FLAGS=“-O0 -g3 -gdwarf-4” ： c 语言编译配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CMAKE_CXX_FLAGS=“-O0 -g3 -gdwarf-4” ：c++ 编译配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-O0 : 关闭编译器的优化，如果没有，使用GDB追踪程序时，大多数变量被优化,无法显示, 生产环境必须关掉</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-g3 : 意味着会产生大量的调试信息</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-gdwarf-4 : dwarf 是一种调试格式，dwarf-4 版本为4</span></span><br><span class="line">     </span><br><span class="line">./do_cmake.sh -DWITH_MANPAGE=OFF -DWITH_BABELTRACE=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DCMAKE_BUILD_TYPE=RelWithDebInfo -DWITH_CCACHE=ON --DWITH_PYTHON3=ON --DMGR_PYTHON_VERSION=3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行 cmake，解释一下，DWITH_MGR_DASHBOARD_FRONTEND=OFF 主要是因为 ceph dashboard 用到了一些国外的 nodejs源，国内无法下载，会导致编译失败超时。-DWITH_CCACHE=ON 如果你没有安装 步骤 2-2 的 ccache 的话，可以去掉这个参数。</span></span><br><span class="line">    </span><br><span class="line">cd build</span><br><span class="line">make -j20 #（线程数等于cpu core的2倍，可以提高编译的速度，20核CPU、32G内存的服务器）</span><br></pre></td></tr></table></figure><p>修改do_cmake.sh<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_1.png"><br>编译进度<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_2.png"></p><p>自此已经编译完ceph源代码！</p><h2 id="运行测试集群"><a href="#运行测试集群" class="headerlink" title="运行测试集群"></a>运行测试集群</h2><p>发行版的 ceph 安装包安装的集群默认是没有办法debug调试。这里推荐 ceph 内置的debug调试——vstart，非常方便模仿特殊场景进行debug调试。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /home/watson/ceph/build        # 进入build目录</span><br><span class="line">make vstart                       # 编译模拟启动环境（make help 查看有哪些target可以单独编译）</span><br><span class="line">MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore         # (模拟启动，指令前半部分的MDS=0 RGW=1之类的就是设定你想要模拟的集群结构（集群的配置文件在ceph/build/ceph.conf）)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动完成后，可以在模拟集群环境下执行各种 ceph 指令(模拟集群所有的指令都在 build/bin 目录)</span></span><br><span class="line">bin/ceph -s                       # 查看 ceph 集群状态</span><br><span class="line">bin/radosgw-admin user list       # 查看用户</span><br><span class="line">../src/stop.sh                    # 关闭测试集群</span><br></pre></td></tr></table></figure><p>编译vstasrt环境<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_3.png"><br>启动vstart环境<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_4.png"><br>查看 ceph 集群状态<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_5.png"><br>查看Ceph用户<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_6.png"></p><h2 id="运行单元测试用例"><a href="#运行单元测试用例" class="headerlink" title="运行单元测试用例"></a>运行单元测试用例</h2><p>更改了代码准备提交到公司内部repo或者社区repo都需要先执行一下最小测试集，看看自己修改的代码有没有影响到别的模块(社区也会进行同样的测试)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd build</span><br><span class="line">make                       #修改代码后先编译，可以模块编译</span><br><span class="line">man ctest                  #查看ctest的功能</span><br><span class="line">ctest -j20                 #运行所有测试（使用所有处理器并行）</span><br><span class="line">ctest -R [regex matching test name(s)]                  #运行部分模块测试，使用 -R（正则表达式匹配）</span><br><span class="line">ctest -V -R [regex matching test name(s)]               #使用 -V（详细）标志运行</span><br><span class="line">ctest -j20 -V -R [regex matching test name(s)]          #运行正则表达式匹配的模块测试，显示详细信息，并发进行</span><br></pre></td></tr></table></figure><p>注意：许多从 src&#x2F;test 构建的目标不是使用ctest运行的。以 “unittest” 开头的目标在其中运行make check，因此可以使用运行ctest。以 “ceph_test” 开头的目标不能，应该手动运行。发生故障时，请在 build&#x2F;Testing&#x2F;Temporary 中查找日志。</p><p><strong>开发编译测试过程</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 编写保存源代码</span><br><span class="line">2. make -j20 unittest_crush               #模块编译</span><br><span class="line">3. ctest -j20 -V -R unittest_crush         #模块测试</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_7.png"></p><h2 id="通过librados客户端调试CRUSH算法"><a href="#通过librados客户端调试CRUSH算法" class="headerlink" title="通过librados客户端调试CRUSH算法"></a>通过librados客户端调试CRUSH算法</h2><p><strong>编写客户端代码</strong><br>调用librados 库写入数据<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_8.png"></p><p><strong>运行librados代码</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install librados2-devel  libradospp   libradosstriper-devel -y  #安装相关开发包（C/C++开发包）</span><br><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib                         #编译客户端程序 rados_write.c</span><br></pre></td></tr></table></figure><p>这里解释一下gcc 几个参数，首先需要理解的是c程序在编译时依赖的库和运行时依赖库是分开指定的，也就是说，编译的时候使用的库，不一定就是运行时使用的库</p><ul><li>g : 允许gdb调试</li><li>lrados : -l 指定依赖库的名字为rados</li><li>L : 指定编译时依赖库的的路径， 如果不指定将在系统目录下寻找</li><li>o : 编译的二进制文件名</li><li>Wl : 指定编译时参数</li><li>rpath : 指定运行时依赖库的路径， 如果不指定将在系统目录下寻找</li></ul><p><strong>运行客户端程序</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./rados_write</span><br><span class="line">bin/rados ls -p default.rgw.meta                 #在集群中确认一下是否写入数据</span><br></pre></td></tr></table></figure><p>运行rados_write程序<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_9.png"><br>确认写入数据<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_10.png"></p><p>ceph的开发者模式是测试ceph功能和调试代码非常方便的途径，因为集群默认开启了debug模式，所有的日志都会详细的输出，并且为了调试的方便，在正式环境中的多线程多队列，在这都会简化。</p><h2 id="使用GDB调试分析Object至OSD映射"><a href="#使用GDB调试分析Object至OSD映射" class="headerlink" title="使用GDB调试分析Object至OSD映射"></a>使用GDB调试分析Object至OSD映射</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gdb                   #安装gdb</span><br><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib   #编译客户端程序 rados_write.c</span><br><span class="line">gdb ./rados_write                    #使用gdb 调试 rados_write 程序</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动程序后，需要设置断点，这里选择的是 crush_do_rule 函数，因为这个函数是 object–&gt;到PG 流程的终点</span></span><br><span class="line">b crush_do_rule                      #在crush_do_rule 函数设置断点</span><br><span class="line">bt                                   #查看当前的函数堆栈</span><br></pre></td></tr></table></figure><p>gdb调试raodos_wirte程序<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_11.png"><br>设置调试断点<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_12.png"><br>查看当前函数栈<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_13.png"></p><p>得到的函数流程如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#0   crush_do_rule at /home/watson/ceph/src/crush/mapper.c:904</span><br><span class="line">#1   do_rule at /home/watson/ceph/src/crush/CrushWrapper.h:1570</span><br><span class="line">#2   OSDMap::_pg_to_raw_osds at /home/watson/ceph/src/osd/OSDMap.cc:2340</span><br><span class="line">#3   OSDMap::_pg_to_up_acting_osds at /home/watson/ceph/src/osd/OSDMap.cc:2586</span><br><span class="line">#4   pg_to_up_acting_osds  at /home/watson/ceph/src/osd/OSDMap.h:1209</span><br><span class="line">#5   Objecter::_calc_target at /home/watson/ceph/src/osdc/Objecter.cc:2846</span><br><span class="line">#6   Objecter::_op_submit  at /home/watson/ceph/src/osdc/Objecter.cc:2367</span><br><span class="line">#7   Objecter::_op_submit_with_budget at /home/watson/ceph/src/osdc/Objecter.cc:2284</span><br><span class="line">#8   Objecter::op_submit at /home/watson/ceph/src/osdc/Objecter.cc:2251</span><br><span class="line">#9   librados::IoCtxImpl::operate  at /home/watson/ceph/src/librados/IoCtxImpl.cc:690</span><br><span class="line">#10  librados::IoCtxImpl::write at /home/watson/ceph/src/librados/IoCtxImpl.cc:623</span><br><span class="line">#11  rados_write at /home/watson/ceph/src/librados/librados_c.cc:1133</span><br><span class="line">#12  main at rados_write.c:73</span><br></pre></td></tr></table></figure><p>不关心librados是如何封装请求，只关心object到pg的计算过程，所以这里决定从 Objecter::_calc_target 函数开始debug 整个过程，重新开始，然后再次设置断点。重新开始，计算 object的hash值 ps</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b Objecter::_calc_target        #断点</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_14.png"></p><p>卡住在断点处，现在我们打开tui模式跟踪代码， <code>crtl + x + a</code> 可以切换到tui界面<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_15.png"><br>这里按 n 逐行debug代码， 这里我想显示打印 pg_pool_t *p 和 op_target_t *t 的信息<br>其中 pg_pool_t 是pool的结构体，包含pool相关的所有信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p *pi                   #查看pi的数据结构</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_17.png"><br>而 op_target_t 则是整个写入操作封装的结构信息，包含对象的名字，写入pool的id<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_18.png"><br>继续 n 单步调试，这里我们会进去 osdmap-&gt;object_locator_to_pg 函数。然后一步一步调试……<br>object到PG的函数流程图<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_19.jpg"><br>PG映射到OSD函数流程图<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_20.jpg"><br>crush_choose_firstn选择的过程<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_21.png"></p><h2 id="使用VScode远程调试Ceph"><a href="#使用VScode远程调试Ceph" class="headerlink" title="使用VScode远程调试Ceph"></a>使用VScode远程调试Ceph</h2><p>以ceph osd部分为例，为您演示通过第三方社区提供的vscode 编辑软件，对ceph osd进行进行图形化单步调试以及配置操作。vscode是微软公司一个开源的编译器具备轻量的特点，通过插件安装方式提供了丰富的调试功能。通常 Linux环境的c&#x2F;c++软件开发使用GDB进行命令行调试，命令行操方式极其不方便。使用vscode 的图形化界面可替代gdb 命令行 ，整个开发调试过程更加便捷。Ceph源码路径在&#x2F;home&#x2F;watson&#x2F;ceph目录下，其编译运行文件在&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;build&#x2F;bin当中。启动调试前需要停止本地的osd运行服务。<br><strong>下载安装windows的vscode和ssh</strong><br>在以下地址下载vscode:  <a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a><br>安装openssh (一般情况不用自己手动安装)如果需要远程开发，Windows机器也需要支持openssh，如果本机没有，会报错。可以到微软官网上下载ssh。<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_22.png"><br>在vscode安装Remote Development和Remote-SSH<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_23.png"><br>在安装完成之后，点击左侧的Remote-SSH选项卡，再将鼠标移向CONNECTIONS栏，点击出现的configure：<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_25.png"><br>填写linux服务器的ssh端口和用户名（如果是默认的22端口可不用填写）<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_26.png"><br>按下ctrl + s 保存 然后连接（&#x2F;home&#x2F;watson&#x2F;ceph&#x2F;）<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_27.png"><br>输入密码，总共有多次输入密码的流程留意窗口变化<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_28.png"><br>打开远程服务器的文件夹<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_29.png"><br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_30.png"></p><p><strong>远程连接遇到的问题以及技巧</strong></p><p>因为ceph工程文件数量众多会出现无法在这个大型工作区中监视文件更改。请按照说明链接来解决此问题的问题。原因：工作区很大并且文件很多，导致VS Code文件观察程序的句柄达到上限。<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_31.png"><br>解决方法：编辑linux服务器中的 &#x2F;etc&#x2F;sysctl.conf；将以下一行添加到文件末尾，可以将限制增加到最大值<br>    <code>fs.inotify.max_user_watches=524288</code></p><p>保存之后终端窗口 输入sysctl -p可解决。<br>远程调试<br>首先前提Linux服务器已经安装了GDB，否则会提示出错。在ceph工程目录下添加launch.json文件。在最左上栏运行(R) -&gt; 添加配置 ，注意一定要在ceph当前工程目录。修改配置launch.json中的program、args选项。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">launch.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ceph-debug&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/build/bin/unittest_crush&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;-d&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--cluster&quot;</span><span class="punctuation">,</span> <span class="string">&quot;ceph&quot;</span><span class="punctuation">,</span><span class="string">&quot;--id&quot;</span><span class="punctuation">,</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--setuser&quot;</span><span class="punctuation">,</span> <span class="string">&quot;root&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--setgroup&quot;</span><span class="punctuation">,</span> <span class="string">&quot;root&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;stopAtEntry&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;environment&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;externalConsole&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Enable pretty-printing for gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>按照下图点击就可以开始调试之路<br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_31.png"><br><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_32.png"></p><h2 id="报错记录"><a href="#报错记录" class="headerlink" title="报错记录"></a>报错记录</h2><p>报错1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RPC failed; result=35, HTTP code = 0 fatal: The remote end hung up unexpectedly无法克隆 &#x27;https://github.com/xxxx/xxxxxxxx.git&#x27; 到子模组路径 &#x27;xxxxxxxxx&#x27;</span><br><span class="line">解决：</span><br><span class="line">    通过设置Git的http缓存大小，解决了这个问题，在当前工程目录下运行如下命令：</span><br><span class="line">        git config --global http.postBuffer 20M     (如果20M不行就50M)</span><br></pre></td></tr></table></figure><p>报错2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">编译出现了一个问题，卡在5%Built target rocksdb_ext这里 </span><br><span class="line">原因：国外网络太慢，下载boost_1_72_0.tar.bz2太慢了，换网络或者在先用本地下载再传到服务器上（ceph/build/boost/src目录下）</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_34.png"></p><p>报错3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">No Package found for python-scipy</span><br><span class="line">vim ceph.spec.in</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%B0%83%E8%AF%95_35.png"></p><p>报错4</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;Error: Package: golang-github-prometheus-2.26.1-2.el7.x86_64 (epel) Requires: /usr/bin/systemd-sysusers&quot;, 去掉该需求</span><br><span class="line">vim ~/ceph-14.2.16/ceph.spec.in</span><br><span class="line"># 内容</span><br><span class="line">#BuildRequires:   golang-github-prometheus</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;对于一个ceph开发人员来说编译源码以及打rpm是其必备技能。无论是fix bug还是向社区提交pull request都离不开编译源码。&lt;/p&gt;
&lt;h2 id=&quot;编译环境&quot;&gt;&lt;a href=&quot;#编译环境&quot; class=&quot;headerlink&quot; title=&quot;编译环境&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_librados_api使用</title>
    <link href="https://watsonlu6.github.io/Ceph_librados_api%E4%BD%BF%E7%94%A8/"/>
    <id>https://watsonlu6.github.io/Ceph_librados_api%E4%BD%BF%E7%94%A8/</id>
    <published>2021-06-18T06:28:31.000Z</published>
    <updated>2024-07-27T14:37:33.694Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Librados-API概述"><a href="#Librados-API概述" class="headerlink" title="Librados API概述"></a>Librados API概述</h1><p>Ceph存储集群提供基本的存储服务，Ceph以独特的方式将对象、块和文件存储集成到一个存储系统中。基于RADOS，可以不限于RESTful或POSIX接口，使用librados API能够创建自定义的Ceph存储集群接口（除了块存储、对象存储和文件系统存储外）。<br>librados API能够与Ceph存储集群中的两种类型的守护进程进行交互：</p><ul><li>Ceph Mon守护进程，维护集群映射的主副本</li><li>Ceph OSD守护进程，它将数据作为对象存储在存储节点上<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_1.png"><br>要使用 API，您需要一个正在运行的 Ceph 存储集群。（本教程教程使用ceph编译的vstart启动的开发编程环境）<br>编译模拟启动环境<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">make vstart  #模拟启动</span><br><span class="line">MDS=0 RGW=1 ../src/vstart.sh -d -l -n --bluestore  #模拟集群所有的指令都在 build/bin 目录</span><br><span class="line">bin/ceph -s  #查看 ceph 集群状态</span><br><span class="line">../src/stop.sh #停止模拟集群</span><br></pre></td></tr></table></figure></li></ul><h3 id="第-1-步：获取librados"><a href="#第-1-步：获取librados" class="headerlink" title="第 1 步：获取librados"></a>第 1 步：获取librados</h3><p>Ceph客户端应用必须绑定librados才能连接Ceph存储集群。在写使用librados的ceph客户端应用前，要安装librados及其依赖包。librados API本身是用C++实现，也有C、Python、Java和PHP的API。（本教程仅限于librados C&#x2F;C++API）<br>获取C&#x2F;C++的librados</p><ul><li>要在 Debian&#x2F;Ubuntu 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令：<br>  <code>sudo apt-get install librados-dev</code></li><li>要在 RHEL&#x2F;CentOS 发行版上安装C&#x2F;C++ 的librados开发支持文件，执行以下命令：<br>  <code>sudo yum install librados2-devel</code></li><li>安装librados 后，可以在&#x2F;usr&#x2F;include&#x2F;rados 下找到 C&#x2F;C++所需的头文件<br>  <code>ls /usr/include/rados</code></li></ul><h2 id="第-2-步：配置集群句柄"><a href="#第-2-步：配置集群句柄" class="headerlink" title="第 2 步：配置集群句柄"></a>第 2 步：配置集群句柄</h2><p>一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用libradosAPI连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它会创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_2.png"><br>Ceph存储集群手柄封装客户端配置，包括：</p><ul><li>基于用户ID的rados_create() 或者基于用户名的rados_create2()(首选) </li><li>cephx认证密钥</li><li>Mon ID和IP地址</li><li>日志记录级别</li><li>调试级别</li></ul><p>因此，Ceph客户端应用程序使用Ceph群集的步骤：</p><ol><li>创建一个集群句柄，客户端应用将使用该句柄连接到存储集群中；</li><li>使用该手柄进行连接。要连接到集群的客户端应用必须提供Mon地址，用户名和认证密钥（默认启用cephx）。<br>提示：与不同的 Ceph 存储集群或与具有不同用户的同一个集群通信需要不同的集群句柄。RADOS 提供了多种设置所需值的方法。对于Mon和加密密钥设置，处理它们的一种简单方法是确保 Ceph 配置文件包含密钥环文件的密钥环路径和至少一个Mon地址（例如mon host）。例如:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">mon host = 192.168.1.1</span><br><span class="line">keyring = /etc/ceph/ceph.client.admin.keyring</span><br></pre></td></tr></table></figure></li><li>创建句柄后，读取 Ceph 配置文件来配置句柄。可以将参数传递给客户端应用程序并使用解析命令行参数的函数（例如rados_conf_parse_argv()）或解析 Ceph 环境变量（例如rados_conf_parse_env()）来解析它们。</li><li>连接后，客户端应用程序可以调用仅使用集群句柄影响整个集群的函数。例如，一旦有了集群句柄，就可以：<br> • 获取集群统计信息<br> • 使用池操作（存在、创建、列出、删除）<br> • 获取和设置配置</li></ol><p>Ceph 的强大功能之一是能够绑定到不同的池。每个池可能有不同数量的归置组、对象副本和复制策略。例如，可以将池设置为使用 SSD 存储常用对象的“热”池或使用纠删码的“冷”池。各种语言的librados 绑定的主要区别在于 C 与C++、Java 和 Python 的面向对象绑定之间。面向对象的绑定使用对象来表示集群句柄、IO 上下文、迭代器、异常等。</p><p><strong>C调用librados 示例</strong><br>对于 C，使用管理员用户创建一个简单的集群句柄，配置它并连接到集群如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">rados_t</span> cluster;</span><br><span class="line">        <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">        <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">        <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">        <span class="type">uint64_t</span> flags;</span><br><span class="line">        <span class="type">int</span> err;</span><br><span class="line">        err = rados_create2(&amp;cluster,cluster_name,user_name,flags);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: Couldn&#x27;t create the cluster handle!%s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Create a cluster handle!!!\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_conf_read_file(cluster,conf_flie);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot read config file: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Read the config flie\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_conf_parse_argv(cluster,argc,argv);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot parse command line arguments: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Read the command line arguments\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        err = rados_connect(cluster);</span><br><span class="line">        <span class="keyword">if</span>(err &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: cannot connect to cluster: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Connected to the cluster\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用-lrados编译客户端应用代码并链接到librados，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc ceph-client.c -lrados -o ceph-client</span><br></pre></td></tr></table></figure><p>ceph源码开发vstart环境下的编译，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -g rados_write.c -lrados -L/home/watson/ceph/build/lib -o rados_write -Wl,-rpath,/home/watson/ceph/build/lib</span><br></pre></td></tr></table></figure><p><strong>C++调用librados示例</strong><br>Ceph项目在ceph&#x2F;examples&#x2F;librados目录中提供了一个 C++ 示例。对于 C++，使用管理员用户的简单集群句柄需要初始化librados::Rados集群句柄对象</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    *通过librados::Rados句柄处理整个RADOS系统层面以及pool层面的管理。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    librados::Rados cluster;    <span class="comment">//定义一个操控集群的句柄对象</span></span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;     <span class="comment">//集群名字</span></span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;   <span class="comment">//集群用户名</span></span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;   <span class="comment">//集群配置文件</span></span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    ret = cluster.<span class="built_in">init2</span>(user_name,cluster_name,flags);      <span class="comment">//初始化句柄对象</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t initialize the cluster handle! error: &quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Create a cluster handle.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">conf_read_file</span>(conf_flie);     <span class="comment">//读配置文件获取Mon的信息</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read the ceph configuration file! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Read the ceph configuration file.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">conf_parse_argv</span>(argc,argv);   <span class="comment">//解析命令行输入的参数</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t parsed command line options!error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Parsed command line options.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">connect</span>();   <span class="comment">//连接集群</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t connect to cluster! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Connected to the cluster.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    cluster.<span class="built_in">pool_create</span>(<span class="string">&quot;testpool&quot;</span>); <span class="comment">//创建存储池</span></span><br><span class="line">    std::list&lt;std::string&gt; poolList; </span><br><span class="line">    cluster.<span class="built_in">pool_list</span>(poolList);   <span class="comment">//获取存储池列表</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> iter : poolList)&#123;</span><br><span class="line">        std::cout&lt;&lt;iter&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译源码，然后，使用-lrados链接librados，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ -g -c ceph-client.cc -o ceph-client.o </span><br><span class="line">g++ -g ceph-client.o -lrados -o ceph-client</span><br></pre></td></tr></table></figure><p>ceph源码开发vstart环境下的编译，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -g librados_rados.cpp -lrados -L/home/watson/ceph/build/lib -o librados_rados -Wl,-rpath,/home/watson/ceph/build/lib</span><br></pre></td></tr></table></figure><h2 id="第-3-步：创建-I-O-上下文"><a href="#第-3-步：创建-I-O-上下文" class="headerlink" title="第 3 步：创建 I&#x2F;O 上下文"></a>第 3 步：创建 I&#x2F;O 上下文</h2><p>一旦客户端应用程序拥有集群句柄并连接到 Ceph 存储集群，就可以创建 I&#x2F;O 上下文并开始读取和写入数据。I&#x2F;O 上下文将连接绑定到特定池。用户必须具有适当的CAPS权限才能访问指定的池。例如，具有读取权限但没有写入权限的用户将只能读取数据。I&#x2F;O 上下文功能包括：</p><ul><li>写入&#x2F;读取数据和扩展属性</li><li>列出并迭代对象和扩展属性</li><li>快照池、列表快照等<br><img src="/images/Ceph_Librados_api%E4%BD%BF%E7%94%A8_3.png"><br>RADOS 使客户端应用程序能够进行同步和异步交互。一旦应用程序具有 I&#x2F;O 上下文，读&#x2F;写操作只需要知道对象&#x2F;xattr 名称。librados中封装的 CRUSH 算法使用Cluster map来选择合适的 OSD。OSD 守护进程自动处理副本。librados库将对象映射到归置组。以下示例使用默认数据池。但是，也可以使用 API 列出池、确保它们存在或创建和删除池。对于写操作，示例说明了如何使用同步模式。对于读取操作，示例说明了如何使用异步模式。<code>(提示：使用此 API 删除池时要小心。如果删除池，则该池和池中的所有数据都将丢失。)</code><br><strong>C创建Ceph IO上下文示例</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">rados_t</span> cluster;      <span class="comment">//集群句柄</span></span><br><span class="line">    <span class="type">rados_ioctx_t</span> io;     <span class="comment">//io上下文</span></span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">    <span class="type">char</span> poolname[] = <span class="string">&quot;testpool&quot;</span>;</span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    <span class="type">int</span> err;</span><br><span class="line">    <span class="comment">/*  为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！  */</span></span><br><span class="line">    err = rados_create2(&amp;cluster,cluster_name,user_name,flags);</span><br><span class="line">    err = rados_conf_read_file(cluster,conf_flie);</span><br><span class="line">    err = rados_conf_parse_argv(cluster,argc,argv);</span><br><span class="line">    err = rados_connect(cluster);</span><br><span class="line">    <span class="keyword">if</span>(err &lt; <span class="number">0</span>)                     <span class="comment">//检查是否连接到集群上</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">&quot;%s: Cannot connect to cluster: %s\n&quot;</span>,argv[<span class="number">0</span>],strerror(-err));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Connected to the cluster......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//err = rados_pool_delete(cluster,poolname);</span></span><br><span class="line">    <span class="type">int</span> poolID = rados_pool_lookup(cluster,poolname);  <span class="comment">//通过poolname获取pool的ID，若池不存在返回-ENOENT</span></span><br><span class="line">    <span class="keyword">if</span>(poolID == -ENOENT)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;this pool does not exist,and create the pool...... \n&quot;</span>);</span><br><span class="line">        rados_pool_create(cluster,poolname);</span><br><span class="line">    &#125;</span><br><span class="line">    err = rados_ioctx_create(cluster,poolname,&amp;io);    <span class="comment">//初始化io上下文</span></span><br><span class="line">    <span class="type">char</span> obj_name[] = <span class="string">&quot;obj&quot;</span>;</span><br><span class="line">    <span class="type">char</span> obj_content[] = <span class="string">&quot;Hello librados&quot;</span>;</span><br><span class="line">    err = rados_write(io,obj_name,obj_content,<span class="built_in">strlen</span>(obj_content),<span class="number">0</span>);    <span class="comment">//往集群写入对象</span></span><br><span class="line">    <span class="keyword">if</span>(err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;rados_write success......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> xattr[] = <span class="string">&quot;en_US&quot;</span>;</span><br><span class="line">    err = rados_setxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>,xattr,<span class="number">5</span>);     <span class="comment">//给对象设置属性</span></span><br><span class="line">    <span class="keyword">if</span>(err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Set object xattr success......\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">rados_completion_t</span> comp;</span><br><span class="line">    err = rados_aio_create_completion(<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,&amp;comp);      <span class="comment">//异步读</span></span><br><span class="line">    <span class="type">char</span> read_ret[<span class="number">1024</span>];</span><br><span class="line">    err = rados_aio_read(io,obj_name,comp,read_ret,<span class="keyword">sizeof</span>(read_ret),<span class="number">0</span>);</span><br><span class="line">    rados_aio_wait_for_complete(comp);</span><br><span class="line">    <span class="keyword">if</span>( err == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\&#x27;s content is %s\n&quot;</span>,obj_name,read_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;read_aio_read: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    rados_aio_release(comp);</span><br><span class="line">    err = rados_read(io,obj_name,read_ret,<span class="keyword">sizeof</span>(read_ret),<span class="number">0</span>);        <span class="comment">//同步读</span></span><br><span class="line">    <span class="keyword">if</span>( err &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\&#x27;s content is %s\n&quot;</span>,obj_name,read_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;read_read: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> xattr_ret[<span class="number">100</span>];</span><br><span class="line">    err = rados_getxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>,xattr_ret,<span class="number">6</span>);     <span class="comment">//获取对象属性</span></span><br><span class="line">    <span class="keyword">if</span>( err &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Read %s\&#x27;s xattr \&quot;lang\&quot; is %s\n&quot;</span>,obj_name,xattr_ret);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;rados_getxattr: err\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    err = rados_rmxattr(io,obj_name,<span class="string">&quot;lang&quot;</span>);     <span class="comment">//删除对象属性</span></span><br><span class="line">    err = rados_remove(io,obj_name);     <span class="comment">//删除对象</span></span><br><span class="line">    rados_ioctx_destroy(io);   <span class="comment">//释放io上下文</span></span><br><span class="line">    rados_shutdown(cluster);    <span class="comment">//关闭集群句柄</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><strong>C++创建Ceph IO上下文示例</strong><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;rados/librados.hpp&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">const</span> <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    librados::Rados cluster;</span><br><span class="line">    librados::IoCtx io_ctx;</span><br><span class="line">    <span class="type">char</span> cluster_name[] = <span class="string">&quot;ceph&quot;</span>;</span><br><span class="line">    <span class="type">char</span> user_name[] = <span class="string">&quot;client.admin&quot;</span>;</span><br><span class="line">    <span class="type">char</span> conf_flie[] = <span class="string">&quot;/home/watson/ceph/build/ceph.conf&quot;</span>;</span><br><span class="line">    <span class="type">char</span> poolname[] = <span class="string">&quot;testpool&quot;</span>;</span><br><span class="line">    <span class="type">uint64_t</span> flags;</span><br><span class="line">    <span class="type">int</span> ret;</span><br><span class="line">    <span class="comment">/*  为了使示例代码更可观性，不对返回值判错，实际应用中需要进行判错，请养成良好习惯！  */</span></span><br><span class="line">    ret = cluster.<span class="built_in">init2</span>(user_name,cluster_name,flags);</span><br><span class="line">    ret = cluster.<span class="built_in">conf_read_file</span>(conf_flie);</span><br><span class="line">    ret = cluster.<span class="built_in">conf_parse_argv</span>(argc,argv);</span><br><span class="line">    ret = cluster.<span class="built_in">connect</span>();       </span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span> )           <span class="comment">//测试集群连接情况</span></span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t connect to cluster! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Connected to the cluster.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> poolID = cluster.<span class="built_in">pool_lookup</span>(poolname);     <span class="comment">//通过pool名检测是否存在pool</span></span><br><span class="line">    <span class="keyword">if</span>(poolID == -ENOENT)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;this pool does not exist,and create the pool...... \n&quot;</span>);</span><br><span class="line">        cluster.<span class="built_in">pool_create</span>(poolname);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;pool &quot;</span>&lt;&lt;poolID&lt;&lt;<span class="string">&quot;  is using......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = cluster.<span class="built_in">ioctx_create</span>(poolname,io_ctx);    <span class="comment">//初始化io_ctx</span></span><br><span class="line">    <span class="type">char</span> obj_name[] = <span class="string">&quot;obj&quot;</span>;</span><br><span class="line">    librados::bufferlist bl;</span><br><span class="line">    bl.<span class="built_in">append</span>(<span class="string">&quot;Hello Librados!&quot;</span>);</span><br><span class="line">    ret = io_ctx.<span class="built_in">write_full</span>(obj_name,bl);         <span class="comment">//往集群写入数据</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t write object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Write success......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist lang_bl;</span><br><span class="line">    lang_bl.<span class="built_in">append</span>(<span class="string">&quot;en_US&quot;</span>);</span><br><span class="line">    ret = io_ctx.<span class="built_in">setxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>,lang_bl);          <span class="comment">//给对象设置属性</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t write object xattr! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;Set xattr success......&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist read_bl;                 <span class="comment">//异步读</span></span><br><span class="line">    <span class="type">int</span> read_len = <span class="number">1024</span>;</span><br><span class="line">    librados::AioCompletion *read_completion = librados::Rados::<span class="built_in">aio_create_completion</span>();</span><br><span class="line">    ret = io_ctx.<span class="built_in">aio_read</span>(obj_name,read_completion,&amp;read_bl,read_len,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    read_completion-&gt;<span class="built_in">wait_for_complete</span>();    <span class="comment">//等待异步完成</span></span><br><span class="line">    ret = read_completion-&gt;<span class="built_in">get_return_value</span>();       <span class="comment">//获取返回值</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;read_bl.<span class="built_in">c_str</span>()&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    librados::bufferlist lang_res;</span><br><span class="line">    ret = io_ctx.<span class="built_in">getxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>,lang_res);       <span class="comment">//获取属性</span></span><br><span class="line">    <span class="keyword">if</span>(ret &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr&lt;&lt;<span class="string">&quot;Couldn&#x27;t read object xattr! error&quot;</span>&lt;&lt;ret&lt;&lt;std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        std::cout&lt;&lt;lang_res.<span class="built_in">c_str</span>()&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ret = io_ctx.<span class="built_in">rmxattr</span>(obj_name,<span class="string">&quot;lang&quot;</span>);     <span class="comment">//删除对象属性</span></span><br><span class="line">    ret = io_ctx.<span class="built_in">remove</span>(obj_name);           <span class="comment">//删除对象</span></span><br><span class="line">    io_ctx.<span class="built_in">close</span>();       <span class="comment">//关闭io</span></span><br><span class="line">    cluster.<span class="built_in">shutdown</span>();      <span class="comment">//关闭集群句柄</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="第-4-步：结束会话"><a href="#第-4-步：结束会话" class="headerlink" title="第 4 步：结束会话"></a>第 4 步：结束会话</h2><p>一旦客户端应用程序完成了 I&#x2F;O 上下文和集群句柄，应用程序应该关闭连接并关闭句柄。对于异步 I&#x2F;O，应用程序还应确保挂起的异步操作已完成。<br><strong>C结束会话示例</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rados_ioctx_destroy(io); </span><br><span class="line">rados_shutdown(cluster);</span><br></pre></td></tr></table></figure><p><strong>C++结束会话示例</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">io_ctx.<span class="built_in">close</span>(); </span><br><span class="line">cluster.<span class="built_in">shutdown</span>();</span><br></pre></td></tr></table></figure><p>补充：查看pool下的object对象 –all 显示所有namespace的object</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rados ls -p pool --all</span><br></pre></td></tr></table></figure><h2 id="LIBRADOS常用接口"><a href="#LIBRADOS常用接口" class="headerlink" title="LIBRADOS常用接口"></a>LIBRADOS常用接口</h2><ol><li><p>集群配置：提供了获取和设置配置值的方法，读取Ceph配置文件，并解析参数。<br> Rados.conf_get(option)<br> Rados.conf_set(option, val)<br> Rados.conf_read_file(path)<br> Rados.conf_parse_argv(args)<br> Rados.version()</p></li><li><p>连接管理：连接到集群、检查集群、检索集群的统计数据，并从集群断开连接。也可以断言集群句柄处于一个特定的状态（例如，”配置”，”连接”等等）。<br> Rados.connect(timeout)<br> Rados.shutdown()<br> Rados.get_fsid()<br> Rados.get_cluster_stats()</p></li><li><p>池操作：列出可用的池，创建一个池，检查一个池是否存在，并删除一个池。<br> Rados.list_pools()<br> Rados.create_pool(pool_name, crush_rule, auid)<br> Rados.pool_exists(pool_name)<br> Rados.delete_pool(pool_name)</p></li><li><p>CLI 命令：Ceph CLI命令在内部使用以下librados Python绑定方法。<br> Rados.mon_command(cmd, inbuf, timeout, target)<br> Rados.osd_command(osdid, cmd, inbuf, timeout)<br> Rados.mgr_command(cmd, inbuf, timeout, target)<br> Rados.pg_command(pgid, cmd, inbuf, timeout)</p></li><li><p>I&#x2F;O上下文：为了将数据写入Ceph对象存储和从Ceph对象存储读取数据，必须创建一个输入&#x2F;输出上下文（ioctx）。Rados类提供了open_ioctx()和open_ioctx2()方法。其余的操作涉及调用Ioctx和其他类的方法。<br> Rados.open_ioctx(ioctx_name)<br> Ioctx.require_ioctx_open()<br> Ioctx.get_stats()<br> Ioctx.get_last_version()<br> Ioctx.close()</p></li><li><p>对象操作：同步或异步地读和写对象。一个对象有一个名称（或键）和数据。<br> Ioctx.aio_write(object_name, to_write, offset, oncomplete, onsafe)<br> Ioctx.aio_write_full(object_name, to_write, oncomplete, onsafe)<br> Ioctx.aio_append(object_name, to_append, oncomplete, onsafe)<br> Ioctx.write(key, data, offset)<br> Ioctx.write_full(key, data)<br> Ioctx.aio_flush()<br> Ioctx.set_locator_key(loc_key)<br> Ioctx.aio_read(object_name, length, offset, oncomplete)<br> Ioctx.read(key, length, offset)<br> Ioctx.stat(key)<br> Ioctx.trunc(key, size)<br> Ioctx.remove_object(key)</p></li><li><p>对象扩展属性：在一个对象上设置扩展属性(XATTRs)。<br> Ioctx.set_xattr(key, xattr_name, xattr_value)<br> Ioctx.get_xattrs(oid)<br> XattrIterator.<strong>next</strong>()<br> Ioctx.get_xattr(key, xattr_name)<br> Ioctx.rm_xattr(key, xattr_name)</p></li><li><p>对象接口：从一个池中检索一个对象的列表，并对它们进行迭代。提供的对象接口使每个对象看起来像一个文件，可以对对象进行同步操作。对于异步操作，应该使用I&#x2F;O上下文的方法。<br> Ioctx.list_objects()<br> ObjectIterator.<strong>next</strong>()<br> Object.read(length&#x3D;1024 * 1024)<br> Object.write(string_to_write)<br> Object.get_xattrs()<br> Object.get_xattr(xattr_name)<br> Object.set_xattr(xattr_name, xattr_value)<br> Object.rm_xattr(xattr_name)<br> Object.stat()<br> Object.remove()</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Librados-API概述&quot;&gt;&lt;a href=&quot;#Librados-API概述&quot; class=&quot;headerlink&quot; title=&quot;Librados API概述&quot;&gt;&lt;/a&gt;Librados API概述&lt;/h1&gt;&lt;p&gt;Ceph存储集群提供基本的存储服务，Ceph</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph_librados介绍</title>
    <link href="https://watsonlu6.github.io/Ceph_librados%E4%BB%8B%E7%BB%8D/"/>
    <id>https://watsonlu6.github.io/Ceph_librados%E4%BB%8B%E7%BB%8D/</id>
    <published>2021-06-05T06:15:14.000Z</published>
    <updated>2024-07-27T14:37:27.947Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-Librados介绍"><a href="#Ceph-Librados介绍" class="headerlink" title="Ceph Librados介绍"></a>Ceph Librados介绍</h1><h2 id="Ceph-Librados-概述"><a href="#Ceph-Librados-概述" class="headerlink" title="Ceph Librados 概述"></a>Ceph Librados 概述</h2><p>一个Ceph客户端，通过librados直接与OSD交互，来存储和取出数据。为了与OSD交互，客户端应用必须直接调用librados，连接一个Ceph Monitor。一旦连接好以后，librados会从Monitor处取回一个Cluster map。当客户端的应用想读或者取数据的时候，它要创建一个I&#x2F;O上下文并且与一个pool绑定。通过这个I&#x2F;O上下文，客户端将Object的名字提供给librados，然后librados会根据Object的名字和Cluster map计算出相应的PG和OSD的位置。然后客户端就可以读或者写数据。客户端的应用无需知道这个集群的拓扑结构。</p><p>Ceph客户端主要是实现了接口，对外提供了访问的功能。上层可以通过接口访问Ceph存储。Ceph的客户端通过一套名为librados的接口进行集群的访问，这里的访问包括对集群的整体访问和对象的访问两类接口。这套接口（API）包括C、C++和Python常见语言的实现，接口通过网络实现对Ceph集群的访问。在用户层面，可以在自己的程序中调用该接口，从而集成Ceph集群的存储功能，或者在监控程序中实现对Ceph集群状态的监控。所谓集群的整体访问包括连接集群、创建存储池、删除存储池和获取集群状态等等。所谓对象访问是之对存储池中对象的访问，包括创建删除对象、向对象写数据或者追加数据和读对象数据等接口。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_1.png"></p><h2 id="客户端基本架构概述"><a href="#客户端基本架构概述" class="headerlink" title="客户端基本架构概述"></a>客户端基本架构概述</h2><p>librados客户端基本架构如下图所示，主要包括4层，分别是API层、IO处理层、对象处理层和消息收发层。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_2.png"></p><ul><li><strong>API层</strong>是一个抽象层，为上层提供统一的接口。API层提供的原生接口包括C和C++两种语言的实现外，还有Python的实现。</li><li><strong>IO处理层</strong>用于实现IO的简单封装，其通过一个名为ObjectOperation类实现，该类主要包括的是读写操作的数据信息。之后在IO处理层在IoCtxImpl::operate函数中将ObjectOperation转换为Objecter::Op类的对象，并将该对象提交到对象处理层进行进一步的处理。</li><li><strong>对象处理层</strong>包括了Ceph对象处理所需要的信息，包括通信管道、OSDMap和MonMap等内容。因此，在这里，根据对象的信息可以计算出对象存储的具体位置，最终找到客户端与OSD的连接信息（Session）。</li><li><strong>消息收发层</strong>的接口会被对象处理层调用，此时消息会传递到本层，并且通过本层的线程池发送到具体的OSD。这里需要注意的是，消息收发层与服务端的消息收发公用Messager的代码。</li></ul><h2 id="核心流程图"><a href="#核心流程图" class="headerlink" title="核心流程图"></a>核心流程图</h2><p>先根据配置文件调用librados创建Rados，接下来为这个Rados创建一个RadosClient，RadosClient包含3个主要模块(finisher、Messenger、Objecter)。再根据pool创建对应的ioctx，在ioctx中能够找到RadosClient。再调用OSDC生成对应的OSD请求，与OSD进行通信响应请求。这从大体上叙述了librados与osdc在整个Ceph中的作用。</p><p>具体细节可以按照该流程读对应源代码理解。在这个流程中需要注意的是_op_submit函数会调用_calc_target和_get_session两个函数，两个函数的作用分别是获取目的OSD和对应的Session（连接），这个是后面发送数据的基础。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_3.png"></p><h2 id="Librados与OSDC的关系"><a href="#Librados与OSDC的关系" class="headerlink" title="Librados与OSDC的关系"></a>Librados与OSDC的关系</h2><p>Librados与OSDC位于ceph客户端中比较底层的位置。</p><ul><li>Librados模块是RADOS对象存储系统访问的接口，它提供了pool的创建、删除、对象的创建、删除、读写等基本操作接口。类RadosClient是librados模块的核心管理类，处理整个RADOS系统层面以及pool层面的管理。类ioctxlmpl实现单个pool层的对象读写等操作。</li><li>OSDC模块实现了请求的封装和通过网络模块发送请求的逻辑，其核心类Object完成对象的地址计算、消息的发送和处理超时等工作。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_4.png"><br>librados模块包含两个部分，分别是RadosClient 模块和IoctxImpl。RadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。</li></ul><h2 id="Librados模块"><a href="#Librados模块" class="headerlink" title="Librados模块"></a>Librados模块</h2><h4 id="类RadosClient"><a href="#类RadosClient" class="headerlink" title="类RadosClient"></a>类RadosClient</h4><p>RadosClient处于最上层，是librados的核心管理类，管理着整个RADOS系统层面以及pool层面的管理。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">librados</span>::RadosClient : <span class="keyword">public</span> Dispatcher    <span class="comment">//继承Dispatcher(消息分发类)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//unique_ptr智能指针</span></span><br><span class="line">    std::unique_ptr&lt;CephContext,std::function&lt;<span class="type">void</span>(CephContext*)&gt; &gt; cct_deleter;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> Dispatcher::cct;</span><br><span class="line">    <span class="type">const</span> ConfigProxy&amp; conf;  <span class="comment">//配置文件</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">enum</span> &#123;</span><br><span class="line">    DISCONNECTED,</span><br><span class="line">    CONNECTING,</span><br><span class="line">    CONNECTED,</span><br><span class="line">    &#125; state;   <span class="comment">//Monitor的网络连接状态</span></span><br><span class="line">    MonClient monclient;    <span class="comment">//Monitor客户端</span></span><br><span class="line">    MgrClient mgrclient;    <span class="comment">//MGR客户端</span></span><br><span class="line">    Messenger *messenger;    <span class="comment">//网络消息接口</span></span><br><span class="line">    <span class="type">uint64_t</span> instance_id;     <span class="comment">//rados客户端实例的ID</span></span><br><span class="line">    <span class="comment">//相关消息分发 Dispatcher类的函数重写</span></span><br><span class="line">    <span class="type">bool</span> _dispatch(Message *m);</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_dispatch</span><span class="params">(Message *m)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_get_authorizer</span><span class="params">(<span class="type">int</span> dest_type, AuthAuthorizer **authorizer)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">ms_handle_connect</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_handle_reset</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">ms_handle_remote_reset</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">ms_handle_refused</span><span class="params">(Connection *con)</span> <span class="keyword">override</span></span>;</span><br><span class="line">    Objecter *objecter;   <span class="comment">//OSDC模块中用于发送封装好的OP消息</span></span><br><span class="line">    Mutex lock;</span><br><span class="line">    Cond cond;</span><br><span class="line">    SafeTimer timer;    <span class="comment">//定时器</span></span><br><span class="line">    <span class="type">int</span> refcnt;     <span class="comment">//引用计算</span></span><br><span class="line">    <span class="type">version_t</span> log_last_version;</span><br><span class="line">    <span class="type">rados_log_callback_t</span> log_cb;</span><br><span class="line">    <span class="type">rados_log_callback2_t</span> log_cb2;</span><br><span class="line">    <span class="type">void</span> *log_cb_arg;</span><br><span class="line">    string log_watch;</span><br><span class="line">    <span class="type">bool</span> service_daemon = <span class="literal">false</span>;</span><br><span class="line">    string daemon_name, service_name;</span><br><span class="line">    map&lt;string,string&gt; daemon_metadata;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">wait_for_osdmap</span><span class="params">()</span></span>;</span><br><span class="line">    Finisher finisher;      <span class="comment">//用于执行回调函数的finisher类</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">RadosClient</span><span class="params">(CephContext *cct_)</span></span>;    </span><br><span class="line">    ~<span class="built_in">RadosClient</span>() <span class="keyword">override</span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">ping_monitor</span><span class="params">(string mon_id, string *result)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">connect</span><span class="params">()</span></span>;   <span class="comment">//RadosClient的初始化函数、  连接</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">shutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">watch_flush</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">async_watch_flush</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">uint64_t</span> <span class="title">get_instance_id</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_min_compatible_osd</span><span class="params">(<span class="type">int8_t</span>* require_osd_release)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_min_compatible_client</span><span class="params">(<span class="type">int8_t</span>* min_compat_client,<span class="type">int8_t</span>* require_min_compat_client)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">wait_for_latest_osdmap</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">//创建一个pool相关的上下文信息IoCtxImpl对象（根据pool名字或Id创建ioctx）</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">create_ioctx</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, IoCtxImpl **io)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">create_ioctx</span><span class="params">(<span class="type">int64_t</span>, IoCtxImpl **io)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_fsid</span><span class="params">(std::string *s)</span></span>;</span><br><span class="line">    <span class="comment">//用于查找pool</span></span><br><span class="line">    <span class="function"><span class="type">int64_t</span> <span class="title">lookup_pool</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">pool_requires_alignment</span><span class="params">(<span class="type">int64_t</span> pool_id)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_requires_alignment2</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">bool</span> *<span class="keyword">requires</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">uint64_t</span> <span class="title">pool_required_alignment</span><span class="params">(<span class="type">int64_t</span> pool_id)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_required_alignment2</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">uint64_t</span> *alignment)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_get_name</span><span class="params">(<span class="type">uint64_t</span> pool_id, std::string *name, <span class="type">bool</span> wait_latest_map = <span class="literal">false</span>)</span></span>;</span><br><span class="line">    <span class="comment">//用于列出所有的pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_list</span><span class="params">(std::list&lt;std::pair&lt;<span class="type">int64_t</span>, string&gt; &gt;&amp; ls)</span></span>;</span><br><span class="line">    <span class="comment">//用于获取pool的统计信息</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_pool_stats</span><span class="params">(std::list&lt;string&gt;&amp; ls, map&lt;string,::<span class="type">pool_stat_t</span>&gt; *result,<span class="type">bool</span> *per_pool)</span></span>;</span><br><span class="line">    <span class="comment">//用于获取系统的统计信息</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_fs_stats</span><span class="params">(ceph_statfs&amp; result)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">get_pool_is_selfmanaged_snaps_mode</span><span class="params">(<span class="type">const</span> std::string&amp; pool)</span></span>;</span><br><span class="line">    <span class="comment">//pool的同步创建</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_create</span><span class="params">(string&amp; name, <span class="type">int16_t</span> crush_rule=<span class="number">-1</span>)</span></span>;</span><br><span class="line">    <span class="comment">//pool的异步创建</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_create_async</span><span class="params">(string&amp; name, PoolAsyncCompletionImpl *c,<span class="type">int16_t</span> crush_rule=<span class="number">-1</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_get_base_tier</span><span class="params">(<span class="type">int64_t</span> pool_id, <span class="type">int64_t</span>* base_tier)</span></span>;</span><br><span class="line">    <span class="comment">//同步删除pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_delete</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">    <span class="comment">//异步删除pool</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pool_delete_async</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, PoolAsyncCompletionImpl *c)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">blacklist_add</span><span class="params">(<span class="type">const</span> string&amp; client_address, <span class="type">uint32_t</span> expire_seconds)</span></span>;</span><br><span class="line">    <span class="comment">//处理Mon相关命令,调用monclient.start_mon_command 把命令发送给Mon处理</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">mon_command_async</span><span class="params">(………)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(<span class="type">int</span> rank,<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mon_command</span><span class="params">(string name,<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl,bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">mgr_command</span><span class="params">(<span class="type">const</span> vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist &amp;inbl, bufferlist *outbl, string *outs)</span></span>;</span><br><span class="line">    <span class="comment">//处理OSD相关命令</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">osd_command</span><span class="params">(<span class="type">int</span> osd, vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist&amp; inbl,bufferlist *poutbl, string *prs)</span></span>;</span><br><span class="line">    <span class="comment">//处理PG相关命令</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pg_command</span><span class="params">(<span class="type">pg_t</span> pgid, vector&lt;string&gt;&amp; cmd, <span class="type">const</span> bufferlist&amp; inbl,bufferlist *poutbl, string *prs)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">handle_log</span><span class="params">(MLog *m)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">monitor_log</span><span class="params">(<span class="type">const</span> string&amp; level, <span class="type">rados_log_callback_t</span> cb,<span class="type">rados_log_callback2_t</span> cb2, <span class="type">void</span> *arg)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">put</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">blacklist_self</span><span class="params">(<span class="type">bool</span> set)</span></span>;</span><br><span class="line">    <span class="function">std::string <span class="title">get_addrs</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">service_daemon_register</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; service,  <span class="comment">///&lt; service name (e.g., &#x27;rgw&#x27;)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; name,     <span class="comment">///&lt; daemon name (e.g., &#x27;gwfoo&#x27;)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::map&lt;std::string,std::string&gt;&amp; metadata)</span></span>; <span class="comment">///&lt; static metadata about daemon</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">service_daemon_update_status</span><span class="params">(std::map&lt;std::string,std::string&gt;&amp;&amp; status)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">mon_feature_t</span> <span class="title">get_required_monitor_features</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_pgs</span><span class="params">(<span class="type">int64_t</span> pool_id, std::vector&lt;std::string&gt;* pgs)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="类IoctxImpl"><a href="#类IoctxImpl" class="headerlink" title="类IoctxImpl"></a>类IoctxImpl</h4><p>类IoctxImpl是对于其中的某一个pool进行管理，如对 对象的读写等操作的控制。<br>该类是pool的上下文信息，一个pool对应一个IoctxImpl对象。librados中所有关于io操作的API都设计在librados::IoCtx中，接口的真正实现在ioCtxImpl中，它的处理过程如下：</p><ol><li>把请求封装成ObjectOperation类(osdc类中)</li><li>把相关的pool信息添加到里面，封装成Object::Op对象</li><li>调用响应的函数object-&gt;op_submit发送给相应的OSD</li><li>操作完成后，调用相应的回调函数。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">librados</span>::IoCtxImpl &#123;</span><br><span class="line">  std::atomic&lt;<span class="type">uint64_t</span>&gt; ref_cnt = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">  RadosClient *client;</span><br><span class="line">  <span class="type">int64_t</span> poolid;</span><br><span class="line">  <span class="type">snapid_t</span> snap_seq;</span><br><span class="line">  ::SnapContext snapc;</span><br><span class="line">  <span class="type">uint64_t</span> assert_ver;</span><br><span class="line">  <span class="type">version_t</span> last_objver;</span><br><span class="line">  <span class="type">uint32_t</span> notify_timeout;</span><br><span class="line">  <span class="type">object_locator_t</span> oloc;</span><br><span class="line"></span><br><span class="line">  Mutex aio_write_list_lock;</span><br><span class="line">  <span class="type">ceph_tid_t</span> aio_write_seq;</span><br><span class="line">  Cond aio_write_cond;</span><br><span class="line">  xlist&lt;AioCompletionImpl*&gt; aio_write_list;</span><br><span class="line">  map&lt;<span class="type">ceph_tid_t</span>, std::list&lt;AioCompletionImpl*&gt; &gt; aio_write_waiters;</span><br><span class="line"></span><br><span class="line">  Objecter *objecter;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">IoCtxImpl</span>();</span><br><span class="line">  <span class="built_in">IoCtxImpl</span>(RadosClient *c, Objecter *objecter,<span class="type">int64_t</span> poolid, <span class="type">snapid_t</span> s);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">dup</span><span class="params">(<span class="type">const</span> IoCtxImpl&amp; rhs)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_snap_read</span><span class="params">(<span class="type">snapid_t</span> s)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">set_snap_write_context</span><span class="params">(<span class="type">snapid_t</span> seq, vector&lt;<span class="type">snapid_t</span>&gt;&amp; snaps)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">put</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">queue_aio_write</span><span class="params">(<span class="keyword">struct</span> AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">complete_aio_write</span><span class="params">(<span class="keyword">struct</span> AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">flush_aio_writes_async</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">flush_aio_writes</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">get_id</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">string <span class="title">get_cached_pool_name</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_object_hash_position</span><span class="params">(<span class="type">const</span> std::string&amp; oid, <span class="type">uint32_t</span> *hash_position)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_object_pg_hash_position</span><span class="params">(<span class="type">const</span> std::string&amp; oid, <span class="type">uint32_t</span> *pg_hash_position)</span></span>;</span><br><span class="line">  ::<span class="function">ObjectOperation *<span class="title">prepare_assert_ops</span><span class="params">(::ObjectOperation *op)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// snaps</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_list</span><span class="params">(vector&lt;<span class="type">uint64_t</span>&gt; *snaps)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_lookup</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *name, <span class="type">uint64_t</span> *snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_get_name</span><span class="params">(<span class="type">uint64_t</span> snapid, std::string *s)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_get_stamp</span><span class="params">(<span class="type">uint64_t</span> snapid, <span class="type">time_t</span> *t)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_create</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* snapname)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_create</span><span class="params">(<span class="type">uint64_t</span> *snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">aio_selfmanaged_snap_create</span><span class="params">(<span class="type">uint64_t</span> *snapid, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">snap_remove</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* snapname)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">rollback</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *snapName)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_remove</span><span class="params">(<span class="type">uint64_t</span> snapid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">aio_selfmanaged_snap_remove</span><span class="params">(<span class="type">uint64_t</span> snapid, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">selfmanaged_snap_rollback_object</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid,::SnapContext&amp; snapc, <span class="type">uint64_t</span> snapid)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// io</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">nlist</span><span class="params">(Objecter::NListContext *context, <span class="type">int</span> max_entries)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">nlist_seek</span><span class="params">(Objecter::NListContext *context, <span class="type">uint32_t</span> pos)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">nlist_seek</span><span class="params">(Objecter::NListContext *context, <span class="type">const</span> rados_object_list_cursor&amp; cursor)</span></span>;</span><br><span class="line">  <span class="function">rados_object_list_cursor <span class="title">nlist_get_cursor</span><span class="params">(Objecter::NListContext *context)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">object_list_slice</span><span class="params">(……)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">create</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">bool</span> exclusive)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">write</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">append</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">write_full</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">writesame</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl,<span class="type">size_t</span> write_len, <span class="type">uint64_t</span> offset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">mapext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> off, <span class="type">size_t</span> len,std::map&lt;<span class="type">uint64_t</span>,<span class="type">uint64_t</span>&gt;&amp; m)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">sparse_read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, std::map&lt;<span class="type">uint64_t</span>,<span class="type">uint64_t</span>&gt;&amp; m,bufferlist&amp; bl, <span class="type">size_t</span> len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">checksum</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">int</span> flags)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">stat</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> *psize, <span class="type">time_t</span> *pmtime)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">stat2</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> *psize, <span class="keyword">struct</span> timespec *pts)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">trunc</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> size)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cmpext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> off, bufferlist&amp; cmp_bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">tmap_update</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, bufferlist&amp; cmdbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">exec</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *cls, <span class="type">const</span> <span class="type">char</span> *method, bufferlist&amp; inbl, bufferlist&amp; outbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">getxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">setxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">getxattrs</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, map&lt;string, bufferlist&gt;&amp; attrset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">rmxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">operate</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, ::ObjectOperation *o, ceph::real_time *pmtime, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">operate_read</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, ::ObjectOperation *o, bufferlist *pbl, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_operate</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_operate_read</span><span class="params">(…………)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_stat_Ack</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_stat2_Ack</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">C_aio_Complete</span> : <span class="keyword">public</span> Context &#123;……  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_read</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_read</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_sparse_read</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cmpext</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> off,bufferlist&amp; cmp_bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cmpext</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_write</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_append</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl, <span class="type">size_t</span> len)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_write_full</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_writesame</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c,<span class="type">const</span> bufferlist&amp; bl, <span class="type">size_t</span> write_len, <span class="type">uint64_t</span> off)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_remove</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span> &amp;oid, AioCompletionImpl *c, <span class="type">int</span> flags=<span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_exec</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_exec</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_stat</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> *psize, <span class="type">time_t</span> *pmtime)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_stat2</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">uint64_t</span> *psize, <span class="keyword">struct</span> timespec *pts)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_getxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,<span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_setxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c, <span class="type">const</span> <span class="type">char</span> *name, bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_getxattrs</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,map&lt;string, bufferlist&gt;&amp; attrset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_rmxattr</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, AioCompletionImpl *c,<span class="type">const</span> <span class="type">char</span> *name)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_cancel</span><span class="params">(AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">hit_set_list</span><span class="params">(<span class="type">uint32_t</span> hash, AioCompletionImpl *c,std::list&lt; std::pair&lt;<span class="type">time_t</span>, <span class="type">time_t</span>&gt; &gt; *pls)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">hit_set_get</span><span class="params">(<span class="type">uint32_t</span> hash, AioCompletionImpl *c, <span class="type">time_t</span> stamp,bufferlist *pbl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_objects</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_inconsistent_snapsets</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_sync_op_version</span><span class="params">(<span class="type">version_t</span> ver)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_watch</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_watch</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">watch_check</span><span class="params">(<span class="type">uint64_t</span> cookie)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">unwatch</span><span class="params">(<span class="type">uint64_t</span> cookie)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_unwatch</span><span class="params">(<span class="type">uint64_t</span> cookie, AioCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">notify</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">notify_ack</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid, <span class="type">uint64_t</span> notify_id, <span class="type">uint64_t</span> cookie,bufferlist&amp; bl)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">aio_notify</span><span class="params">(………)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">set_alloc_hint</span><span class="params">(……)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">version_t</span> <span class="title">last_version</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_assert_version</span><span class="params">(<span class="type">uint64_t</span> ver)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set_notify_timeout</span><span class="params">(<span class="type">uint32_t</span> timeout)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cache_pin</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">cache_unpin</span><span class="params">(<span class="type">const</span> <span class="type">object_t</span>&amp; oid)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_enable</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, <span class="type">bool</span> force)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">application_enable_async</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, <span class="type">bool</span> force,PoolAsyncCompletionImpl *c)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_list</span><span class="params">(std::set&lt;std::string&gt; *app_names)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_get</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key,std::string* value)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_set</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key,<span class="type">const</span> std::string&amp; value)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_remove</span><span class="params">(<span class="type">const</span> std::string&amp; app_name,<span class="type">const</span> std::string &amp;key)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">application_metadata_list</span><span class="params">(<span class="type">const</span> std::string&amp; app_name, std::map&lt;std::string, std::string&gt; *values)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ol><h4 id="librados主要接口"><a href="#librados主要接口" class="headerlink" title="librados主要接口"></a>librados主要接口</h4><ol><li>集群句柄创建<br>librados::Rados对象是用来操纵ceph集群的句柄，使用init来创建RadosClient，之后读取指定的ceph配置文件，获取monitor的ip和端口号。RadosClient里面有与monitor通信的MonClient和用于与OSD通信的Messenger。</li><li>集群连接<br>初始化集群句柄之后，就可以使用这个句柄来连接集群了<br>RadosClient::connect完成了连接操作：<br> a. 调用monclient.build_inital_monmap，从配置文件种检查是否有初始化的monitor的地址信息<br> b. 创建网络通信模块messenger，并设置相关的Policy信息<br> c. 创建Objecter对象并初始化<br> d. 调用monclient.init()函数初始化monclient<br> e. Timer定时器初始化，Finisher对象初始化</li><li>IO上下文环境初始化<br>使用句柄创建好存储池后，还需要创建与存储池相关的IO上下文句柄<br>rados.ioctx_create(pool_name, io_ctx)</li><li>对象读写<br>创建对象并写入数据：io_ctx.create_full(object_name,bl)<br>读取对象中的数据到bufferlist中，对象读取有同步读取和异步读取两种接口：io_ctx.read和io_ctx.aio_read<br> a. 同步读取：io_ctx.read(object_name,read_bl,read_len,0)<br> b. 异步读取：需要指定完成读取数据后的回调，用于检查读取是否完成<br> librados::AioCompletion *read_completion &#x3D; librados::Rados::aio_create_completion();<br> io_ctx.aio_read(object_name,read_completion,&amp;read_buff,read_len,0)<br> read_completion-&gt;wait_for_complete()<br> 同时还要获取返回值，得到读取对象的字节数</li><li>IO上下文关闭<br>io_ctx.close()</li><li>集群句柄关闭<br>rados.shutdown()<br>上述功能通过Rados和IoCtx两个类实现，两个类的主要函数如下图所示（这里仅是示例，实际接口数量要多很多，具体参考源代码）。<br><img src="/images/Ceph_Librados%E4%BB%8B%E7%BB%8D_5.png"></li></ol><h2 id="Ceph官方的示例代码"><a href="#Ceph官方的示例代码" class="headerlink" title="Ceph官方的示例代码"></a>Ceph官方的示例代码</h2><p>为了了解如何使用这些API，这里给出一些代码片段。具体完整的代码大家可以参考Ceph官方的示例代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">librados::IoCtx io_ctx;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *pool_name = <span class="string">&quot;test&quot;</span>;</span><br><span class="line">cluster.<span class="built_in">ioctx_create</span>(pool_name, io_ctx);      <span class="comment">/*  创建进行IO处理的上下文，其实就是用于访问Ceph的对象 */</span></span><br><span class="line"><span class="comment">/* 同步写对象 */</span></span><br><span class="line">librados::bufferlist bl;</span><br><span class="line">bl.<span class="built_in">append</span>(<span class="string">&quot;Hello World!&quot;</span>);  <span class="comment">/* 对象的内容 */</span></span><br><span class="line">ret = io_ctx.<span class="built_in">write_full</span>(<span class="string">&quot;itworld123&quot;</span>, bl);    <span class="comment">/*写入对象itworld123*/</span></span><br><span class="line"><span class="comment">/* 向对象添加属性，这里的属性与文件系统中文件的扩展属性类似。   */</span></span><br><span class="line">librados::bufferlist attr_bl;</span><br><span class="line">attr_bl.<span class="built_in">append</span>(<span class="string">&quot;en_US&quot;</span>);</span><br><span class="line">io_ctx.<span class="built_in">setxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>, attr_bl);</span><br><span class="line"><span class="comment">/* 异步读取对象内容 */</span></span><br><span class="line">librados::bufferlist read_buf;</span><br><span class="line"><span class="type">int</span> read_len = <span class="number">1024</span>;</span><br><span class="line">librados::AioCompletion *read_completion = librados::Rados::<span class="built_in">aio_create_completion</span>();   <span class="comment">/* 创建一个异步完成类对象 */</span></span><br><span class="line">io_ctx.<span class="built_in">aio_read</span>(<span class="string">&quot;itworld123&quot;</span>, read_completion, &amp;read_buf, read_len, <span class="number">0</span>);    <span class="comment">/* 发送读请求 */</span></span><br><span class="line">read_completion-&gt;<span class="built_in">wait_for_complete</span>(); <span class="comment">/* 等待请求完成 */</span></span><br><span class="line">read_completion-&gt;<span class="built_in">get_return_value</span>();  </span><br><span class="line">librados::bufferlist attr_res;</span><br><span class="line">io_ctx.<span class="built_in">getxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>, attr_res);  <span class="comment">/* 读取对象属性 */</span></span><br><span class="line">io_ctx.<span class="built_in">rmxattr</span>(<span class="string">&quot;itworld123&quot;</span>, <span class="string">&quot;test_attr&quot;</span>);      <span class="comment">/* 删除对象的属性 */</span></span><br><span class="line">io_ctx.<span class="built_in">remove</span>(<span class="string">&quot;itworld123&quot;</span>);     <span class="comment">/* 删除对象 */</span>  </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-Librados介绍&quot;&gt;&lt;a href=&quot;#Ceph-Librados介绍&quot; class=&quot;headerlink&quot; title=&quot;Ceph Librados介绍&quot;&gt;&lt;/a&gt;Ceph Librados介绍&lt;/h1&gt;&lt;h2 id=&quot;Ceph-Librados</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph数据读写过程</title>
    <link href="https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/"/>
    <id>https://watsonlu6.github.io/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/</id>
    <published>2021-05-19T09:06:37.000Z</published>
    <updated>2024-07-27T14:31:10.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ceph数据映射过程"><a href="#Ceph数据映射过程" class="headerlink" title="Ceph数据映射过程"></a>Ceph数据映射过程</h2><p>在一个大规模分布式存储系统中，需要解决两个核心问题：“我应该把数据写到哪里？”和“我之前把数据存储在了哪里？”。这就引出了数据寻址的问题。Ceph 的寻址流程可以如下描述。<br> <img src="/images/Ceph%E5%AF%BB%E5%9D%80.png"></p><ul><li><strong>File</strong>：此处的File就是用户需要存储或访问的文件。对于一个基于Ceph开发的对象存储应用而言，这个File也就对应于应用中的“对象” ，也就是用户直接操作的“对象”</li><li><strong>Object：</strong> 在 RADOS（Reliable Autonomic Distributed Object Store）中，”对象” 是指系统中存储的基本单位。与 File 的不同之处在于，Object 的最大尺寸受到 RADOS 的限制，通常为 2MB 或 4MB。这一限制是为了优化底层存储的管理和组织。因此，当上层应用向 RADOS 存储一个较大的 File 时，需要将其拆分成多个统一大小的 Object（最后一个 Object 的大小可能不同）进行存储。</li><li><strong>PG（Placement Group）：</strong> 顾名思义，PG 用于组织对象的存储并映射其位置。具体来说，一个 PG 负责管理多个对象，而每个对象只能映射到一个 PG 中，即 PG 和对象之间是“一对多”的映射关系。同时，一个 PG 会被映射到多个 OSD（Object Storage Device）上，通常 n 至少为 2，而在生产环境中，n 通常至少为 3。每个 OSD 上会承载大量的 PG，可能达到数百个。PG 的数量设置直接影响数据的分布均匀性，因此在实际配置中需要谨慎考虑。</li><li><strong>OSD（Object Storage Device）：</strong> OSD 是 Ceph 中用于存储数据的对象存储设备。OSD 的数量对系统的数据分布均匀性有直接影响，因此不宜过少。为了充分发挥 Ceph 系统的优势，通常需要配置至少数百个 OSD。</li></ul><ol><li><p><strong>File → Object映射</strong><br> 这个映射过程的目的是将用户操作的 File 转换为 RADOS 能够处理的 Object。这个过程相对简单，本质上就是按照 Object 的最大尺寸对 File 进行切分，类似于磁盘阵列中的条带化（striping）过程。这种切分有两个主要好处：</p><ul><li>将大小不定的 File 转换为具有一致最大尺寸的 Object，使得 RADOS 能够更高效地管理这些数据。</li><li>将对单一 File 的串行处理转变为对多个 Object 的并行处理，从而提高处理效率。</li></ul><p> 每一个切分后的 Object 将获得一个唯一的 Object ID (oid)，其生成方式非常简单，是一种线性映射。具体来说，<code>ino</code> 表示待操作 File 的元数据，可以简单理解为该 File 的唯一 ID；<code>ono</code> 则是由该 File 切分产生的某个 Object 的序号。而 <code>oid</code> 就是将这个序号简单地附加在该 File 的 ID 之后得到的。举个例子，如果一个 ID 为 <code>filename</code> 的 File 被切分成了 3 个 Object，那么其 Object 的序号依次为 0、1 和 2，最终得到的 oid 就依次为 <code>filename0</code>、<code>filename1</code> 和 <code>filename2</code>。</p><p> 这里有一个隐含的问题，即 <code>ino</code> 的唯一性必须得到保证，否则后续的映射将无法正确进行。</p></li><li><p><strong>Object → PG 映射</strong><br> 当一个 File 被映射为一个或多个 Object 后，需要将每个 Object 独立地映射到一个 PG 中。这个过程相对简单，具体计算过程如下：</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hash(oid) &amp; mask -&gt; pgid</span><br></pre></td></tr></table></figure><p> 这个计算过程分为两步：</p><ol><li>使用 Ceph 系统指定的静态哈希算法计算 oid 的哈希值，将 oid 转换为一个近似均匀分布的伪随机值。</li><li>将这个伪随机值与 mask 进行按位与操作，得到最终的 PG 序号 (pgid)。</li></ol><p> 根据 RADOS 的设计，PG 的总数为 m（m 应该为 2 的整数幂），则 mask 的值为 m - 1。哈希值计算和按位与操作的结果就是从所有 m 个 PG 中近似均匀地随机选择一个。这种机制保证了在大量 Object 和大量 PG 存在的情况下，Object 和 PG 之间的映射近似均匀。由于 Object 是由 File 切分而来，大部分 Object 的尺寸相同，因此这一映射最终保证了各个 PG 中存储的 Object 的总数据量的近似均匀性。</p><p> 这里强调“大量”是因为，只有在 Object 和 PG 数量较多时，这种伪随机关系的近似均匀性才有效，Ceph 的数据存储均匀性才能得到保障。为了确保这一点，一方面，Object 的最大尺寸应该被合理配置，以使得相同数量的 File 能被切分成更多的 Object；另一方面，Ceph 建议 PG 的总数应为 OSD 总数的数百倍，以确保有足够数量的 PG 供映射使用。</p></li><li><p><strong>PG → OSD 映射</strong><br> 第三次映射是将作为对象逻辑组织单元的 PG 映射到实际存储单元 OSD 上。RADOS 使用了一种称为 CRUSH（Controlled Replication Under Scalable Hashing）的算法，将 <code>pgid</code> 代入其中，然后得到一组包含 n 个 OSD。这 n 个 OSD 共同负责存储和维护一个 PG 中的所有对象。通常，n 的值根据实际应用中的可靠性需求而定，在生产环境下通常为 3。具体到每个 OSD，由其上运行的 OSD Daemon 负责执行映射到本地的对象在本地文件系统中的存储、访问、元数据维护等操作。</p><p> 与对象到 PG 的映射中采用的哈希算法不同，CRUSH 算法的结果并非绝对不变，而会受到其他因素的影响，主要有两个：</p><ol><li><p><strong>当前系统状态</strong>：即集群运行图。当系统中的 OSD 状态或数量发生变化时，集群运行图可能会改变，这将影响 PG 与 OSD 之间的映射关系。</p></li><li><p><strong>存储策略配置</strong>：这与数据的安全性相关。系统管理员可以通过策略配置指定承载同一个 PG 的 3 个 OSD 分别位于数据中心的不同服务器或机架上，从而提高存储的可靠性。</p></li></ol><p> 因此，只有在系统状态和存储策略都不发生变化时，PG 和 OSD 之间的映射关系才是固定的。在实际使用中，策略配置通常一经设定就不会改变。而系统状态的变化可能是由于设备损坏或存储集群规模的扩大。好在 Ceph 提供了对这些变化的自动化支持，因此，即便 PG 与 OSD 之间的映射关系发生变化，也不会对应用产生影响。实际上，Ceph 利用 CRUSH 算法的动态特性，可以根据需要将一个 PG 动态迁移到不同的 OSD 组合上，从而自动实现高可靠性和数据分布再平衡等特性。</p><p> 选择 CRUSH 算法而非其他哈希算法的原因有两点：</p><ol><li><strong>可配置性</strong>：CRUSH 算法具有可配置特性，可以根据管理员的配置参数决定 OSD 的物理位置映射策略。</li><li><strong>稳定性</strong>：CRUSH 算法具有特殊的“稳定性”，即当系统中加入新的 OSD 导致系统规模增大时，大部分 PG 与 OSD 之间的映射关系不会改变，只有少部分 PG 的映射关系会发生变化并引发数据迁移。这种特性使得系统在扩展时能够保持相对稳定，避免了普通哈希算法可能带来的大规模数据迁移问题。</li></ol></li></ol><p>至此为止，Ceph通过3次映射，完成了从File到Object、Object到PG、PG再到OSD的整个映射过程。从整个过程可以看到，这里没有任何的全局性查表操作需求。至于唯一的全局性数据结构：集群运行图。它的维护和操作都是轻量级的，不会对系统的可扩展性、性能等因素造成影响。</p><p><strong>接下来的一个问题是:为什么需要引人PG并在Object与OSD之间增加一层映射呢？</strong><br>可以想象一下，如果没有 PG 这一层的映射，会是什么情况？在这种情况下，需要采用某种算法将 Object 直接映射到一组 OSD 上。如果这种算法是某种固定映射的哈希算法，这就意味着一个 Object 将被固定映射在一组 OSD 上。当其中一个或多个 OSD 损坏时，Object 无法自动迁移到其他 OSD 上（因为映射函数不允许），而当系统为了扩容新增 OSD 时，Object 也无法被再平衡到新的 OSD 上（同样因为映射函数不允许）。这些限制违背了 Ceph 系统高可靠性和高自动化的设计初衷。</p><p>即便使用一个动态算法（如 CRUSH 算法）来完成这一映射，似乎可以避免静态映射带来的问题。但这样会导致各个 OSD 处理的本地元数据量大幅增加，计算复杂度和维护工作量也会大幅上升。</p><p>例如，在 Ceph 的现有机制中，一个 OSD 通常需要与其他承载同一个 PG 的 OSD 交换信息，以确定各自是否工作正常或是否需要进行维护。由于每个 OSD 承载约数百个 PG，而每个 PG 通常有 3 个 OSD，因此，在一定时间内，一个 OSD 大约需要进行数百次至数千次的信息交换。</p><p>然而，如果没有 PG 存在，一个 OSD 需要与其他承载同一个 Object 的 OSD 交换信息。由于每个 OSD 可能承载高达数百万个 Object，在同样时间内，一个 OSD 大约需要进行数百万次甚至数千万次的信息交换。这种状态维护成本显然过高。</p><p>综上所述，引入 PG 有至少两方面的好处：一方面，实现了 Object 和 OSD 之间的动态映射，为 Ceph 的可靠性和自动化等特性的实现提供了可能；另一方面，有效简化了数据的存储组织，大大降低了系统的维护和管理成本。</p><h2 id="Ceph数据读写过程"><a href="#Ceph数据读写过程" class="headerlink" title="Ceph数据读写过程"></a>Ceph数据读写过程</h2><p>Ceph的读&#x2F;写操作采用<strong>Primary-Replica</strong>模型，客户端只向Object所对应OSD set的Primary OSD发起读&#x2F;写请求，这保证了数据的强一致性。当Primary OSD收到Object的写请求时，它负责把数据发送给其他副本，只有这个数据被保存在所有的OSD上时，Primary OSD才应答Object的写请求，这保证了副本的一致性。</p><p><strong>写入数据</strong><br>这里以Object写入为例，假定一个PG被映射到3个OSD上。Object写入流程如图所示。<br> <img src="/images/Ceph%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B.jpg"></p><p>当某个客户端需要向Ceph集群写入一个File时，首先需要在本地完成前面所述的<a href="https://blog.csdn.net/lhc121386/article/details/113428189">寻址流程</a>，将File变为一个Object，然后找出存储该Object的一组共3个OSD，这3个OSD具有各自不同的序号，序号最靠前的那个OSD就是这一组中的Primary OSD，而后两个则依次Secondary OSD和Tertiary OSD。<br>找出3个OSD后，客户端将直接和Primary OSD进行通信，发起写入操作(<strong>步骤1</strong>)。 Primary OSD收到请求后，分别向Secondary OSD和Tertiary OSD发起写人操作(<strong>步骤2</strong>和<strong>步骤3</strong>)。当Secondary OSD和Tertiary OSD各自完成写入操作后，将分别向Primary OSD发送确认信息(<strong>步骤4</strong>和<strong>步骤5</strong>)。当Primary OSD确认其他两个OSD的写入完成后，则自己也完成数据写入，并向客户端确认Object写入操作完成(<strong>步骤6</strong>)。<br>之所以采用这样的写入流程，本质上是为了保证写入过程中的可靠性，尽可能避免出现数据丢失的情况。同时，由于客户端只需要向Primary OSD发送数据，因此在互联网使用场景下的外网带宽和整体访问延迟又得到了一定程度的优化。<br>当然，这种可靠性机制必然导致较长的延迟，特别是，如果等到所有的OSD都将数据写入磁盘后再向客户端发送确认信号，则整体延迟可能难以忍受。因此， <strong>Ceph可以分两次向客户端进行确认。当各个OSD都将数据写入内存缓冲区后，就先向客户端发送一次确认，此时客户端即可以向下执行。待各个OSD都将数据写入磁盘后，会向客户端发送一个最终确认信号，此时客户端可以根据需要删除本地数据。</strong><br>分析上述流程可以看出，在正常情况下，客户端可以独立完成OSD寻址操作，而不必依赖于其他系统模块。因此，大量的客户端可以同时和大量的OSD进行并行操作。同时，如果一个File被切分成多个Object，这多个Object也可被并行发送至多个OSD上。<br>从OSD的角度来看，由于同一个OSD在不同的PG中的角色不同，因此，其工作压力也可以被尽可能均匀地分担，从而避免单个OSD变成性能瓶颈。</p><p><strong>读取数据</strong><br>如果需要读取数据，客户端只需完成同样的<a href="https://blog.csdn.net/lhc121386/article/details/113428189">寻址过程</a>，并直接和Primary OSD联系。<strong>在目前的Ceph设计中，被读取的数据默认由Primary OSD提供</strong>，但也可以设置允许从其他OSD中获取，以分散读取压力从而提高性能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ceph数据映射过程&quot;&gt;&lt;a href=&quot;#Ceph数据映射过程&quot; class=&quot;headerlink&quot; title=&quot;Ceph数据映射过程&quot;&gt;&lt;/a&gt;Ceph数据映射过程&lt;/h2&gt;&lt;p&gt;在一个大规模分布式存储系统中，需要解决两个核心问题：“我应该把数据写到哪里？</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>Ceph体系架构</title>
    <link href="https://watsonlu6.github.io/Ceph%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    <id>https://watsonlu6.github.io/Ceph%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/</id>
    <published>2021-05-07T02:19:42.000Z</published>
    <updated>2024-07-27T14:30:54.244Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Ceph 官方定义</strong><br>Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.(Ceph 是一种为优秀的性能、可靠性和可扩展性而设计的统一的、分布式的存储系统。)</p><p><strong>Ceph 设计思路</strong></p><ul><li><strong>充分发挥存储设备自身的计算能力。</strong> 采用具有计算能力的设备作为存储系统的存储节点。</li><li><strong>去除所有的中心点。</strong> 解决单点故障点和当系统规模扩大时出现的规模和性能瓶颈问题。</li></ul><p> <strong>Ceph的设计哲学</strong></p><ul><li>每个组件必须可扩展  </li><li>不存在单点故障</li><li>解决方案必须是基于软件的</li><li>可摆脱专属硬件的束缚即可运行在常规硬件上 </li><li>推崇自我管理</li></ul><p><strong>Ceph体系结构</strong><br>首先作为一个存储系统，Ceph在物理上必然包含一个存储集群，以及这个存储集群的应用或客户端。Ceph客户端又需要一定的协议与Ceph存储集群进行交互，Ceph的逻辑层次演化如图所示。<br><img src="/images/Ceph%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.jpg"><br><strong>OSD</strong>：主要功能包括存储数据，处理数据的复制、恢复、回补、平衡数据分布，并将一些相关数据提供给Ceph Monitor。一个Ceph的存储集群，至少需要两个Ceph OSD来实现active+clean健康状态和有效的保存数据的双副本。一旦应用程序向ceph集群发出写操作，数据就以对象的形式存储在OSD中，OSD是Ceph集群中存储实际用户数据的唯一组件。通常，一个OSD守护进程绑定到集群中的一个物理磁盘。因此，通常来说，Ceph集群中物理磁盘的总数与在每个物理磁盘上存储用户数据的OSD守护进程的总数相同。</p><p><strong>MON</strong>：Ceph的监控器，主要功能是维护整个集群健康状态，提供一致性的决策。</p><p><strong>MDS</strong>：主要保存的是Ceph文件系统的元数据。（Ceph的块存储和对象存储都不需要Ceph MDS）</p><p><strong>RADOS</strong>：Ceph基于可靠的、自动化的、分布式的对象存储(<strong>R</strong>eliabl,<strong>A</strong>utonomous,<strong>D</strong>istributed <strong>O</strong>bject <strong>S</strong>torage, <strong>RADOS</strong> )提供了一个可无限扩展的存储集群，RADOS是Ceph最为关键的技术，它是一个支持海量存储对象的分布式对象存储系统。RADOS层本身就是一个完整的对象存储系统，事实上，所有存储在Ceph系统中的用户数据最终都是由这一层来存储。RADOS层确保数据始终保持一致，他执行数据复制、故障检测和恢复，以及跨集群节点的数据迁移和再平衡。 RADOS集群主要由两种节点组成：<em><strong>为数众多的OSD</strong></em>，负责完成数据存储和维护；<em><strong>若干个Monitor</strong></em>，负责完成系统状态检测和维护。OSD和Monion之间互相传递节点的状态信息，共同得出系统的总体运行状态，并保存在一个全局数据结构中，即所谓的集群运行图(Cluster Map )里。集群运行图与RADOS提供的特定算法相配合，便实现了Ceph的许多优秀特性。</p><p><strong>Librados</strong>：Librados库实际上是对RADOS进行抽象和封装，并向上层提供API，支持PHP、Ruby、Java、Python、C和C++编程语言。它为Ceph存储集群（RADOS）提供了本机接口，并为其他服务提供基础，如RBD、RGW和CephFS，这些服务构建在Librados之上，Librados还支持从应用程序直接访问RADOS，没有HTTP开销。</p><p><strong>RBD</strong>：RBD提供了一个标准的块设备接口，常用于在虚拟化的场景下为虚拟机创建存储卷，Red Hat已经将RBD驱动集成在QEMU&#x2F;KVM中，以提高虚拟机的访问性能。</p><p><strong>RADOS GW</strong>：Ceph对象网关RADOS GW提供对象存储服务，是一个构建在Librados库之上的对象存储接口，为应用访问Ceph集群提供了一个与Amazon S3和OpenStack Swift兼容的RESTful风格的 网关。</p><p><strong>Ceph FS</strong>：Ceph文件系统提供了一个符合posix标准的文件系统，它使用Ceph存储集群在文件系统上存储用户数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Ceph 官方定义&lt;/strong&gt;&lt;br&gt;Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalabili</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>ansible搭建Ceph集群</title>
    <link href="https://watsonlu6.github.io/Ceph%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://watsonlu6.github.io/Ceph%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2021-05-05T14:08:55.000Z</published>
    <updated>2024-07-29T14:45:54.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>共计20台服务器，单台前置热插拔硬盘位10T * 10（业务盘）+2T * 2（系统盘）或10T * 10（业务盘）+4T * 2（系统盘），其中两块系统盘配置为RAID 1，安装CentOS 7系统，分布如下图。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B21.png"></p><p>Ceph01 - Ceph20依次对应IP地址：172.25.7.201 - 172.25.7.220<br>其中，Ceph01、Ceph02、Ceph03、Ceph11、Ceph12为Monitor节点，其余为OSD节点。业务盘不配置RAID，每块业务盘作为一个OSD，资源池数据使用单副本。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B22.png"></p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h4 id="hosts配置-（所有节点执行）"><a href="#hosts配置-（所有节点执行）" class="headerlink" title="hosts配置 （所有节点执行）"></a>hosts配置 （所有节点执行）</h4><p>hostnamectl –static set-hostname 节点对应主机名<br>echo -e “127.0.0.1\tlocalhost localhost.localdomain localhost4 localhost4.localdomain4<br>::1\tlocalhost localhost.localdomain localhost6 localhost6.localdomain6<br>172.25.7.201\tceph-node1-mon1<br>172.25.7.202\tceph-node2-mon2<br>172.25.7.203\tceph-node3-mon3<br>172.25.7.204\tceph-node4<br>172.25.7.205\tceph-node5<br>172.25.7.206\tceph-node6<br>172.25.7.207\tceph-node7<br>172.25.7.208\tceph-node8<br>172.25.7.209\tceph-node9<br>172.25.7.210\tceph-node10<br>172.25.7.211\tceph-node11-mon4<br>172.25.7.212\tceph-node12-mon5<br>172.25.7.213\tceph-node13<br>172.25.7.214\tceph-node14<br>172.25.7.215\tceph-node15<br>172.25.7.216\tceph-node16<br>172.25.7.217\tceph-node17<br>172.25.7.218\tceph-node18<br>172.25.7.219\tceph-node19<br>172.25.7.220\tceph-node20” &gt; &#x2F;etc&#x2F;hosts</p><h4 id="配置SSH免密登陆（在ceph-ansible节点上执行）"><a href="#配置SSH免密登陆（在ceph-ansible节点上执行）" class="headerlink" title="配置SSH免密登陆（在ceph-ansible节点上执行）"></a>配置SSH免密登陆（在ceph-ansible节点上执行）</h4><p>ssh-keygen -t rsa<br>ssh-copy-id root@ceph-node1-mon1<br>ssh-copy-id root@ceph-node2-mon2<br>ssh-copy-id root@ceph-node3-mon3<br>ssh-copy-id root@ceph-node4<br>ssh-copy-id root@ceph-node5<br>ssh-copy-id root@ceph-node6<br>ssh-copy-id root@ceph-node7<br>ssh-copy-id root@ceph-node8<br>ssh-copy-id root@ceph-node9<br>ssh-copy-id root@ceph-node10<br>ssh-copy-id root@ceph-node11-mon4<br>ssh-copy-id root@ceph-node12-mon5<br>ssh-copy-id root@ceph-node13<br>ssh-copy-id root@ceph-node14<br>ssh-copy-id root@ceph-node15<br>ssh-copy-id root@ceph-node16<br>ssh-copy-id root@ceph-node17<br>ssh-copy-id root@ceph-node18<br>ssh-copy-id root@ceph-node19<br>ssh-copy-id root@ceph-node20<br>验证各节点ssh是否能免密登陆</p><h4 id="关闭SELINUX和防火墙（所有节点执行）"><a href="#关闭SELINUX和防火墙（所有节点执行）" class="headerlink" title="关闭SELINUX和防火墙（所有节点执行）"></a>关闭SELINUX和防火墙（所有节点执行）</h4><p>sed -i “s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;g” &#x2F;etc&#x2F;selinux&#x2F;config<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld<br>reboot</p><h4 id="配置时间同步"><a href="#配置时间同步" class="headerlink" title="配置时间同步"></a>配置时间同步</h4><p><strong>所有节点执行</strong><br>yum -y install ntp ntpdate<br>cd &#x2F;etc &amp;&amp; mv ntp.conf ntp.conf.bak</p><p><strong>在ceph-ansible节点执行</strong><br>编辑ntpd配置文件<br>vi &#x2F;etc&#x2F;ntp.conf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line">restrict 172.25.7.0 mask 255.255.255.0</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 8</span><br></pre></td></tr></table></figure><p>启动ntpd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start ntpd</span><br><span class="line">systemctl enable ntpd</span><br></pre></td></tr></table></figure><p><strong>其余节点执行</strong><br>编辑ntp服务<br>vi &#x2F;etc&#x2F;ntp.conf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server 172.25.7.201</span><br></pre></td></tr></table></figure><p>启动ntp，同步时间</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ceph-node1-mon1</span><br><span class="line">hwclock -w</span><br><span class="line"></span><br><span class="line">crontab -e</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">键入</span></span><br><span class="line">*/10 * * * * /usr/sbin/ntpdate 172.25.7.201</span><br></pre></td></tr></table></figure><h4 id="配置Ceph源-所有节点"><a href="#配置Ceph源-所有节点" class="headerlink" title="配置Ceph源(所有节点)"></a>配置Ceph源(所有节点)</h4><p>编辑ceph源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/yum.repos.d/ceph.repo</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">键入</span></span><br><span class="line">[Ceph]</span><br><span class="line">name=Ceph packages for $basearch</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/$basearch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[Ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph source packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-nautilus/el7/SRPMS</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">priority=1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>更新ceph源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install epel-release</span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br></pre></td></tr></table></figure><h2 id="Ceph-ansible配置（仅在ceph-ansible节点安装）"><a href="#Ceph-ansible配置（仅在ceph-ansible节点安装）" class="headerlink" title="Ceph-ansible配置（仅在ceph-ansible节点安装）"></a>Ceph-ansible配置（仅在ceph-ansible节点安装）</h2><h4 id="安装ansible"><a href="#安装ansible" class="headerlink" title="安装ansible"></a>安装ansible</h4><p>安装ansible，并修改&#x2F;etc&#x2F;ansible&#x2F;hosts<br><code>yum -y install ansible</code><br>注意对应的版本号<br>参考官网文档：<a href="https://docs.ceph.com/projects/ceph-ansible/en/latest/">https://docs.ceph.com/projects/ceph-ansible/en/latest/</a><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B23.png"></p><p>检测是否成功安装ansible<br><code>ansible --version</code><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B24.png"></p><p>修改&#x2F;etc&#x2F;ansible&#x2F;hosts</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/ansible/hosts</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加以下内容</span></span><br><span class="line">[mons]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[mgrs]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[osds]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node4</span><br><span class="line">ceph-node5</span><br><span class="line">ceph-node6</span><br><span class="line">ceph-node7</span><br><span class="line">ceph-node8</span><br><span class="line">ceph-node9</span><br><span class="line">ceph-node10</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line">ceph-node13</span><br><span class="line">ceph-node14</span><br><span class="line">ceph-node15</span><br><span class="line">ceph-node16</span><br><span class="line">ceph-node17</span><br><span class="line">ceph-node18</span><br><span class="line">ceph-node19</span><br><span class="line">ceph-node20</span><br><span class="line"></span><br><span class="line">[grafana-server]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br></pre></td></tr></table></figure><p>测试ansible是否能正常运行：<code>ansible all -m ping</code><br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B25.png"></p><h4 id="安装ceph-absible"><a href="#安装ceph-absible" class="headerlink" title="安装ceph-absible"></a>安装ceph-absible</h4><p>确保环境上安装了git，可通过一下方式安装<br>    <code>yum -y install git</code></p><p>配置“http.sslVerify”参数为“false”，跳过系统证书。<br>    <code>git config --global http.sslVerify false</code></p><p>下载Ceph-ansible，注意ceph N版的版本号是stable-4.0<br>    <code>git clone -b stable-4.0 https://github.com/ceph/ceph-ansible.git --recursive</code></p><p>安装 Ceph-ansible 依赖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y python-pip           #安装python-pip</span><br><span class="line">pip install --upgrade pip           # 将pip更新到最新版本</span><br><span class="line">cd /root/ceph-ansible/              #进入ceph-ansible目录</span><br><span class="line">pip install -r requirements.txt     #检查并安装需要的软件版本</span><br></pre></td></tr></table></figure><p>在ceph-ansible目录内新建hosts文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">vi /root/ceph-ansible/hosts</span><br><span class="line"></span><br><span class="line">[mons]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[mgrs]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line"></span><br><span class="line">[osds]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node4</span><br><span class="line">ceph-node5</span><br><span class="line">ceph-node6</span><br><span class="line">ceph-node7</span><br><span class="line">ceph-node8</span><br><span class="line">ceph-node9</span><br><span class="line">ceph-node10</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br><span class="line">ceph-node13</span><br><span class="line">ceph-node14</span><br><span class="line">ceph-node15</span><br><span class="line">ceph-node16</span><br><span class="line">ceph-node17</span><br><span class="line">ceph-node18</span><br><span class="line">ceph-node19</span><br><span class="line">ceph-node20</span><br><span class="line"></span><br><span class="line">[grafana-server]</span><br><span class="line">ceph-node1-mon1</span><br><span class="line">ceph-node2-mon2</span><br><span class="line">ceph-node3-mon3</span><br><span class="line">ceph-node11-mon4</span><br><span class="line">ceph-node12-mon5</span><br></pre></td></tr></table></figure><p>使用Ceph-ansible提供的ansible变量用来设置ceph集群的配置。<br>所有选项及默认配置放在group_vars目录下，每种ceph进程对应相关的配置文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp mons.yml.sample mons.yml</span><br><span class="line">cp mgrs.yml.sample mgrs.yml</span><br><span class="line">cp mdss.yml.sample mdss.yml</span><br><span class="line">cp rgws.yml.sample rgws.yml</span><br><span class="line">cp osds.yml.sample osds.yml</span><br><span class="line">cp clients.yml.sample clients.yml</span><br><span class="line">cp all.yml.sample all.yml</span><br></pre></td></tr></table></figure><p>修改group_vars&#x2F;all.yml文件（注意网络接口）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">vi group_vars/all.yml</span><br><span class="line"></span><br><span class="line">ceph_origin: repository</span><br><span class="line">ceph_repository: community</span><br><span class="line">ceph_mirror: http://download.ceph.com</span><br><span class="line">ceph_stable_release: nautilus</span><br><span class="line">ceph_stable_repo: &quot;&#123;&#123; ceph_mirror &#125;&#125;/rpm-&#123;&#123; ceph_stable_release &#125;&#125;&quot;</span><br><span class="line">ceph_stable_redhat_distro: el7</span><br><span class="line">journal_size: 5120</span><br><span class="line">monitor_interface: p1p1</span><br><span class="line">public_network: &quot;172.25.7.0/24&quot;</span><br><span class="line">cluster_network: &quot;172.25.7.0/24&quot;</span><br><span class="line">mon_host: 172.25.7.201, 172.25.7.202, 172.25.7.203, 172.25.7.211, 172.25.7.212</span><br><span class="line">osd_objectstore: bluestore</span><br><span class="line"></span><br><span class="line">dashboard_enabled: True</span><br><span class="line">dashboard_protocol: http</span><br><span class="line">dashboard_port: 8443</span><br><span class="line">dashboard_admin_user: admin</span><br><span class="line">dashboard_admin_password: admin</span><br><span class="line">grafana_admin_user: admin</span><br><span class="line">grafana_admin_password: admin</span><br><span class="line">grafana_uid: 472</span><br><span class="line">grafana_datasource: Dashboard</span><br><span class="line">grafana_dashboard_version: nautilus</span><br><span class="line">grafana_port: 3000</span><br><span class="line">grafana_allow_embedding: True</span><br><span class="line">grafana_crt: &#x27;&#x27;</span><br><span class="line">grafana_key: &#x27;&#x27;</span><br><span class="line">grafana_container_image: &quot;grafana/grafana:5.2.4&quot;</span><br><span class="line">grafana_container_cpu_period: 100000</span><br><span class="line">grafana_container_cpu_cores: 2</span><br><span class="line">grafana_container_memory: 4</span><br><span class="line">grafana_dashboards_path: &quot;/etc/grafana/dashboards/ceph-dashboard&quot;</span><br><span class="line">grafana_dashboard_files:</span><br><span class="line">  - ceph-cluster.json</span><br><span class="line">  - cephfs-overview.json</span><br><span class="line">  - host-details.json</span><br><span class="line">  - hosts-overview.json</span><br><span class="line">  - osd-device-details.json</span><br><span class="line">  - osds-overview.json</span><br><span class="line">  - pool-detail.json</span><br><span class="line">  - pool-overview.json</span><br><span class="line">  - radosgw-detail.json</span><br><span class="line">  - radosgw-overview.json</span><br><span class="line">  - rbd-overview.json</span><br><span class="line">grafana_plugins:</span><br><span class="line">  - vonage-status-panel</span><br><span class="line">  - grafana-piechart-panel</span><br><span class="line">prometheus_container_image: &quot;prom/prometheus:v2.7.2&quot;</span><br><span class="line">prometheus_container_cpu_period: 100000</span><br><span class="line">prometheus_container_cpu_cores: 2</span><br><span class="line">prometheus_container_memory: 4</span><br><span class="line">prometheus_data_dir: /var/lib/prometheus</span><br><span class="line">prometheus_conf_dir: /etc/prometheus</span><br><span class="line">prometheus_user_id: &#x27;65534&#x27;  </span><br><span class="line">prometheus_port: 9092</span><br><span class="line"></span><br><span class="line">ceph_conf_overrides:</span><br><span class="line"> global:</span><br><span class="line">osd_pool_default_pg_num: 64</span><br><span class="line">  osd_pool_default_pgp_num: 64</span><br><span class="line">  osd_pool_default_size: 2</span><br><span class="line"> mon:</span><br><span class="line">  mon_allow_pool_create: true</span><br></pre></td></tr></table></figure><p>修改group_vars&#x2F;osds.yml文件<br>在osds.yml添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vi group_vars/osds.yml</span><br><span class="line"></span><br><span class="line">devices:</span><br><span class="line">  - /dev/sda</span><br><span class="line">  - /dev/sdb</span><br><span class="line">  - /dev/sdc</span><br><span class="line">  - /dev/sdd</span><br><span class="line">  - /dev/sde</span><br><span class="line">  - /dev/sdf</span><br><span class="line">  - /dev/sdg</span><br><span class="line">  - /dev/sdh</span><br><span class="line">  - /dev/sdi</span><br><span class="line">  - /dev/sdj</span><br></pre></td></tr></table></figure><p>修改site.yml文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp site.yml.sample site.yml</span><br><span class="line">vi site.yml</span><br></pre></td></tr></table></figure><p><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B26.png"></p><h2 id="Ceph-集群部署"><a href="#Ceph-集群部署" class="headerlink" title="Ceph 集群部署"></a>Ceph 集群部署</h2><p>执行命令：ansible-playbook -i hosts site.yml<br>执行结束，在执行页面会有相关的提示，如图所示，所有节点显示failed&#x3D;0，则处于部署过程中。<br><img src="/images/Ceph%E9%83%A8%E7%BD%B2/Ceph%E9%83%A8%E7%BD%B27.png"></p><p>如果是过程出错，先清空集群，在进行部署</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp infrastructure-playbooks/purge-cluster.yml purge-cluster.yml # 必须copy到项目根目录下</span><br><span class="line">ansible-playbook -i hosts purge-cluster.yml</span><br></pre></td></tr></table></figure><h2 id="Rados性能测试工具"><a href="#Rados性能测试工具" class="headerlink" title="Rados性能测试工具"></a>Rados性能测试工具</h2><p>创建pool<br>    <code>ceph osd pool create testbench 100 100</code><br>清除缓存<br>    <code>echo 3 &gt; /proc/sys/vm/drop_caches</code></p><p>4M写入测试<br>    <code>rados bench -p testbench 180 write -t 32 --no-cleanup</code></p><p>4k写入测试<br>    <code>rados bench -p testbench 180 write -t 32 -b 4096 --no-cleanup</code></p><p>4K顺序读<br>    <code>rados bench -p testbench 180 seq -t 32 --no-cleanup</code></p><p>4K随机读<br>    <code>rados bench -p testbench 180 rand -t 32  --no-cleanup</code></p><p>清除数据<br>    <code>rados -p testbench cleanup</code></p><p>参数说明<br>格式：rados bench -p <pool-name> <seconds> <mode> -b <block size> -t –no-cleanup</p><ul><li>pool-name：测试存储池名称</li><li>seconds：测试时间，单位秒</li><li>mode：操作模式，write：写，seq：顺序读；rand：随机读</li><li>-b：block size，块大小，默认为 4M,单位字节，只有在写的时候有效。</li><li>-t：读&#x2F;写并行数，默认为 16</li><li>–no-cleanup 表示测试完成后不删除测试用数据。<br>注意：在测试之前要执行一次命令加–no-cleanup产生数据</li></ul><h2 id="部署过程的问题"><a href="#部署过程的问题" class="headerlink" title="部署过程的问题"></a>部署过程的问题</h2><ol><li>   执行完ansible-playbook -i hosts site.yml 命令后，前面无报错但某些节点不正常<br>解决方法：属于正常现象，再执行ansible-playbook -i hosts site.yml命令可显示正常状态。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;p&gt;共计20台服务器，单台前置热插拔硬盘位10T * 10（业务盘）+2T * 2（系统盘）或10T * 10（业务盘）+4T </summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/Ceph/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="Ceph" scheme="https://watsonlu6.github.io/tags/Ceph/"/>
    
  </entry>
  
  <entry>
    <title>块存储_文件系统存储_对象存储的区别</title>
    <link href="https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2021-04-23T08:29:15.000Z</published>
    <updated>2024-07-27T14:30:41.200Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB.png"></p><h2 id="定义角度"><a href="#定义角度" class="headerlink" title="定义角度"></a>定义角度</h2><ul><li><strong>块存储</strong><br>指以扇区为基础，一个或者连续的扇区组成一个块，也叫物理块。它是在文件系统与块设备(例如：磁盘驱动器)之间。利用多个物理硬盘的并发能力。关注的是写入偏移位置。 </li><li><strong>文件系统存储</strong><br>文件系统存储也称为文件级存储或基于文件的存储，数据会以单条信息的形式存储在文件夹中。当需要访问该数据时，计算机需要知道相应的查找路径，存储在文件中的数据会根据数量有限的元数据来进行整理和检索，这些元数据会告诉计算机文件所在的确切位置。它就像是数据文件的库卡目录。</li><li><strong>对象存储</strong><br>对象存储，也称为基于对象的存储，是一种扁平结构，其中的文件被拆分成多个部分并散布在多个硬件间。在对象存储中，数据会被分解为称为“对象”的离散单元，并保存在单个存储库中，而不是作为文件夹中的文件或服务器上的块来保存。</li></ul><h2 id="使用角度"><a href="#使用角度" class="headerlink" title="使用角度"></a>使用角度</h2><ul><li><strong>块存储</strong><br>生活中常见的块存储设备（也叫“块设备”）比如，插在你本地电脑上的U盘、硬盘，你电脑连接的iSCSI等。<br>从使用上来说，块级的存储如果是第一次使用，那么必须需要进行一次格式化的操作，创建出一个文件系统，然后才可以使用。例如新买的U盘、硬盘、或者新发现的iSCSI设备等，首次使用的时候都需要进行一次格式化操作，创建出一个文件系统，然后才可以将你的文件拷贝到U盘、硬盘、或者新发现的iSCSI设备中。</li><li><strong>文件系统存储</strong><br>文件系统存储是最常见的一种文件内系统，我们日常对操作系使用中，基本上能够直接接触到的都就是这种，能够直接访问的C、D、E盘，电脑里的一个目录，网上邻居的空间都是文件级的存储。块级的存储设备经过格式化以及挂载（win 会自动挂载）之后，你就将一个块级的存储变成了文件级的存储。</li><li><strong>对象存储</strong><br>对象存储一般来说并不是给我们人直接去使用的，从使用者角度来说，它更适合用用于给程序使用。平时最常见的一般就是百度网盘，其后端对接的就是对象存储。还有就网页上的图片、视频，其本身也是存储在对象存储的文件系统中的。如果要直接使用对象级的存储，你会发现对象级的存储本身是非常的简单的（但是对人来说不方便），它只有简单的几种命令如上传、下载、删除，并且你只需要知道某个文件的编号（如：”d5t35e6tdud725dgs6u2hdsh27dh27d7”  这不是名字）就可以直接对它进行上传、下载、删除等操作，不需要像文件级那样，直到文件的具体的路径（如:D:\photo\1.jpg），并且他也只有这几种操作，如果你想编辑文件，那只能将文件下载下来编辑好之后在进行上传（这也是它对人来说不方便的原因之一）</li></ul><h2 id="技术角度"><a href="#技术角度" class="headerlink" title="技术角度"></a>技术角度</h2><p>块级、文件级、对象级技术上的区别，首先要明白两个概念<br>第一，无论是那个级别的存储系统，其数据都是会存储在物理的存储设备上的，这些存储设备现在常见的基本上就两种机械硬盘、固态硬盘。<br>第二，任何数据都是由两部”数据“分组成的，一部分是”数据本身”(下文中“数据”指”数据本身“)，另一部分就是这些“数据”的”元数据“。所谓的”元数据”就是用来描述”数据”的”数据”。包括数据所在的位置，文件的长度（大小），文件的访问权限、文件的时间戳（创建时间、修改时间….），元数据本身也是数据。</p><ul><li><strong>块存储</strong><br>对于块级来说，如果要通过块设备来访问一段数据的话，你自己需要知道这些数据具体是存在于那个存储设备上的位置上，例如如果你要从块设备上读取一张照片，你就要高速存储设备：我要从第2块硬盘中的从A位置开始到B位置的数据，硬盘的驱动就会将这个数据给你。读取照片的过程中照片的具体位置就是元数据，也就是说块级的存储中要求程序自己保存元数据。</li><li><strong>文件系统存储</strong><br>如果需要自己保存元数据的话就太麻烦了，上文也说了，元数据本身也是数据，实际上元数据也是存储在硬盘上的，那么如何访问元数据这个数据呢其实，文件级的元数据是存储在固定位置的，存储的位置和方式是大家事先约定好的，这个约定就叫做文件系统，例如EXT4、FAT32、XFS、NTFS等。借助于这些约定，我们就不用自己去维护一个表去记录每一份数据的具体存储位置了。我们只需要直到我们存储的文件的路径和名字就好了，例如我们想要 D:\1.jpg 这个文件，那么你只需要告诉文件系统 D:\1.jpg 这个位置就可以了，去硬盘的哪里找D:\1.jpg 数据的真身，就是文件系统的工作了</li><li><strong>对象存储</strong><br>对象级存储，文件级的元数据实际上是和数据放在一起的，就像一本书每本书都有一个目录，这个目录描述的是这本书上内容的索引，目录就是书内容的“元数据”，而对象存储，会有一本书只放目录（元数据），其他更多的书只有内容，并且内容都是被拆分好的一段一段的，就是说你会看每本书上面的内容完全是混在在一起的，这一页的前两行是书A的某句话，后面就跟的是书D的某句话，如果只放目录（元数据）那本书，你根本不知道这里写的是啥。对象及存储将一切的文件都视作对象，并且将对象按照固定的”形式”组合或拆分的存储在存储设备中，并且将数据的元数据部分完全的独立出来，进行单独的管理。</li></ul><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><ul><li>从<strong>距离（io路径）</strong> 上来说（相对于传统的存储），块存储的使用者距离最底层实际存储数据的存储设备是最近的，对象级是最远的。</li><li>从<strong>使用</strong>上来说，块存储需要使用者自己直到数据的真是位置，需要自己管理记录这些数据，所以使用上是最复杂的，而对象存储的接口最简单，基本上只有上传、下载、删除，并且不需要自己保存元数据，也不需要直到文件的索引路径，所以使用上是最简单的。但是从方便角度来讲还是文件存储最方便。</li><li>从<strong>性能</strong>上来说，综合的来讲（在特定的应用场合）性能最好的是块存储，它主要用在数据库、对延时要求非常高的场景中，对象存储多用于互联网，因为扩展性好，容量可以做的非常的大。对于人类来说，如果不借助特定的客户端、APP，使用文件存储是最友好最简单的。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li><strong>块存储：</strong> 要求高性能的应用，如数据库需要高IO，用块存储比较合适。</li><li><strong>文件系统存储：</strong> 需局域网共享的应用，如文件共享，视频处理，动画渲染&#x2F;高性能计算。</li><li><strong>对象存储：</strong> 互联网领域的存储，如点播&#x2F;视频监控的视频存储、图片存储、网盘存储、静态网页存储等，以及异地备份存储&#x2F;归档等。</li></ul><p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB_1.png"></p><h2 id="为什么块级的存储性能最好"><a href="#为什么块级的存储性能最好" class="headerlink" title="为什么块级的存储性能最好"></a>为什么块级的存储性能最好</h2><p>&emsp;&emsp;首先要明确一点，要明确，每次在发生数据读取访问的时候，实际上对应系统的底层是发生了多次IO的（主要是要对元数据进行访问），例如，你要打开文件1.txt ，操作系统回去进行文件是否存在的查询，以及读写权限的查询等操作，这些操作实际上都是对于元数据的访问。<br>&emsp;&emsp;然后，相对于其它的存储方式，块存储的元数据是有操作系统自己管理的，也就是说整个文件系统（元数据）是存在在操做系统的内存中的，这样操作系统在进行元数据管理的时候可以直和自己的内存打交道。而文件系统存储和对象存储，它的文件系统是存在于另一台服务器上的，这样在进行元数据访问时就需要从网络进行访问，这样要比从内存访问慢得多。<br>&emsp;&emsp;总结来讲，就是块级存储的元数据在系统本机中，在进行元数据访问（每次读写文件实际都会在操作系统底层发生），会更快，因为其它的级别的存储元数据都要通过网络访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>云存储概述</title>
    <link href="https://watsonlu6.github.io/%E4%BA%91%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/"/>
    <id>https://watsonlu6.github.io/%E4%BA%91%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/</id>
    <published>2021-04-18T15:09:26.000Z</published>
    <updated>2024-07-27T14:30:28.553Z</updated>
    
    <content type="html"><![CDATA[<h2 id="云存储概述"><a href="#云存储概述" class="headerlink" title="云存储概述"></a>云存储概述</h2><p><img src="/images/%E4%BA%91%E5%AD%98%E5%82%A8%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF.png"></p><h4 id="云存储的概述"><a href="#云存储的概述" class="headerlink" title="云存储的概述"></a>云存储的概述</h4><p>云存储是指通过网络，将分布在不同地方的多种存储设备，通过应用软件集合起来共同对外提供数据存储和业务访问功能的一个系统。云存储是云计算系统中的一种新型网络存储技术。云存储对外提供的存储能力以统一、简单的数据服务接口来提供和展现。用户不用关心数据具体存放在哪个设备、哪个区域，甚至不知道数据到底是怎么保存的，他们只需要关心需要多少存储空间、什么时间能够拿到数据、数据存放的安全性和可用性如何即可。</p><h4 id="云存储的实现模式"><a href="#云存储的实现模式" class="headerlink" title="云存储的实现模式"></a>云存储的实现模式</h4><p>云存储的实现模式有多种，云存储的架构可以由传统的存储架构延伸而来，也可以采用全新的云计算架构。云存储的实现可以是软件的，也可以是硬件的。云存储的实现模式可以是块存储、文件存储和对象存储。</p><ul><li><p><strong>块存储</strong></p><ul><li>块存储：最接近底层的存储，可以对数据进行任意格式化操作，可以在上面运行数据库等性能要求高的应用。可以给虚拟机使用。</li></ul></li><li><p><strong>文件存储</strong></p><ul><li>文件存储：对数据以文件的形式进行存储，支持复杂的文件操作，适合共享文件和协作工作。典型应用场景：NAS。</li></ul></li><li><p><strong>对象存储</strong></p><ul><li>对象存储：将数据以对象形式存储，通过唯一的对象ID进行访问，适合存储大规模非结构化数据，支持RESTful API接口。典型应用场景：云存储服务，视频、图片存储。</li></ul></li></ul><h4 id="为什么需要多元化存储？"><a href="#为什么需要多元化存储？" class="headerlink" title="为什么需要多元化存储？"></a>为什么需要多元化存储？</h4><p>由于不同的应用场景对存储的需求不同，单一的存储类型无法满足所有需求。大规模存储系统需要支持多种存储类型和多种存储协议，比如NFS、iSCSI、HDFS、S3等。多元化存储可以更好地适应各种应用场景，提高存储系统的灵活性和适应性。</p><h4 id="文件如何通过分布式存储在许多服务器中"><a href="#文件如何通过分布式存储在许多服务器中" class="headerlink" title="文件如何通过分布式存储在许多服务器中"></a>文件如何通过分布式存储在许多服务器中</h4><p>分布式存储系统将数据分散存储在多个物理设备上。文件被切分成多个小块，存储在不同的服务器上。通过分布式哈希表（DHT）等算法确定数据块的位置，实现数据的快速定位和访问。通过数据复制和纠删码技术提高数据的可靠性和可用性。</p><h4 id="文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？"><a href="#文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？" class="headerlink" title="文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？"></a>文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？</h4><p>元数据服务器（MDS）存储文件系统的元数据，包括文件名、文件大小、数据块位置等信息。客户端请求文件时，首先查询MDS获取元数据，然后根据元数据访问对应的数据块。分布式文件系统中常用的元数据管理技术包括分布式哈希表（DHT）、目录树、名称节点（NameNode）等。</p><h4 id="如果文件丢失怎么办？"><a href="#如果文件丢失怎么办？" class="headerlink" title="如果文件丢失怎么办？"></a>如果文件丢失怎么办？</h4><p>由于分布式存储系统的特性，单一数据副本的丢失不会导致数据不可恢复。分布式存储系统采用数据冗余和副本机制，常见的冗余技术包括数据复制和纠删码。数据复制是将同一份数据存储在多个节点上，副本数通常为3个或更多。纠删码是一种冗余编码技术，通过增加校验数据，在数据块丢失的情况下，可以通过校验数据恢复原始数据。分布式存储系统在后台自动检测数据块的健康状态，发现数据丢失或损坏时，自动启动数据恢复机制，确保数据的完整性和可用性。</p><h4 id="存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？"><a href="#存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？" class="headerlink" title="存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？"></a>存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？</h4><p>存储系统的数据可靠性和可用性通过多种技术手段来保证。RAID技术通过数据条带化、镜像、奇偶校验等方法，提高单一存储设备的数据可靠性。分布式存储系统通过数据复制和纠删码技术，在多个节点上存储数据副本，提高数据的可靠性和可用性。高可用性通过冗余设计实现，常见的高可用架构包括双机热备、集群等。通过负载均衡技术，将用户请求分散到多个节点上，提高系统的可用性。</p><h4 id="写入的数据是如何被保护的？"><a href="#写入的数据是如何被保护的？" class="headerlink" title="写入的数据是如何被保护的？"></a>写入的数据是如何被保护的？</h4><p>数据写入时，采用多副本机制，确保数据的一致性和可靠性。写时复制（Copy-On-Write，COW）是一种常见的技术，通过在写入数据前复制一份旧数据，确保数据写入过程中的一致性。在分布式存储系统中，数据写入时，通常会先写入多个副本，只有所有副本写入成功后，才算写入成功。数据写入过程中的故障检测和处理机制，确保数据的可靠性和一致性。</p><h4 id="多人多设备协作时，如何保证远程协作时数据的一致性？"><a href="#多人多设备协作时，如何保证远程协作时数据的一致性？" class="headerlink" title="多人多设备协作时，如何保证远程协作时数据的一致性？"></a>多人多设备协作时，如何保证远程协作时数据的一致性？</h4><p>分布式存储系统通过分布式一致性协议（如Paxos、Raft）确保数据的一致性。在多个节点之间进行数据写入时，一致性协议保证数据的一致性和正确性。冲突检测和处理机制，在多人协作时，检测并解决数据冲突。分布式锁和事务机制，确保数据的一致性和完整性。</p><h4 id="节省存储空间"><a href="#节省存储空间" class="headerlink" title="节省存储空间"></a>节省存储空间</h4><p>存储系统采用数据压缩和数据去重技术，减少存储空间占用。数据压缩通过减少数据的冗余，提高存储空间的利用率。数据去重通过检测和删除重复数据，节省存储空间。在大规模存储系统中，数据压缩和去重技术可以显著降低存储成本，提高存储效率。</p><h4 id="避免存储固定的文件"><a href="#避免存储固定的文件" class="headerlink" title="避免存储固定的文件"></a>避免存储固定的文件</h4><p>存储系统采用分级存储和冷热数据分离策略，提高存储资源的利用率。根据数据的访问频率和重要性，将数据存储在不同的存储介质上。频繁访问的数据存储在高速存储设备上，减少访问延迟。较少访问的数据存储在低成本存储设备上，降低存储成本。通过冷热数据分离，优化存储资源的使用，提高存储系统的性能和效率。</p><h4 id="IO速度要有保证"><a href="#IO速度要有保证" class="headerlink" title="IO速度要有保证"></a>IO速度要有保证</h4><p>存储系统通过多种技术手段保证IO速度。使用高速缓存技术，将热点数据缓存到内存或SSD中，减少数据访问延迟。采用预取技术，在数据请求到达前提前加载数据，提高数据访问速度。使用QoS（Quality of Service）技术，为不同的应用场景和用户提供不同的IO优先级和带宽保障。负载均衡技术，将IO请求分散到多个存储节点上，避免单点瓶颈，提高IO性能。</p><h4 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h4><p>存储系统提供版本控制功能，允许用户对数据进行版本管理。在数据修改前，保存一份旧版本的数据，用户可以根据需要回滚到旧版本。版本控制功能确保数据的可追溯性和可恢复性，防止数据丢失和误操作。在分布式存储系统中，版本控制功能通过元数据管理和数据快照技术实现。元数据管理记录数据的版本信息和变更历史，数据快照技术保存数据的不同版本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;云存储概述&quot;&gt;&lt;a href=&quot;#云存储概述&quot; class=&quot;headerlink&quot; title=&quot;云存储概述&quot;&gt;&lt;/a&gt;云存储概述&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/%E4%BA%91%E5%AD%98%E5%82%A8%E5%BA%95%E5%</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Linux存储栈</title>
    <link href="https://watsonlu6.github.io/Linux%E5%AD%98%E5%82%A8%E6%A0%88/"/>
    <id>https://watsonlu6.github.io/Linux%E5%AD%98%E5%82%A8%E6%A0%88/</id>
    <published>2021-04-06T12:24:56.000Z</published>
    <updated>2024-07-27T03:55:23.469Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux存储栈"><a href="#Linux存储栈" class="headerlink" title="Linux存储栈"></a>Linux存储栈</h1><p><img src="/images/linux_storage_stack.png"><br>Linux存储系统包括用户接口和存储设备接口两个部分，前者以流形式处理数据，后者以块形式处理数据，文件系统在中间起到承上启下的作用。应用程序通过系统调用发出写请求，文件系统定位请求位置并转换成块设备所需的块，然后发送到设备上。内存在此过程中作为磁盘缓冲，将上下两部分隔离成异步运行的两个过程，避免频繁的磁盘同步。当数据需要从页面缓存同步到磁盘时，请求被包装成包含多个bio的request，每个bio包含需要同步的数据页。磁盘在执行写操作时，需要通过IO请求调度合理安排顺序，减少磁头的频繁移动，提高磁盘性能。</p><ol><li><h5 id="用户视角的数据流接口"><a href="#用户视角的数据流接口" class="headerlink" title="用户视角的数据流接口"></a>用户视角的数据流接口</h5><p> 应用程序通过系统调用（如<code>write</code>、<code>read</code>等）与操作系统交互。这些调用使得数据以流的形式被处理。</p></li><li><h5 id="存储设备的块接口"><a href="#存储设备的块接口" class="headerlink" title="存储设备的块接口"></a>存储设备的块接口</h5><p> 数据在底层存储设备（如硬盘、SSD等）中以块（通常是512字节或4096字节）为单位进行读写操作。</p></li><li><h5 id="文件系统的中间角色"><a href="#文件系统的中间角色" class="headerlink" title="文件系统的中间角色"></a>文件系统的中间角色</h5><ul><li><strong>位置定位</strong>：文件系统负责将用户的读写请求定位到存储设备的具体块位置。</li><li><strong>数据转换</strong>：将数据流转换为存储设备所需的块结构，并将这些块组织成<code>bio</code>（block I&#x2F;O）请求。</li></ul></li><li><h5 id="内存作为缓冲"><a href="#内存作为缓冲" class="headerlink" title="内存作为缓冲"></a>内存作为缓冲</h5><ul><li><strong>页面缓存</strong>：内存中的页面缓存（Page Cache）用于暂时存储数据，以减少频繁的磁盘I&#x2F;O操作。</li><li><strong>异步运行</strong>：将用户操作与底层存储设备的实际写操作异步化，提升系统效率。对于用户态程序来说，数据尽量保留在内存中，这样可以减少频繁的数据同步。</li></ul></li><li><h5 id="I-O请求调度"><a href="#I-O请求调度" class="headerlink" title="I&#x2F;O请求调度"></a>I&#x2F;O请求调度</h5><ul><li><strong>请求封装</strong>：从页面缓存同步到磁盘的请求被封装成<code>request</code>，每个<code>request</code>包含多个<code>bio</code>，而每个<code>bio</code>又包含具体的数据页。</li><li><strong>调度策略</strong>：操作系统会对I&#x2F;O请求进行调度，优化执行顺序，尽量减少磁盘磁头的来回移动，提高磁盘的读写效率。</li></ul></li></ol><h5 id="Linux数据写入流程"><a href="#Linux数据写入流程" class="headerlink" title="Linux数据写入流程"></a>Linux数据写入流程</h5><ol><li><strong>应用程序发出写请求</strong>：比如，应用程序通过<code>write</code>系统调用写入数据。</li><li><strong>文件系统处理</strong>：文件系统接收请求，找到对应的文件位置，将数据写入页面缓存。</li><li><strong>内存缓冲处理</strong>：数据暂存在内存的页面缓存中，以等待后续的写入操作。</li><li><strong>请求调度与封装</strong>：页面缓存的数据需要同步到磁盘时，被封装成<code>bio</code>和<code>request</code>。</li><li><strong>I&#x2F;O调度执行</strong>：调度器优化I&#x2F;O请求的执行顺序，减少磁头移动，提高写入效率。</li><li><strong>数据写入磁盘</strong>：最终，数据从页面缓存同步到磁盘的指定位置，完成写操作。<br>通过以上流程，Linux存储系统在保证数据一致性的同时，最大限度地提高了性能和效率。</li></ol><h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><p><img src="/images/linux_storage_stack_1.png"><br>&emsp;&emsp;用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用。在内核和应用程序交叉的地方，内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。用户可以通过文件系统相关的调用请求系统打开问价、关闭文件和读写文件。<br>&emsp;&emsp;内核提供的这组系统调用称为系统调用接口层。系统调用接口把应用程序的请求传达给内核，待内核处理完请求后再将处理结果返回给应用程序。<br>&emsp;&emsp;32位Linux，CPU能访问4GB的虚拟空间，其中低3GB的地址是应用层的地址空间，高地址的1GB是留给内核使用的。内核中所有线程共享这1GB的地址空间，而每个进程可以有自己的独立的3GB的虚拟空间，互不干扰。<br>&emsp;&emsp;当一个进程运行的时候，其用到文件的代码段，数据段等都是映射到内存地址区域的，这个功能是通过系统调用mmap()来完成的。mmap()将文件（由文件句柄fd所指定）从偏移offset的位置开始的长度为length的一个块映射到内存区域中，从而把文件的某一段映射到进程的地址空间，这样程序就可以通过访问内存的方式访问文件了。与read()&#x2F;write()相比，使用mmap的方式对文件进行访问，带来的一个显著好处就是可以减少一次用户空间到内核空间的复制，在某些场景下，如音频、视频等大文件，可以带来性能的提升。</p><h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><p><img src="/images/linux_storage_stack_2.png"><br>&emsp;&emsp;Linux文件系统的体系结构是一个对复杂系统进行抽象化，通过使用一组通用的API函数，Linux就可以在多种存储设备上支持多种文件系统，使得它拥有了与其他操作系统和谐共存的能力。<br>&emsp;&emsp;Linux中文件的概念并不局限于普通的磁盘文件，而是由字节序列构成的信息载体，I&#x2F;O设备、socket等也被包括在内。因为有了文件的存在，所以需要衍生文件系统去进行组织和管理文件，而为了支持各种各样的文件系统，所以有了虚拟文件系统的出现。文件系统是一种对存储设备上的文件、数据进行存储和组织的机制。<br>&emsp;&emsp;虚拟文件系统通过在各种具体的文件系统上建立了一个抽象层，屏蔽了不同文件系统间的差异，通过虚拟文件系统分层架构，在对文件进行操作时，便不需要去关心相关文件所在的具体文件系统细节。通过系统调用层，可以在不同文件系统之间复制和移动数据，正是虚拟文件系统使得这种跨越不同存储设备和不同文件系统的操作成为了可能。</p><h4 id="虚拟文件系统象类型"><a href="#虚拟文件系统象类型" class="headerlink" title="虚拟文件系统象类型"></a>虚拟文件系统象类型</h4><ul><li><strong>超级块（Super Block）</strong><br>超级块对象代表了一个已经安装的文件系统，用于存储该文件系统的相关信息，如文件系统的类型、大小、状态等。对基于磁盘的文件系统， 这类对象通常存放在磁盘特定的扇区上。对于并非基于磁盘的文件系统，它们会现场创建超级块对象并将其保存在内存中。</li><li><strong>索引节点（Inode）</strong><br>索引节点对象代表存储设备上的一个实际物理文件，用于存储该文件的有关信息。Linux将文件的相关信息（如访问权限、大小、创建时间等）与文件本身区分开。文件的相关信息又被称为文件的元数据。</li><li><strong>目录项（Dentry)</strong><br>  目录项对象描述了文件系统的层次结构，一个路径的各个组成部分，不管是目录（虚拟文件系统将目录当作文件来处理）还是普通文件，都是一个目录项对象。</li><li><strong>文件</strong><br>  文件对象代表已经被进程打开的文件，主要用于建立进程和文件之间的对应关系。它由open()系统调用创建，由close()系统调用销毁，当且仅当进程访问文件期间存在于内存中，同一个物理文件可能存在多个对应的文件对象，但其对应的索引节点对象是唯一的。</li></ul><h2 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h2><p><img src="/images/linux_storage_stack_3.png"><br>&emsp;&emsp;Page Cache，通常也称为文件缓存，使用内存Page Cache文件的逻辑内容，从而提高对磁盘文件的访问速度。Page Cache是以物理页为单位对磁盘文件进行缓存的。<br>&emsp;&emsp;应用程序尝试读取某块数据的时候，会首先查找Page Cache，如果这块数据已经存放在Page Cache中，那么就可以立即返回给应用程序，而不需要再进行实际的物理磁盘操作。如果不能在Page Cache中发现要读取的数据，那么就需要先将数据从磁盘读取到Page Cache中，同样，对于写操作来说，应用程序也会将数据写到Page Cache中，再根据所采用的写操作机制，判断数据是否应该立即被写到磁盘上</p><h2 id="Direct-I-O和Buffered-I-O"><a href="#Direct-I-O和Buffered-I-O" class="headerlink" title="Direct I&#x2F;O和Buffered I&#x2F;O"></a>Direct I&#x2F;O和Buffered I&#x2F;O</h2><p><img src="/images/linux_storage_stack_4.png"><br>进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条</p><ul><li><strong>标准I&#x2F;O：</strong> 也称为Buffered I&#x2F;O；Linux会将I&#x2F;O的数据缓存在Page Cache中，也就是说，数据会先被复制到内核的缓冲区，再从内核的缓冲区复制到应用程序的用户地址空间。在Buffered I&#x2F;O机制中，在没有CPU干预的情况下，可以通过DMA操作在磁盘和Page Cache之间直接进行数据的传输，在一定程度上分离了应用程序和物理设备，但是没有方法能直接在应用程序的地址空间和磁盘之间进行数据传输，数据在传输过程中需要在用户空间和Page Cache之间进行多次数据复制操作，这将带来较大的CPU开销。</li><li><strong>Direct I&#x2F;O：</strong> 可以省略使用Buffered I&#x2F;O中的内核缓冲区，数据可以直接在用户空间和磁盘之间进行传输，从而使得缓存应用程序可以避开复杂系统级别的缓存结构，执行自定义的数据读写管理，从而降低系统级别的管理对应用程序访问数据的影响。如果在块设备中执行Direct I&#x2F;O，那么进程必须在打开文件的时候将对文件的访问模式设置为O_DIRECT，这样就等于告诉Linux进程在接下来将使用Direct I&#x2F;O方式去读写文件，且传输的数据不经过内核中的Page Cache。Direct I&#x2F;O最主要的优点就是通过减少内核缓冲区和用户空间的数据复制次数，降低文件读写时所带来的CPU负载能力及内存带宽的占用率。如果传输的数据量很大，使用Direct IO的方式将会大大提高性能。然而，不经过内湖缓冲区直接进行磁盘的读写，必然会引起阻塞，因此通常Direct IO和AIO（异步IO）一起使用。</li></ul><h2 id="块层（Block-Layer）"><a href="#块层（Block-Layer）" class="headerlink" title="块层（Block Layer）"></a>块层（Block Layer）</h2><p><img src="/images/linux_storage_stack_5.png"><br>&emsp;&emsp;块设备访问时，需要在介质的不同区间前后移动，对于内核来说，管理块设备要比管理字符设备复杂得多。<br>&emsp;&emsp;系统调用read()触发相应的虚拟文件系统函数，虚拟文件系统判断请求是否已经在内核缓冲区里，如果不在，则判断如何执行读操作。如果内核必须从块设备上读取数据，就必须要确定数据在物理设备上的位置。这由映射层，即磁盘文件系统来完成。文件系统将文件访问映射为设备访问。<br>在通用块层中，使用bio结构体来描述一个I&#x2F;O请求在上层文件系统与底层物理磁盘之间的关系。而到了Linux驱动，则是使用request结构体来描述向块设备发出的I&#x2F;O请求的。对于慢速的磁盘而言，请求的处理速度很慢，这是内核就提供一种队列的机制把这些I&#x2F;O请求添加到队列中，使用request_queue结构体来描述。<br>&emsp;&emsp;bio和request是块层最核心的两个数据结构，其中，bio描述了磁盘里要真实操作的位置和Page Cache中的映射关系。作为Linux I&#x2F;O请求的基本单元，bio结构贯穿块层对I&#x2F;O请求处理的始终，每个bio对应磁盘里面一块连续的位置，bio结构中的bio_vec是一个bio的数据容器，专门用来保存bio的数据，包含一块数据所在页，以及页内的偏移及长度信息，通过这些信息就可以很清晰地描述数据具体什么位置。request用来描述单次I&#x2F;O请求，request_queue用来描述与设备相关的请求队列，每个块设备在块层都有一个request_queue与之对应，所有对该块设备的I&#x2F;O请求最后都会流经request_queue。块层正是借助bio、bio_vec、request、request_queue这几个结构将I&#x2F;O请求在内核I&#x2F;O子系统各个层次的处理过程联系起来。</p><ul><li><strong>I&#x2F;O调度算法：</strong> noop算法（不调度算法）、deadline算法（改良的电梯算法）、CFQ算法（完全公平调度算法，对于通用的服务器来说，CFQ是较好的选择，从Linux2.6.18版本开始，CFQ成为了默认的IO调度算法）。</li><li><strong>I&#x2F;O合并：</strong> 将符合条件的多个IO请求合并成单个IO请求进行一并处理，从而提升IO请求的效率。进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条，无论哪一条路径，在bio结构转换为request结构进行IO调度前都需要进入Plug队列进行蓄流（部分Direct IO产生的请求不需要经过蓄流），所以对IO请求来说，能够进行合并的位置主要有Page Cache、Plug List、IO调度器3个。而在块层中，Plug将块层的IO请求聚集起来，使得零散的请求有机会进行合并和排序，最终达到高效利用存储设备的目的。每个进程都有一个私有的Plug队列，进程在向通用块层派发IO派发请求之前如果开始蓄流的功能，那么IO请求在被发送给IO调度器之前都被保存在Plug队列中，直到泄流的时候才被批量交给调度器。蓄流主要是为了增加请求合并的机会，bio在进入Plug队列之前会尝试与Plug队列保存的request进行合并。当应用需要发多个bio请求的时候，比较好的办法是先蓄流，而不是一个个单独发给最终的硬盘。</li></ul><h2 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a>LVM</h2><p>&emsp;&emsp;LVM，即Logical Volume Manager，逻辑卷管理器，是一种硬盘的虚拟化技术，可以允许用户的硬盘资源进行灵活的调整和动态管理。<br>&emsp;&emsp;LVM是Linux系统对于硬盘分区管理的一种机制，诞生是为了解决硬盘设备在创建分区后不易修改分区大小的缺陷。尽管对硬盘的强制性扩容和缩容理论上是可行的，但是却可能造成数据丢失。LVM技术是通过在硬盘分区和文件系统之间增加一个逻辑层，提供了一个抽象的卷组，就可以把多块硬盘设备、硬盘分区，甚至RAID整体进行卷则合并。并可以根据情况进行逻辑上的虚拟分割，这样一来，用户不用关心物理硬盘设备的底层架构和布局，就可以实现对硬盘分区设备的动态调整。<br>&emsp;&emsp;LVM通过在操作系统与物理存储资源之间引入逻辑卷（Logical Volume）的抽象，来解决传统磁盘分区管理工具的问题。LVM将众多不同的物理存储器资源（物理卷，Physical Volume）组成卷组（Volume Group），该卷组可以理解为普通系统的物理磁盘，但是卷组上不能创建或者安装文件系统，而是需要LVM先在卷组中创建一个逻辑卷，然后将ext3等文件系统安装在这个逻辑卷上，可以在不重新引导系统的前提下通过在卷组划分额外的空间，来为这个逻辑卷动态扩容。<br>LVM的架构体系中，有三个很重要的概念：</p><ul><li>PV，物理卷，即实际存在的硬盘、分区或者RAID</li><li>VG，卷组，是由多个物理卷组合形成的大的整体的卷组</li><li>LV，逻辑卷，是从卷组上分割出来的，可以使用使用的逻辑存储设备</li></ul><h2 id="条带化"><a href="#条带化" class="headerlink" title="条带化"></a>条带化</h2><p>&emsp;&emsp;大多数磁盘系统都对访问次数（每秒的 I&#x2F;O 操作，IOPS）和数据传输率（每秒传输的数据量，TPS）有限制。当达到这些限制时，后面需要访问磁盘的进程就需要等待，这时就是所谓的磁盘冲突。避免磁盘冲突是优化 I&#x2F;O 性能的一个重要目标，而 I&#x2F;O 性能的优化与其他资源（如CPU和内存）的优化有着很大的区别 ,I&#x2F;O 优化最有效的手段是将 I&#x2F;O 最大限度的进行平衡。条带化技术就是一种自动的将 I&#x2F;O 的负载均衡到多个物理磁盘上的技术，条带化技术就是将一块连续的数据分成很多小部分并把他们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分而不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的 I&#x2F;O 并行能力，从而获得非常好的性能。很多操作系统、磁盘设备供应商、各种第三方软件都能做到条带化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Linux存储栈&quot;&gt;&lt;a href=&quot;#Linux存储栈&quot; class=&quot;headerlink&quot; title=&quot;Linux存储栈&quot;&gt;&lt;/a&gt;Linux存储栈&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/linux_storage_stack.png&quot;&gt;&lt;br</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
