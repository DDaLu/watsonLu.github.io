<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>watson&#39;blogs</title>
  
  
  <link href="https://watsonlu6.github.io/atom.xml" rel="self"/>
  
  <link href="https://watsonlu6.github.io/"/>
  <updated>2024-07-13T15:48:21.670Z</updated>
  <id>https://watsonlu6.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>块存储_文件系统存储_对象存储的区别</title>
    <link href="https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://watsonlu6.github.io/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2024-07-13T15:29:15.000Z</published>
    <updated>2024-07-13T15:48:21.670Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB.png"></p><h2 id="定义角度"><a href="#定义角度" class="headerlink" title="定义角度"></a>定义角度</h2><ul><li><strong>块存储</strong><br>指以扇区为基础，一个或者连续的扇区组成一个块，也叫物理块。它是在文件系统与块设备(例如：磁盘驱动器)之间。利用多个物理硬盘的并发能力。关注的是写入偏移位置。 </li><li><strong>文件系统存储</strong><br>文件系统存储也称为文件级存储或基于文件的存储，数据会以单条信息的形式存储在文件夹中。当需要访问该数据时，计算机需要知道相应的查找路径，存储在文件中的数据会根据数量有限的元数据来进行整理和检索，这些元数据会告诉计算机文件所在的确切位置。它就像是数据文件的库卡目录。</li><li><strong>对象存储</strong><br>对象存储，也称为基于对象的存储，是一种扁平结构，其中的文件被拆分成多个部分并散布在多个硬件间。在对象存储中，数据会被分解为称为“对象”的离散单元，并保存在单个存储库中，而不是作为文件夹中的文件或服务器上的块来保存。</li></ul><h2 id="使用角度"><a href="#使用角度" class="headerlink" title="使用角度"></a>使用角度</h2><ul><li><strong>块存储</strong><br>生活中常见的块存储设备（也叫“块设备”）比如，插在你本地电脑上的U盘、硬盘，你电脑连接的iSCSI等。<br>从使用上来说，块级的存储如果是第一次使用，那么必须需要进行一次格式化的操作，创建出一个文件系统，然后才可以使用。例如新买的U盘、硬盘、或者新发现的iSCSI设备等，首次使用的时候都需要进行一次格式化操作，创建出一个文件系统，然后才可以将你的文件拷贝到U盘、硬盘、或者新发现的iSCSI设备中。</li><li><strong>文件系统存储</strong><br>文件系统存储是最常见的一种文件内系统，我们日常对操作系使用中，基本上能够直接接触到的都就是这种，能够直接访问的C、D、E盘，电脑里的一个目录，网上邻居的空间都是文件级的存储。块级的存储设备经过格式化以及挂载（win 会自动挂载）之后，你就将一个块级的存储变成了文件级的存储。</li><li><strong>对象存储</strong><br>对象存储一般来说并不是给我们人直接去使用的，从使用者角度来说，它更适合用用于给程序使用。平时最常见的一般就是百度网盘，其后端对接的就是对象存储。还有就网页上的图片、视频，其本身也是存储在对象存储的文件系统中的。如果要直接使用对象级的存储，你会发现对象级的存储本身是非常的简单的（但是对人来说不方便），它只有简单的几种命令如上传、下载、删除，并且你只需要知道某个文件的编号（如：”d5t35e6tdud725dgs6u2hdsh27dh27d7”  这不是名字）就可以直接对它进行上传、下载、删除等操作，不需要像文件级那样，直到文件的具体的路径（如:D:\photo\1.jpg），并且他也只有这几种操作，如果你想编辑文件，那只能将文件下载下来编辑好之后在进行上传（这也是它对人来说不方便的原因之一）</li></ul><h2 id="技术角度"><a href="#技术角度" class="headerlink" title="技术角度"></a>技术角度</h2><p>块级、文件级、对象级技术上的区别，首先要明白两个概念<br>第一，无论是那个级别的存储系统，其数据都是会存储在物理的存储设备上的，这些存储设备现在常见的基本上就两种机械硬盘、固态硬盘。<br>第二，任何数据都是由两部”数据“分组成的，一部分是”数据本身”(下文中“数据”指”数据本身“)，另一部分就是这些“数据”的”元数据“。所谓的”元数据”就是用来描述”数据”的”数据”。包括数据所在的位置，文件的长度（大小），文件的访问权限、文件的时间戳（创建时间、修改时间….），元数据本身也是数据。</p><ul><li><strong>块存储</strong><br>对于块级来说，如果要通过块设备来访问一段数据的话，你自己需要知道这些数据具体是存在于那个存储设备上的位置上，例如如果你要从块设备上读取一张照片，你就要高速存储设备：我要从第2块硬盘中的从A位置开始到B位置的数据，硬盘的驱动就会将这个数据给你。读取照片的过程中照片的具体位置就是元数据，也就是说块级的存储中要求程序自己保存元数据。</li><li><strong>文件系统存储</strong><br>如果需要自己保存元数据的话就太麻烦了，上文也说了，元数据本身也是数据，实际上元数据也是存储在硬盘上的，那么如何访问元数据这个数据呢其实，文件级的元数据是存储在固定位置的，存储的位置和方式是大家事先约定好的，这个约定就叫做文件系统，例如EXT4、FAT32、XFS、NTFS等。借助于这些约定，我们就不用自己去维护一个表去记录每一份数据的具体存储位置了。我们只需要直到我们存储的文件的路径和名字就好了，例如我们想要 D:\1.jpg 这个文件，那么你只需要告诉文件系统 D:\1.jpg 这个位置就可以了，去硬盘的哪里找D:\1.jpg 数据的真身，就是文件系统的工作了</li><li><strong>对象存储</strong><br>对象级存储，文件级的元数据实际上是和数据放在一起的，就像一本书每本书都有一个目录，这个目录描述的是这本书上内容的索引，目录就是书内容的“元数据”，而对象存储，会有一本书只放目录（元数据），其他更多的书只有内容，并且内容都是被拆分好的一段一段的，就是说你会看每本书上面的内容完全是混在在一起的，这一页的前两行是书A的某句话，后面就跟的是书D的某句话，如果只放目录（元数据）那本书，你根本不知道这里写的是啥。对象及存储将一切的文件都视作对象，并且将对象按照固定的”形式”组合或拆分的存储在存储设备中，并且将数据的元数据部分完全的独立出来，进行单独的管理。</li></ul><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><ul><li>从<strong>距离（io路径）</strong> 上来说（相对于传统的存储），块存储的使用者距离最底层实际存储数据的存储设备是最近的，对象级是最远的。</li><li>从<strong>使用</strong>上来说，块存储需要使用者自己直到数据的真是位置，需要自己管理记录这些数据，所以使用上是最复杂的，而对象存储的接口最简单，基本上只有上传、下载、删除，并且不需要自己保存元数据，也不需要直到文件的索引路径，所以使用上是最简单的。但是从方便角度来讲还是文件存储最方便。</li><li>从<strong>性能</strong>上来说，综合的来讲（在特定的应用场合）性能最好的是块存储，它主要用在数据库、对延时要求非常高的场景中，对象存储多用于互联网，因为扩展性好，容量可以做的非常的大。对于人类来说，如果不借助特定的客户端、APP，使用文件存储是最友好最简单的。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li><strong>块存储：</strong> 要求高性能的应用，如数据库需要高IO，用块存储比较合适。</li><li><strong>文件系统存储：</strong> 需局域网共享的应用，如文件共享，视频处理，动画渲染&#x2F;高性能计算。</li><li><strong>对象存储：</strong> 互联网领域的存储，如点播&#x2F;视频监控的视频存储、图片存储、网盘存储、静态网页存储等，以及异地备份存储&#x2F;归档等。</li></ul><p><img src="/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB_1.png"></p><h2 id="为什么块级的存储性能最好"><a href="#为什么块级的存储性能最好" class="headerlink" title="为什么块级的存储性能最好"></a>为什么块级的存储性能最好</h2><p>&emsp;&emsp;首先要明确一点，要明确，每次在发生数据读取访问的时候，实际上对应系统的底层是发生了多次IO的（主要是要对元数据进行访问），例如，你要打开文件1.txt ，操作系统回去进行文件是否存在的查询，以及读写权限的查询等操作，这些操作实际上都是对于元数据的访问。<br>&emsp;&emsp;然后，相对于其它的存储方式，块存储的元数据是有操作系统自己管理的，也就是说整个文件系统（元数据）是存在在操做系统的内存中的，这样操作系统在进行元数据管理的时候可以直和自己的内存打交道。而文件系统存储和对象存储，它的文件系统是存在于另一台服务器上的，这样在进行元数据访问时就需要从网络进行访问，这样要比从内存访问慢得多。<br>&emsp;&emsp;总结来讲，就是块级存储的元数据在系统本机中，在进行元数据访问（每次读写文件实际都会在操作系统底层发生），会更快，因为其它的级别的存储元数据都要通过网络访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/%E5%9D%97%E5%AD%98%E5%82%A8-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8-%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://watsonlu6.github.io/hello-world/"/>
    <id>https://watsonlu6.github.io/hello-world/</id>
    <published>2024-07-13T08:29:18.282Z</published>
    <updated>2024-07-13T08:29:18.282Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>云存储概述</title>
    <link href="https://watsonlu6.github.io/%E4%BA%91%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/"/>
    <id>https://watsonlu6.github.io/%E4%BA%91%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/</id>
    <published>2024-07-11T15:09:26.000Z</published>
    <updated>2024-07-13T15:50:21.019Z</updated>
    
    <content type="html"><![CDATA[<h2 id="云存储底层技术"><a href="#云存储底层技术" class="headerlink" title="云存储底层技术"></a>云存储底层技术</h2><p><img src="/images/%E4%BA%91%E5%AD%98%E5%82%A8%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF.png"></p><h4 id="云存储的概述"><a href="#云存储的概述" class="headerlink" title="云存储的概述"></a>云存储的概述</h4><p>云存储是指通过网络，将分布在不同地方的多种存储设备，通过应用软件集合起来共同对外提供数据存储和业务访问功能的一个系统。云存储是云计算系统中的一种新型网络存储技术。云存储对外提供的存储能力以统一、简单的数据服务接口来提供和展现。用户不用关心数据具体存放在哪个设备、哪个区域，甚至不知道数据到底是怎么保存的，他们只需要关心需要多少存储空间、什么时间能够拿到数据、数据存放的安全性和可用性如何即可。</p><h4 id="云存储的实现模式"><a href="#云存储的实现模式" class="headerlink" title="云存储的实现模式"></a>云存储的实现模式</h4><p>云存储的实现模式有多种，云存储的架构可以由传统的存储架构延伸而来，也可以采用全新的云计算架构。云存储的实现可以是软件的，也可以是硬件的。云存储的实现模式可以是块存储、文件存储和对象存储。</p><ul><li><p><strong>块存储</strong></p><ul><li>块存储：最接近底层的存储，可以对数据进行任意格式化操作，可以在上面运行数据库等性能要求高的应用。可以给虚拟机使用。</li></ul></li><li><p><strong>文件存储</strong></p><ul><li>文件存储：对数据以文件的形式进行存储，支持复杂的文件操作，适合共享文件和协作工作。典型应用场景：NAS。</li></ul></li><li><p><strong>对象存储</strong></p><ul><li>对象存储：将数据以对象形式存储，通过唯一的对象ID进行访问，适合存储大规模非结构化数据，支持RESTful API接口。典型应用场景：云存储服务，视频、图片存储。</li></ul></li></ul><h4 id="为什么需要多元化存储？"><a href="#为什么需要多元化存储？" class="headerlink" title="为什么需要多元化存储？"></a>为什么需要多元化存储？</h4><p>由于不同的应用场景对存储的需求不同，单一的存储类型无法满足所有需求。大规模存储系统需要支持多种存储类型和多种存储协议，比如NFS、iSCSI、HDFS、S3等。多元化存储可以更好地适应各种应用场景，提高存储系统的灵活性和适应性。</p><h4 id="文件如何通过分布式存储在许多服务器中"><a href="#文件如何通过分布式存储在许多服务器中" class="headerlink" title="文件如何通过分布式存储在许多服务器中"></a>文件如何通过分布式存储在许多服务器中</h4><p>分布式存储系统将数据分散存储在多个物理设备上。文件被切分成多个小块，存储在不同的服务器上。通过分布式哈希表（DHT）等算法确定数据块的位置，实现数据的快速定位和访问。通过数据复制和纠删码技术提高数据的可靠性和可用性。</p><h4 id="文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？"><a href="#文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？" class="headerlink" title="文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？"></a>文件被读取时如何快速找到数据块，确保大目标的组合数据不会丢失？</h4><p>元数据服务器（MDS）存储文件系统的元数据，包括文件名、文件大小、数据块位置等信息。客户端请求文件时，首先查询MDS获取元数据，然后根据元数据访问对应的数据块。分布式文件系统中常用的元数据管理技术包括分布式哈希表（DHT）、目录树、名称节点（NameNode）等。</p><h4 id="如果文件丢失怎么办？"><a href="#如果文件丢失怎么办？" class="headerlink" title="如果文件丢失怎么办？"></a>如果文件丢失怎么办？</h4><p>由于分布式存储系统的特性，单一数据副本的丢失不会导致数据不可恢复。分布式存储系统采用数据冗余和副本机制，常见的冗余技术包括数据复制和纠删码。数据复制是将同一份数据存储在多个节点上，副本数通常为3个或更多。纠删码是一种冗余编码技术，通过增加校验数据，在数据块丢失的情况下，可以通过校验数据恢复原始数据。分布式存储系统在后台自动检测数据块的健康状态，发现数据丢失或损坏时，自动启动数据恢复机制，确保数据的完整性和可用性。</p><h4 id="存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？"><a href="#存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？" class="headerlink" title="存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？"></a>存储系统的数据可靠性（就像RAID）以及可用性（如高可用性）是如何解决的？</h4><p>存储系统的数据可靠性和可用性通过多种技术手段来保证。RAID技术通过数据条带化、镜像、奇偶校验等方法，提高单一存储设备的数据可靠性。分布式存储系统通过数据复制和纠删码技术，在多个节点上存储数据副本，提高数据的可靠性和可用性。高可用性通过冗余设计实现，常见的高可用架构包括双机热备、集群等。通过负载均衡技术，将用户请求分散到多个节点上，提高系统的可用性。</p><h4 id="写入的数据是如何被保护的？"><a href="#写入的数据是如何被保护的？" class="headerlink" title="写入的数据是如何被保护的？"></a>写入的数据是如何被保护的？</h4><p>数据写入时，采用多副本机制，确保数据的一致性和可靠性。写时复制（Copy-On-Write，COW）是一种常见的技术，通过在写入数据前复制一份旧数据，确保数据写入过程中的一致性。在分布式存储系统中，数据写入时，通常会先写入多个副本，只有所有副本写入成功后，才算写入成功。数据写入过程中的故障检测和处理机制，确保数据的可靠性和一致性。</p><h4 id="多人多设备协作时，如何保证远程协作时数据的一致性？"><a href="#多人多设备协作时，如何保证远程协作时数据的一致性？" class="headerlink" title="多人多设备协作时，如何保证远程协作时数据的一致性？"></a>多人多设备协作时，如何保证远程协作时数据的一致性？</h4><p>分布式存储系统通过分布式一致性协议（如Paxos、Raft）确保数据的一致性。在多个节点之间进行数据写入时，一致性协议保证数据的一致性和正确性。冲突检测和处理机制，在多人协作时，检测并解决数据冲突。分布式锁和事务机制，确保数据的一致性和完整性。</p><h4 id="节省存储空间"><a href="#节省存储空间" class="headerlink" title="节省存储空间"></a>节省存储空间</h4><p>存储系统采用数据压缩和数据去重技术，减少存储空间占用。数据压缩通过减少数据的冗余，提高存储空间的利用率。数据去重通过检测和删除重复数据，节省存储空间。在大规模存储系统中，数据压缩和去重技术可以显著降低存储成本，提高存储效率。</p><h4 id="避免存储固定的文件"><a href="#避免存储固定的文件" class="headerlink" title="避免存储固定的文件"></a>避免存储固定的文件</h4><p>存储系统采用分级存储和冷热数据分离策略，提高存储资源的利用率。根据数据的访问频率和重要性，将数据存储在不同的存储介质上。频繁访问的数据存储在高速存储设备上，减少访问延迟。较少访问的数据存储在低成本存储设备上，降低存储成本。通过冷热数据分离，优化存储资源的使用，提高存储系统的性能和效率。</p><h4 id="IO速度要有保证"><a href="#IO速度要有保证" class="headerlink" title="IO速度要有保证"></a>IO速度要有保证</h4><p>存储系统通过多种技术手段保证IO速度。使用高速缓存技术，将热点数据缓存到内存或SSD中，减少数据访问延迟。采用预取技术，在数据请求到达前提前加载数据，提高数据访问速度。使用QoS（Quality of Service）技术，为不同的应用场景和用户提供不同的IO优先级和带宽保障。负载均衡技术，将IO请求分散到多个存储节点上，避免单点瓶颈，提高IO性能。</p><h4 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h4><p>存储系统提供版本控制功能，允许用户对数据进行版本管理。在数据修改前，保存一份旧版本的数据，用户可以根据需要回滚到旧版本。版本控制功能确保数据的可追溯性和可恢复性，防止数据丢失和误操作。在分布式存储系统中，版本控制功能通过元数据管理和数据快照技术实现。元数据管理记录数据的版本信息和变更历史，数据快照技术保存数据的不同版本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;云存储底层技术&quot;&gt;&lt;a href=&quot;#云存储底层技术&quot; class=&quot;headerlink&quot; title=&quot;云存储底层技术&quot;&gt;&lt;/a&gt;云存储底层技术&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/%E4%BA%91%E5%AD%98%E5%82%A8%E5%B</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Linux存储栈</title>
    <link href="https://watsonlu6.github.io/Linux%E5%AD%98%E5%82%A8%E6%A0%88/"/>
    <id>https://watsonlu6.github.io/Linux%E5%AD%98%E5%82%A8%E6%A0%88/</id>
    <published>2024-07-10T12:24:56.000Z</published>
    <updated>2024-07-13T15:50:12.827Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux存储栈"><a href="#Linux存储栈" class="headerlink" title="Linux存储栈"></a>Linux存储栈</h1><p><img src="/images/linux_storage_stack.png"><br>Linux存储系统包括用户接口和存储设备接口两个部分，前者以流形式处理数据，后者以块形式处理数据，文件系统在中间起到承上启下的作用。应用程序通过系统调用发出写请求，文件系统定位请求位置并转换成块设备所需的块，然后发送到设备上。内存在此过程中作为磁盘缓冲，将上下两部分隔离成异步运行的两个过程，避免频繁的磁盘同步。当数据需要从页面缓存同步到磁盘时，请求被包装成包含多个bio的request，每个bio包含需要同步的数据页。磁盘在执行写操作时，需要通过IO请求调度合理安排顺序，减少磁头的频繁移动，提高磁盘性能。</p><ol><li><h5 id="用户视角的数据流接口"><a href="#用户视角的数据流接口" class="headerlink" title="用户视角的数据流接口"></a>用户视角的数据流接口</h5><p> 应用程序通过系统调用（如<code>write</code>、<code>read</code>等）与操作系统交互。这些调用使得数据以流的形式被处理。</p></li><li><h5 id="存储设备的块接口"><a href="#存储设备的块接口" class="headerlink" title="存储设备的块接口"></a>存储设备的块接口</h5><p> 数据在底层存储设备（如硬盘、SSD等）中以块（通常是512字节或4096字节）为单位进行读写操作。</p></li><li><h5 id="文件系统的中间角色"><a href="#文件系统的中间角色" class="headerlink" title="文件系统的中间角色"></a>文件系统的中间角色</h5><ul><li><strong>位置定位</strong>：文件系统负责将用户的读写请求定位到存储设备的具体块位置。</li><li><strong>数据转换</strong>：将数据流转换为存储设备所需的块结构，并将这些块组织成<code>bio</code>（block I&#x2F;O）请求。</li></ul></li><li><h5 id="内存作为缓冲"><a href="#内存作为缓冲" class="headerlink" title="内存作为缓冲"></a>内存作为缓冲</h5><ul><li><strong>页面缓存</strong>：内存中的页面缓存（Page Cache）用于暂时存储数据，以减少频繁的磁盘I&#x2F;O操作。</li><li><strong>异步运行</strong>：将用户操作与底层存储设备的实际写操作异步化，提升系统效率。对于用户态程序来说，数据尽量保留在内存中，这样可以减少频繁的数据同步。</li></ul></li><li><h5 id="I-O请求调度"><a href="#I-O请求调度" class="headerlink" title="I&#x2F;O请求调度"></a>I&#x2F;O请求调度</h5><ul><li><strong>请求封装</strong>：从页面缓存同步到磁盘的请求被封装成<code>request</code>，每个<code>request</code>包含多个<code>bio</code>，而每个<code>bio</code>又包含具体的数据页。</li><li><strong>调度策略</strong>：操作系统会对I&#x2F;O请求进行调度，优化执行顺序，尽量减少磁盘磁头的来回移动，提高磁盘的读写效率。</li></ul></li></ol><h5 id="Linux数据写入流程"><a href="#Linux数据写入流程" class="headerlink" title="Linux数据写入流程"></a>Linux数据写入流程</h5><ol><li><strong>应用程序发出写请求</strong>：比如，应用程序通过<code>write</code>系统调用写入数据。</li><li><strong>文件系统处理</strong>：文件系统接收请求，找到对应的文件位置，将数据写入页面缓存。</li><li><strong>内存缓冲处理</strong>：数据暂存在内存的页面缓存中，以等待后续的写入操作。</li><li><strong>请求调度与封装</strong>：页面缓存的数据需要同步到磁盘时，被封装成<code>bio</code>和<code>request</code>。</li><li><strong>I&#x2F;O调度执行</strong>：调度器优化I&#x2F;O请求的执行顺序，减少磁头移动，提高写入效率。</li><li><strong>数据写入磁盘</strong>：最终，数据从页面缓存同步到磁盘的指定位置，完成写操作。<br>通过以上流程，Linux存储系统在保证数据一致性的同时，最大限度地提高了性能和效率。</li></ol><h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><p><img src="/images/linux_storage_stack_1.png"><br>&emsp;&emsp;用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用。在内核和应用程序交叉的地方，内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。用户可以通过文件系统相关的调用请求系统打开问价、关闭文件和读写文件。<br>&emsp;&emsp;内核提供的这组系统调用称为系统调用接口层。系统调用接口把应用程序的请求传达给内核，待内核处理完请求后再将处理结果返回给应用程序。<br>&emsp;&emsp;32位Linux，CPU能访问4GB的虚拟空间，其中低3GB的地址是应用层的地址空间，高地址的1GB是留给内核使用的。内核中所有线程共享这1GB的地址空间，而每个进程可以有自己的独立的3GB的虚拟空间，互不干扰。<br>&emsp;&emsp;当一个进程运行的时候，其用到文件的代码段，数据段等都是映射到内存地址区域的，这个功能是通过系统调用mmap()来完成的。mmap()将文件（由文件句柄fd所指定）从偏移offset的位置开始的长度为length的一个块映射到内存区域中，从而把文件的某一段映射到进程的地址空间，这样程序就可以通过访问内存的方式访问文件了。与read()&#x2F;write()相比，使用mmap的方式对文件进行访问，带来的一个显著好处就是可以减少一次用户空间到内核空间的复制，在某些场景下，如音频、视频等大文件，可以带来性能的提升。</p><h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><p><img src="/images/linux_storage_stack_2.png"><br>&emsp;&emsp;Linux文件系统的体系结构是一个对复杂系统进行抽象化，通过使用一组通用的API函数，Linux就可以在多种存储设备上支持多种文件系统，使得它拥有了与其他操作系统和谐共存的能力。<br>&emsp;&emsp;Linux中文件的概念并不局限于普通的磁盘文件，而是由字节序列构成的信息载体，I&#x2F;O设备、socket等也被包括在内。因为有了文件的存在，所以需要衍生文件系统去进行组织和管理文件，而为了支持各种各样的文件系统，所以有了虚拟文件系统的出现。文件系统是一种对存储设备上的文件、数据进行存储和组织的机制。<br>&emsp;&emsp;虚拟文件系统通过在各种具体的文件系统上建立了一个抽象层，屏蔽了不同文件系统间的差异，通过虚拟文件系统分层架构，在对文件进行操作时，便不需要去关心相关文件所在的具体文件系统细节。通过系统调用层，可以在不同文件系统之间复制和移动数据，正是虚拟文件系统使得这种跨越不同存储设备和不同文件系统的操作成为了可能。</p><h4 id="虚拟文件系统象类型"><a href="#虚拟文件系统象类型" class="headerlink" title="虚拟文件系统象类型"></a>虚拟文件系统象类型</h4><ul><li><strong>超级块（Super Block）</strong><br>超级块对象代表了一个已经安装的文件系统，用于存储该文件系统的相关信息，如文件系统的类型、大小、状态等。对基于磁盘的文件系统， 这类对象通常存放在磁盘特定的扇区上。对于并非基于磁盘的文件系统，它们会现场创建超级块对象并将其保存在内存中。</li><li><strong>索引节点（Inode）</strong><br>索引节点对象代表存储设备上的一个实际物理文件，用于存储该文件的有关信息。Linux将文件的相关信息（如访问权限、大小、创建时间等）与文件本身区分开。文件的相关信息又被称为文件的元数据。</li><li><strong>目录项（Dentry)</strong><br>  目录项对象描述了文件系统的层次结构，一个路径的各个组成部分，不管是目录（虚拟文件系统将目录当作文件来处理）还是普通文件，都是一个目录项对象。</li><li><strong>文件</strong><br>  文件对象代表已经被进程打开的文件，主要用于建立进程和文件之间的对应关系。它由open()系统调用创建，由close()系统调用销毁，当且仅当进程访问文件期间存在于内存中，同一个物理文件可能存在多个对应的文件对象，但其对应的索引节点对象是唯一的。</li></ul><h2 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h2><p><img src="/images/linux_storage_stack_3.png"><br>&emsp;&emsp;Page Cache，通常也称为文件缓存，使用内存Page Cache文件的逻辑内容，从而提高对磁盘文件的访问速度。Page Cache是以物理页为单位对磁盘文件进行缓存的。<br>&emsp;&emsp;应用程序尝试读取某块数据的时候，会首先查找Page Cache，如果这块数据已经存放在Page Cache中，那么就可以立即返回给应用程序，而不需要再进行实际的物理磁盘操作。如果不能在Page Cache中发现要读取的数据，那么就需要先将数据从磁盘读取到Page Cache中，同样，对于写操作来说，应用程序也会将数据写到Page Cache中，再根据所采用的写操作机制，判断数据是否应该立即被写到磁盘上</p><h2 id="Direct-I-O和Buffered-I-O"><a href="#Direct-I-O和Buffered-I-O" class="headerlink" title="Direct I&#x2F;O和Buffered I&#x2F;O"></a>Direct I&#x2F;O和Buffered I&#x2F;O</h2><p><img src="/images/linux_storage_stack_4.png"><br>进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条</p><ul><li><strong>标准I&#x2F;O：</strong> 也称为Buffered I&#x2F;O；Linux会将I&#x2F;O的数据缓存在Page Cache中，也就是说，数据会先被复制到内核的缓冲区，再从内核的缓冲区复制到应用程序的用户地址空间。在Buffered I&#x2F;O机制中，在没有CPU干预的情况下，可以通过DMA操作在磁盘和Page Cache之间直接进行数据的传输，在一定程度上分离了应用程序和物理设备，但是没有方法能直接在应用程序的地址空间和磁盘之间进行数据传输，数据在传输过程中需要在用户空间和Page Cache之间进行多次数据复制操作，这将带来较大的CPU开销。</li><li><strong>Direct I&#x2F;O：</strong> 可以省略使用Buffered I&#x2F;O中的内核缓冲区，数据可以直接在用户空间和磁盘之间进行传输，从而使得缓存应用程序可以避开复杂系统级别的缓存结构，执行自定义的数据读写管理，从而降低系统级别的管理对应用程序访问数据的影响。如果在块设备中执行Direct I&#x2F;O，那么进程必须在打开文件的时候将对文件的访问模式设置为O_DIRECT，这样就等于告诉Linux进程在接下来将使用Direct I&#x2F;O方式去读写文件，且传输的数据不经过内核中的Page Cache。Direct I&#x2F;O最主要的优点就是通过减少内核缓冲区和用户空间的数据复制次数，降低文件读写时所带来的CPU负载能力及内存带宽的占用率。如果传输的数据量很大，使用Direct IO的方式将会大大提高性能。然而，不经过内湖缓冲区直接进行磁盘的读写，必然会引起阻塞，因此通常Direct IO和AIO（异步IO）一起使用。</li></ul><h2 id="块层（Block-Layer）"><a href="#块层（Block-Layer）" class="headerlink" title="块层（Block Layer）"></a>块层（Block Layer）</h2><p><img src="/images/linux_storage_stack_5.png"><br>&emsp;&emsp;块设备访问时，需要在介质的不同区间前后移动，对于内核来说，管理块设备要比管理字符设备复杂得多。<br>&emsp;&emsp;系统调用read()触发相应的虚拟文件系统函数，虚拟文件系统判断请求是否已经在内核缓冲区里，如果不在，则判断如何执行读操作。如果内核必须从块设备上读取数据，就必须要确定数据在物理设备上的位置。这由映射层，即磁盘文件系统来完成。文件系统将文件访问映射为设备访问。<br>在通用块层中，使用bio结构体来描述一个I&#x2F;O请求在上层文件系统与底层物理磁盘之间的关系。而到了Linux驱动，则是使用request结构体来描述向块设备发出的I&#x2F;O请求的。对于慢速的磁盘而言，请求的处理速度很慢，这是内核就提供一种队列的机制把这些I&#x2F;O请求添加到队列中，使用request_queue结构体来描述。<br>&emsp;&emsp;bio和request是块层最核心的两个数据结构，其中，bio描述了磁盘里要真实操作的位置和Page Cache中的映射关系。作为Linux I&#x2F;O请求的基本单元，bio结构贯穿块层对I&#x2F;O请求处理的始终，每个bio对应磁盘里面一块连续的位置，bio结构中的bio_vec是一个bio的数据容器，专门用来保存bio的数据，包含一块数据所在页，以及页内的偏移及长度信息，通过这些信息就可以很清晰地描述数据具体什么位置。request用来描述单次I&#x2F;O请求，request_queue用来描述与设备相关的请求队列，每个块设备在块层都有一个request_queue与之对应，所有对该块设备的I&#x2F;O请求最后都会流经request_queue。块层正是借助bio、bio_vec、request、request_queue这几个结构将I&#x2F;O请求在内核I&#x2F;O子系统各个层次的处理过程联系起来。</p><ul><li><strong>I&#x2F;O调度算法：</strong> noop算法（不调度算法）、deadline算法（改良的电梯算法）、CFQ算法（完全公平调度算法，对于通用的服务器来说，CFQ是较好的选择，从Linux2.6.18版本开始，CFQ成为了默认的IO调度算法）。</li><li><strong>I&#x2F;O合并：</strong> 将符合条件的多个IO请求合并成单个IO请求进行一并处理，从而提升IO请求的效率。进程产生的IO路径主要有Direct I&#x2F;O和Buffered I&#x2F;O两条，无论哪一条路径，在bio结构转换为request结构进行IO调度前都需要进入Plug队列进行蓄流（部分Direct IO产生的请求不需要经过蓄流），所以对IO请求来说，能够进行合并的位置主要有Page Cache、Plug List、IO调度器3个。而在块层中，Plug将块层的IO请求聚集起来，使得零散的请求有机会进行合并和排序，最终达到高效利用存储设备的目的。每个进程都有一个私有的Plug队列，进程在向通用块层派发IO派发请求之前如果开始蓄流的功能，那么IO请求在被发送给IO调度器之前都被保存在Plug队列中，直到泄流的时候才被批量交给调度器。蓄流主要是为了增加请求合并的机会，bio在进入Plug队列之前会尝试与Plug队列保存的request进行合并。当应用需要发多个bio请求的时候，比较好的办法是先蓄流，而不是一个个单独发给最终的硬盘。</li></ul><h2 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a>LVM</h2><p>&emsp;&emsp;LVM，即Logical Volume Manager，逻辑卷管理器，是一种硬盘的虚拟化技术，可以允许用户的硬盘资源进行灵活的调整和动态管理。<br>&emsp;&emsp;LVM是Linux系统对于硬盘分区管理的一种机制，诞生是为了解决硬盘设备在创建分区后不易修改分区大小的缺陷。尽管对硬盘的强制性扩容和缩容理论上是可行的，但是却可能造成数据丢失。LVM技术是通过在硬盘分区和文件系统之间增加一个逻辑层，提供了一个抽象的卷组，就可以把多块硬盘设备、硬盘分区，甚至RAID整体进行卷则合并。并可以根据情况进行逻辑上的虚拟分割，这样一来，用户不用关心物理硬盘设备的底层架构和布局，就可以实现对硬盘分区设备的动态调整。<br>&emsp;&emsp;LVM通过在操作系统与物理存储资源之间引入逻辑卷（Logical Volume）的抽象，来解决传统磁盘分区管理工具的问题。LVM将众多不同的物理存储器资源（物理卷，Physical Volume）组成卷组（Volume Group），该卷组可以理解为普通系统的物理磁盘，但是卷组上不能创建或者安装文件系统，而是需要LVM先在卷组中创建一个逻辑卷，然后将ext3等文件系统安装在这个逻辑卷上，可以在不重新引导系统的前提下通过在卷组划分额外的空间，来为这个逻辑卷动态扩容。<br>LVM的架构体系中，有三个很重要的概念：</p><ul><li>PV，物理卷，即实际存在的硬盘、分区或者RAID</li><li>VG，卷组，是由多个物理卷组合形成的大的整体的卷组</li><li>LV，逻辑卷，是从卷组上分割出来的，可以使用使用的逻辑存储设备</li></ul><h2 id="条带化"><a href="#条带化" class="headerlink" title="条带化"></a>条带化</h2><p>&emsp;&emsp;大多数磁盘系统都对访问次数（每秒的 I&#x2F;O 操作，IOPS）和数据传输率（每秒传输的数据量，TPS）有限制。当达到这些限制时，后面需要访问磁盘的进程就需要等待，这时就是所谓的磁盘冲突。避免磁盘冲突是优化 I&#x2F;O 性能的一个重要目标，而 I&#x2F;O 性能的优化与其他资源（如CPU和内存）的优化有着很大的区别 ,I&#x2F;O 优化最有效的手段是将 I&#x2F;O 最大限度的进行平衡。条带化技术就是一种自动的将 I&#x2F;O 的负载均衡到多个物理磁盘上的技术，条带化技术就是将一块连续的数据分成很多小部分并把他们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分而不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的 I&#x2F;O 并行能力，从而获得非常好的性能。很多操作系统、磁盘设备供应商、各种第三方软件都能做到条带化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Linux存储栈&quot;&gt;&lt;a href=&quot;#Linux存储栈&quot; class=&quot;headerlink&quot; title=&quot;Linux存储栈&quot;&gt;&lt;/a&gt;Linux存储栈&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/linux_storage_stack.png&quot;&gt;&lt;br</summary>
      
    
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/categories/%E4%BA%91%E5%AD%98%E5%82%A8/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="云存储" scheme="https://watsonlu6.github.io/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"/>
    
    <category term="存储基础" scheme="https://watsonlu6.github.io/tags/%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
